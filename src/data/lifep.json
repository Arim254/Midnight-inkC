[
  {
    "title": "That Political 'Call to Action' Might Actually Be a Scam",
    "url": "https://lifehacker.com/tech/political-call-to-action-might-be-a-scam?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KG65AQZT1BGJW2MP7E11RTHY/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-06T19:00:00.000Z",
    "description": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n            ",
    "body": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n                    No, SendGrid isn't adding a \"Support ICE\" link to your company's emails.\n            \n                        \n    \n                    \n        \n        \n        \n    \n                                Justin Pot\n                            \n        \n            Justin Pot\n                \n                                                                        Editorial Author\n                                                            \n            \n            \n        \n            ExperienceJustin Pot is a freelance journalist who helps people get more out of technology. If you've ever searched online for a specific tech problem you've read Justin's work, because he's been doing it for a long time. Since 2009, he has written tutorials and essays about technology for outlets including WIRED, The Atlantic, PCMag, Popular Science, How-to Geek, and The Wall Street Journal. For Lifehacker, he mostly writes about software, with a particular focus on open source programs and indie apps. Justin has a bachelor's degree in Communications and International Relations. He once worked in marketing for a software company and hated it, but it did teach him a lot about why software tends to get worse over time in large companies. He lives in Oregon with his cat (and his wife). He enjoys brewing beer, exploring nature, and spending time with friends. You can follow Justin on Mastodon and Bluesky, or sign up for his newsletter, Connectivity.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                            \n        \n        \n        February 6, 2026\n            \n            \n                        Credit: Ian Moore/Lifehacker/Adobe Stock\n                            \n    \n        \n        I'm just a humble immigrant, but as a mere (legal!) guest in the U.S., I can't help but notice that the country is rather, shall we say, politically divided these days (sorry if pointing that out seems rude). It seems international scammers have also noticed—and are taking advantage in subtle ways.Recently, investor Fred Benenson blogged about a sophisticated phishing campaign targeting SendGrid users. Phishers sent emails claiming the company was going to add a large \"Support ICE\" button at the bottom of every outgoing email unless users opted out. The emails also featured a large blue button promising to help you disable the message, which, when clicked, naturally led to a fake version of SendGrid that would allow the scammers to steal login information.As scams go, it's not a bad play: Phishing emails work best when they induce a sense of panic—that way you're less likely to think critically about them, and just act. It's not hard to imagine this particular email being effective, given the political climate right now. Say you're running a fair trade coffee company—you wouldn't want a giant \"Support ICE\" button below your signature at this moment in history.But the trick didn't just target left-wing organizations: Variations on the theme claimed the company was going to add pro-LGBT+ and Black Lives Matter banners as well. The differing political messages aren't really the point of the scam, you see—the point is to get business owners to panic about projecting the \"wrong\" values so that they will click the link and give away their login information. Scammers rely on psychological tricks to rope in their victims, all of them designed to get you to stop thinking rationally. Exploiting America's political divide seems to be an excellent way to do that.Political phishing schemes are nothing newThis is just the latest example of a scam that uses politics as a tool. Back in 2020, a fake Black Lives Matter voting campaign spread malware by pretending to be from a county official looking for feedback on the then-exploding political movement. People on both side of the partisan divide ended up clicking through and getting infected.And then there are the campaigns where people pretend to be politicians and beg for donations: Back in 2024 Lifehacker reported on a rash of political donation scams that popped up during the presidential election cycle. That trend is still growing, according to Stacey Wood, a fraud expert writing for Psychology Today. \"What is especially challenging for consumers and voters is that legitimate campaign operatives use many of the same common persuasion techniques employed by scammers,\" she writes.\n            \n                What do you think so far?\n            \n        \nAll of which is to say that international scammers have equal access to American media outlets, are aware of our political divides, and are effective at using them to exploit your emotions in order to steal your money.How to spot a political phishing scamWhat can you do to protect yourself? First, be aware of the tricks that scammers use, and always approach your email inbox with skepticism. Before you click any link from an unfamiliar sender or in an unsolicited email, hover over it to see if it's going to a website that looks legit. Even better: Avoid clicking links altogether, and head to the website for a given service directly by typing it into your browser.Remember, it's easier to fall for a scam than you think, so it pays to be skeptical, especially when you encounter a call to action designed to get you to react in a panic.\n            \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n                        \n                \n            \n                    \n                                            \n                \n            \n                Justin Pot\n                                \n                                            Justin Pot is a freelance journalist who helps people get more out of technology.\n                                    \n                Read Justin's full bio\n                            \n        \n                \n                                            \n    More by Justin\n        \n        \n                        \n                \n                    \n                \n            \n        \n                    \n                \n                    \n                \n            \n        \n                                        \n            \n                                    \n                                            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "That Political 'Call to Action' Might Actually Be a Scam",
      "image": [
        "https://lifehacker.com/imagery/articles/01KG65AQZT1BGJW2MP7E11RTHY/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-06T19:00:00.000Z",
      "dateModified": "2026-02-06T19:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Substack Data Breach May Have Compromised Nearly 700,000 User Records",
    "url": "https://lifehacker.com/tech/substack-user-records-data-breach?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KGT4BA905YCK53HNVCFP4JGG/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-06T19:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 6, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: PJ McDonnell/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Substack disclosed a data breach this week that occurred in October of 2025.\n                                            Hackers compromised email addresses, phone numbers, and \"other internal metadata.\"\n                                            One threat actor claims the breach resulted in the loss of nearly 700,000 user records.\n                                    \n            \n    Table of Contents\n    \n        \n        When you sign up for a subscription on Substack, you're thinking you'll receive newsletters and posts from online creators, not lose the data you share with the platform. But like any digital service, the data you provide when signing up is at the mercy of Substack, or anyone who happens to gain access to that data. Unfortunately, that's now the case. As reported by BleepingComputer, Substack recently disclosed a significant data breach. The company's CEO, Chris Best, sent users a notice of the breach this week, sharing that email addresses, phone numbers, and \"other internal metadata\" were shared from Substack accounts without their permission. The company reportedly discovered the breach on Feb. 3, even though hackers accessed the data itself in October of 2025. That means the data was in unauthorized hands for roughly four months before Substack identified the breach. Best explained that Substack has since fixed the problem with the system that allowed an unauthorized third party to access this data. The company is launching an investigation and is reportedly taking steps to prevent this type of breach from happening going forward. On the bright side, Best claims that credit card numbers, passwords, and financial information were not accessed in the breach. \nWhat Best doesn't share is the scope of the breach. For that, we have to turn to BleepingComputer, which found a post from a \"threat actor\" on the hacking forum BreachForums. The actor posted a database of 697,313 Substack records, sharing that the Substack user base is much larger, but the scraping method was \"noisy and patched fast.\" This actor says the data compromised includes email addresses, phone numbers, names, user IDs, Stripe IDs, profile pictures, and bios—a bit more detailed than the report from Substack's CEO.700,000 records isn't the same as 700,000 users: Each record is something like an email address or a phone number, which means one Substack user could have lost multiple records in the breach. Still, it's a large number of data points, and is little consolation to the users who have lost information here. \n            \n                What do you think so far?\n            \n        \nWhat Substack can do after this breachUnfortunately, there's not much users can do to mitigate a data breach once it's happened. The data stolen from Substack is already lost, and you won't be able to undo that. However, there are some steps you can take to protect yourself in the wake of the breach, and to prevent this data loss in the future. First, closely monitor your incoming texts and emails. Hackers will take advantage of the data here to target Substack users in phishing schemes. If you receive messages from strangers, or even suspicious messages claiming to come from Substack, exercise caution. As per usual, never click on links in messages from senders you don't know, and, even more importantly, never download files or applications if instructed. You may also want to consider masking your email address going forward. Use a service like Apple's \"Hide My Email\" or DuckDuckGo's email protection to generate a \"burner\" address each time you need to share your email with a service. The service will send messages to the burner address, which gets forwarded to your real address. That way, the service doesn't know your real address, and, if hacked, won't compromise it. Hackers will only get the burner, which you can shut down at any time.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Substack Data Breach May Have Compromised Nearly 700,000 User Records",
      "image": [
        "https://lifehacker.com/imagery/articles/01KGT4BA905YCK53HNVCFP4JGG/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-06T19:30:00.000Z",
      "dateModified": "2026-02-06T19:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "You Can Opt Out of Ads on ChatGPT, but It Might Not Be Worth It",
    "url": "https://lifehacker.com/tech/ads-on-chatgpt-free?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH26KJW3KJD43H7MWGTR35FH/hero-image.fill.size_1200x675.webp",
    "tag": "Life",
    "date": "2026-02-09T22:20:40.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: OpenAI\n                            \n            \n                Key Takeaways\n                                            OpenAI is rolling out ads to all ChatGPT Free and Go users.\n                                            The company says that ads are private, but are informed by your current and past chats.\n                                            You can opt out of ads for free, but you will reduce your ChatGPT message limits.\n                                    \n            \n    Table of Contents\n    \n        \n        It finally happened. After months of speculation, ChatGPT officially has ads. OpenAI revealed the news on Monday, announcing that ads would roll out in testing for logged-in adult users on Free and Go subscriptions. If you or your organization pays for ChatGPT, such as with a Plus, Pro, Business, Enterprise, or Education account, you won't see ads with the bot.OpenAI says that ads do not have an impact on the answers ChatGPT generates, and that these posts are always clearly separated from ChatGPT's actual responses. In addition, ads are labeled as \"Sponsored.\" That being said, it's not exactly a church-and-state situation here. OpenAI says that it decides which ads to show you based on your current and past chats, as well as your past interactions with ChatGPT ads. If you're asking for help with a dinner recipe, you might get an ad for a meal kit or grocery service. The company claims it keeps your chats away from advertisers. The idea, according to the company, is strictly funding-based so that OpenAI can expand ChatGPT access to more users. That's reportedly why ads are starting as a test, not a hardcoded feature: OpenAI says it wants to \"learn, listen, and make sure [it gets] the experience right.\" As such, advertisers don't have access to chats, chat histories, memories, or your personal details. They do have access to aggregate information about ad performance, including views and click metrics.   \nOpenAI will only show ads to adults. If the service detects that you are under 18, it will block ads from populating in your chats. Ads also will not appear if you're talking to ChatGPT about something related to health, medicine, or politics. You can offer OpenAI feedback on the ads you do see, which should inform the ads you receive in the future. You can also delete your ad data and manage ad personalization, if you want to reset the information OpenAI is using to send you ads.\n    \n            \n            \n                                        Credit: OpenAI\n                    \n    \nThe thing is, you don't actually have to deal with ads, even if you use ChatGPT for free. That's not just by upgrading to a paid ChatGPT plan, though OpenAI does suggest that option in its announcement. In addition, OpenAI is offering Free and Go users a dedicated choice to opt out of ads here. There is, of course, a pretty sizable catch: You have to agree to fewer daily free messages with ChatGPT. OpenAI doesn't offer specifics here, so it's not clear how limited the ad-free experience will be. But if you hate ads, or if you simply don't want to see an ad for something irrelevant to your ChatGPT conversation, it's an option.\n            \n                What do you think so far?\n            \n        \nIf you like that trade-off, here's how to opt out of ads. Open ChatGPT, then head to your profile, which opens your profile's Settings page. Here, scroll down to \"Ads controls,\" then choose \"Change plan to go ad-free.\" Select \"Reduce message limits,\" and ChatGPT will confirm ads are off for your account. You can return to this page at any time to turn ads back on and restore your message limits.  Disclosure: Ziff Davis, Mashable’s parent company, in April 2025 filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "You Can Opt Out of Ads on ChatGPT, but It Might Not Be Worth It",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH26KJW3KJD43H7MWGTR35FH/hero-image.fill.size_1200x675.webp"
      ],
      "datePublished": "2026-02-09T22:20:40.000Z",
      "dateModified": "2026-02-09T22:20:40.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Spotify Will Now Use AI to Tell You the Meaning Behind Your Favorite Songs",
    "url": "https://lifehacker.com/tech/spotifys-about-the-song-feature-summarizes-the-meaning-of-songs?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KGSTD1SZQ3KGA0KRYY8YS9BH/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-06T16:30:17.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 6, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Mino Surkala/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Spotify's \"About the Song\" feature offers fun facts about the music you're listening to.\n                                            The feature, currently in beta, generates summary cards with facts like song meaning, artist history, and movies the song appeared in.\n                                            About the Song is only available to Premium subscribers.\n                                    \n            \n    Table of Contents\n    \n        \n        Streaming services make it easy to listen to a lot of music, but they don't necessarily tell you much about the songs themselves. You can see how long each track is, who performed it, and maybe even the song writing credits, but you don't know why the artist wrote the song, or what each song is supposed to mean. You can, of course, scour the internet, looking at articles and blogs to learn more about your favorite music—or, you can skim Spotify's new summary cards that offer fun facts about each track. Spotify announced the new feature, called \"About the Song,\" on Friday. The feature, which is launching in beta, is available in the app's Now Playing View. When you select it, you'll see story cards you can swipe through that tell you more about the song you're listening to. Spotify says the stories are summarized from \"third-party sources,\" and in my testing, I've seen sources like Hypebeast, Wikipedia, and fan sites. The company also tells me that \"some systems\" of the feature use machine learning to generate these summaries, which means About the Song is, in part, AI-generated.  \n    \n            \n            \n                                        Credit: Spotify\n                    \n    \nAs with many of Spotify's new features, About the Song is only available for Premium subscribers. At this time, it's also limited to English accounts in the U.S., UK, Canada, Ireland, New Zealand, and Australia. If you pay for Spotify in one of these regions, the feature is exceptionally easy to find. When you're listening to a song, just scroll down on the page until you see the \"About the Song\" card. If you don't see it, that song likely doesn't support the feature. Some songs will only have one summary card, but others may have more. If so, you'll see icons in the top right of the card window telling you which card you're reading. You can swipe left on the card to open the next. \nI've seen songs with as many as four of these cards, though it's possible some songs have even more. Some of those are all summarized from the same source—say, one Wikipedia article—while others pull from multiple sources to generate multiple About the Song cards. There are thumbs-up and thumbs-down options on each card to rate the summary, implying these are AI-generated. The summaries appear to be static once generated though—when I quit the app and return, the summaries are the same. I'd be curious to know if the summaries are the same for everyone who chooses a song, or if they're generated for each individual listener.\n            \n                What do you think so far?\n            \n        \nSpotify has had a busy week. On Thursday, one day before announcing \"About the Song,\" the company revealed its plans to start selling physical paper books, which sync with its digital audiobooks. The day before that, Spotify revamped its lyrics feature, including the option to download lyrics for offline viewing. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Spotify Will Now Use AI to Tell You the Meaning Behind Your Favorite Songs",
      "image": [
        "https://lifehacker.com/imagery/articles/01KGSTD1SZQ3KGA0KRYY8YS9BH/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-06T16:30:17.000Z",
      "dateModified": "2026-02-06T16:30:17.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
    "url": "https://lifehacker.com/tech/malicious-ai-assistants-google-chrome?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T20:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Zooey Liao/Lifehacker/Getty Images\n                            \n            \n                Key Takeaways\n                                            AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information.\n                                            In the latest campaign—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants.\n                                            Always vet extensions carefully—don't just rely on a familiar name like ChatGPT.\n                                    \n            \n    Table of Contents\n    \n        \n        AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information. Researchers at security firm LayerX have analyzed multiple campaigns in recent months involving malicious browser extensions, including the widespread GhostPoster scheme targeting Chrome, Firefox, and Edge. In the latest one—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants, including Claude, ChatGPT, Gemini, Grok, and \"AI Gmail.\" Collectively, these fakes have more than 300,000 installs. Fake Chrome extensions look like popular AI assistantsThe Chrome extensions identified as part of AiFrame look like legitimate AI tools commonly used for summarizing, chat, writing, and Gmail assistance. But once installed, they grant attackers wide-ranging remote access to the user's browser. Some of the capabilities observed include voice recognition, pixel tracking, and email content readability. Researchers note that extensions are broadly capable of harvesting data and monitoring user behavior. Though the extensions analyzed by LayerX used a variety of names and branding, all 30 were found to have the same internal structure, logic, permissions, and backend infrastructure. Instead of implementing functionality locally on the user's device, they render a full-screen iframe that loads remote content as the extension's interface. This allows attackers to push changes silently at any time without a requiring Chrome Web Store update. \nLayerX has a complete list of the names and extension IDs to refer to. Because threat actors use familiar and/or generic branding, such as \"Gemini AI Sidebar\" and \"ChatGPT Translate,\" you may not be able to identify fakes at first glance. If you have an AI assistant installed in Chrome, go to chrome://extensions, toggle on Developer mode in the top-right corner, and search for the ID below the extension name. Remove any malicious add-ons and reset passwords. \n            \n                What do you think so far?\n            \n        \nAs BleepingComputer reports, some of the malicious extensions have already been removed from the Chrome Web Store, but others remain. Several have received the \"Featured\" badge, adding to their legitimacy. Threat actors have also been able to quickly republish add-ons under new names using the existing infrastructure, so this campaign and others like it may persist. Always vet extensions carefully—don't just rely on a familiar name like ChatGPT—and note that even AI-powered add-ons from trusted sources can be highly invasive. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T20:00:00.000Z",
      "dateModified": "2026-02-13T20:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "YouTube Finally Released an App for the Apple Vision Pro",
    "url": "https://lifehacker.com/tech/youtube-app-for-apple-vision-pro?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH9SVASV7VEXA78TP418XENK/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T21:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Stephen Johnson\n                  ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Stephen Johnson\n                            \n        \n            Stephen Johnson\n                \n                                            Senior Staff Writer\n                                    \n            \n            \n        \n            ExperienceStephen Johnson is a senior staff writer at Lifehacker covering pop culture and technology, including the columns “The Out-of-Touch Adults’ Guide to Kid Culture” and “What People Are Getting Wrong This Week.”\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 12, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: YouTube\n                            \n            \n                Key Takeaways\n                                            A YouTube app is now available for Apple Vision Pro.\n                                            Users can stream every video on YouTube, even 8K video.\n                                            The standalone YouTube app was designed with Vision's spatial computing in mind.\n                                    \n            \n    Table of Contents\n    \n        \n        YouTube has finally come to Apple Vision Pro. YouTube for Vision OS is a free, standalone app that lets users log into their existing YouTube accounts through their Vision headsets and stream videos like they would expect to, including standard videos, 180° videos, 360° videos, and YouTube Shorts. Vision Pro M5 users can stream 8K videos, and premium YouTube members can download videos directly to their headsets, a must for long flights.  Google, YouTube's parent company, has apparently been working on the app for a while. In 2024, a spokesperson confirmed that a standalone Vision Pro app was \"on our roadmap,\" but until today, the only way Vision users could watch YouTube on their headsets was through the Safari web browser. The new YouTube app is designed to fit into Vision's spatial computing environments. \"Rather than just responding to different screen sizes, we needed something that responds to different spaces, volumes and use cases,\" YouTube's senior UX designer Brendan Polley told Apple. \"We built an entirely new design system that isolated core elements—comments, the play button, 'like' and 'dislike'—to fit any layout.\"\n            \n                What do you think so far?\n            \n        \nHaving downloaded the app, it works exactly as intended. If you're looking for something that demonstrates Vision Pro's immersive video capabilities, you should check out the just-released 360° videos from the Milano Cortina winter Olympics on NBC's channel. Immersive luge is terrifying! \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "YouTube Finally Released an App for the Apple Vision Pro",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH9SVASV7VEXA78TP418XENK/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T21:30:00.000Z",
      "dateModified": "2026-02-12T21:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
    "url": "https://lifehacker.com/health/ai-chatbots-are-even-worse-at-medical-advice-than-we-thought?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T15:00:00.000Z",
    "description": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n            ",
    "body": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n                    Even when they have the “right” information, they can lead you astray.\n            \n                        \n    \n                    \n        \n        \n        \n    \n                                Beth Skwarecki\n                            \n        \n            Beth Skwarecki\n                \n                                            Senior Health Editor\n                                    \n            \n            \n        \n            ExperienceBeth Skwarecki is Lifehacker’s Senior Health Editor, and holds certifications as a personal trainer and weightlifting coach. She has been writing about health for over 10 years.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                            \n        \n        \n        February 12, 2026\n            \n            \n                        Credit: Jeffrey Hazelwood/Lifehacker/Getty Images\n                            \n    \n        \n        It’s tempting to think that an LLM chatbot can answer any question you pose it, including those about your health. After all, chatbots have been trained on plenty of medical information, and can regurgitate it if given the right prompts. But that doesn’t mean they will give you accurate medical advice, and a new study shows how easily AI’s supposed expertise breaks down. In short, they are even worse at it than I thought.In the study, researchers first quizzed several chatbots about medical information. In these carefully conducted tests, ChatGPT-4o, Llama 3, and Command R+ correctly diagnosed medical scenarios an impressive 94% of the time—though they were able to recommend the right treatment a much less impressive 56% of the time. But that wasn’t a real-world test for the chatbots medical utility. The researchers then gave medical scenarios to 1,298 people, and asked them to use an LLM to figure out what might be going on in that scenario, plus what they should do about it (for example, whether they should call an ambulance, follow up with their doctor when convenient, or take care of the issue on their own). The participants were recruited through an online platform that reported it verifies that research subjects are real humans and not bots themselves. Some participants were in a control group that was told to research the scenario on their own, and not using any AI tools. In the end, the no-AI control group did far better than the LLM-using group in correctly identifying medical conditions, including most serious “red flag” scenarios. How a chatbot with “correct” information can lead people astrayAs the researchers write, “Strong performance from the LLMs operating alone is not sufficient for strong performance with users.” Plenty of previous research has shown that chatbot output is sensitive to the exact phrasing people use when asking questions, and that chatbots seem to prioritize pleasing a user over giving correct information. Even if an LLM bot can correctly answer an objectively phrased question, that doesn’t mean it will give you good advice when you need it. That’s why it doesn’t really matter that ChatGPT can “pass” a modified medical licensing exam—success at answering formulaic multiple choice questions is not the same thing as telling you when you need to go to the hospital.  The researchers analyzed chat logs to figure out where things broke down. Here are some of the issues they identified:The users didn’t always give the bot all of the relevant information. As non-experts, the users certainly didn’t know what was most important to include. If you’ve been to a doctor about anything potentially serious, you know they’ll pepper you with questions to be sure you aren’t leaving out something important. The bots don’t necessarily do that. The bots “generated several types of misleading and incorrect information.” Sometimes they ignored important details to narrow in on something else; sometimes they recommended calling an emergency number but gave the wrong one (such as an Australian emergency number for U.K. users).Responses could be drastically different for similar prompts. In one example, two users gave nearly identical messages about a subarachnoid hemorrhage. One response told the user to seek emergency care; the other said to lie down in a dark room. People varied in how they conversed with the chatbot. For example, some asked specific questions to constrain the bot’s answers, but some let the bot take the lead. Either method could introduce unreliability into the LLM's output.Correct answers were often grouped with incorrect answers. On average, each LLM gave 2.21 answers for the user to choose from. People understandably did not always choose correctly from those options. Overall, people who didn't use LLMs were 1.76 times more likely to get the right diagnosis. (Both groups were similarly likely to figure out the right course of action, but that's not saying much—on average, they only got it right about 43% of the time.) The researchers described the control group as doing \"significantly better\" at the task. And this may represent a best-case scenario: the researchers point out that they provided clear examples of common conditions, and LLMs would likely do worse with rare conditions or more complicated medical scenarios. They conclude: “Despite strong performance from the LLMs alone, both on existing benchmarks and on our scenarios, medical expertise was insufficient for effective patient care.”\n            \n                What do you think so far?\n            \n        \nChatbots are a risk for doctors, tooPatients may not know how to talk to an LLM, or how to vet its output, but surely doctors would fare better, right? Unfortunately, people in the medical field are also using AI chatbots for medical information in ways that create risks to patient care. ECRI, a medical safety nonprofit, put the misuse of AI chatbots in the number one spot on its list of health technology hazards of 2026. While the AI hype machine is trying to convince you to give ChatGPT your medical information, ECRI correctly points out that it’s wrong to think of these chatbots as having human personalities or cognition: “While these models produce humanlike responses, they do so by predicting the next word based on large datasets, not through genuine comprehension of the information.”ECRI reports that physicians are, in fact, using generative AI tools for patient care, and that research has already shown the serious risks involved. Using LLMs does not improve doctors’ clinical reasoning. LLMs will elaborate confidently on incorrect details included in prompts. Google’s Med-Gemini model, created for medical use, made up a nonexistent body part whose name was a mashup of two unrelated real body parts; Google told a Verge reporter that the mistake was a “typo.”  ECRI argues that “because LLM responses often sound authoritative, the risk exists that clinicians may subconsciously factor AI-generated suggestions into their judgments without critical review.”Even in situations that don’t seem like life-and-death cases, consulting a chatbot can cause harm. ECRI asked four LLMs to recommend brands of gel that could be used with a certain ultrasound device on a patient with an indwelling catheter near the area being scanned. It’s important to use a sterile gel in this situation, because of the risk of infection. Only one of the four chatbots identified this issue and made appropriate suggestions; the others just recommended regular ultrasound gels. In other cases, ECRI’s tests resulted in chatbots giving unsafe advice on electrode placement and isolation gowns. Clearly, LLM chatbots are not ready to be trusted to keep people safe when seeking medical care, whether you’re the person who needs care, the doctor treating them, or even the staffer ordering supplies. But the services are already out there, being widely used and aggressively promoted. (Their makers are even fighting in the Super Bowl ads.) There’s no good way to be sure these chatbots aren’t involved in your care, but at the very least we can stick with good old Dr. Google—just make sure to disable AI-powered search results. \n            \n    \n        The Daily Newsletter\n            Ready to do everything better?\n        \n        \n            Jordan Calhoun\n            \n        \n        Get daily tips, tricks, and tech guides from our expert team.\n            The Daily NewsletterReady to do everything better?\n                    Get daily tips, tricks, and tech guides from our expert team.\n            \n        \n    \n                        \n                \n            \n                    \n                                            \n                \n            \n                Beth Skwarecki\n                                    Senior Health Editor\n                                \n                                            Covering health, fitness tech, home gym equipment, and more.\n                                    \n                Read Beth's full bio\n                            \n        \n                \n                                            \n    More by Beth\n        \n        \n                        \n                \n                    \n                \n            \n        \n                    \n                \n                    \n                \n            \n        \n                                        \n            \n                                    \n                                            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T15:00:00.000Z",
      "dateModified": "2026-02-12T15:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "I Tried Malwarebytes' ChatGPT App, and It's Actually Good at Detecting Scams",
    "url": "https://lifehacker.com/tech/malwarebytes-chatgpt-app-impressions?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KGSJ8K8YYSPM82BZDG46DYXW/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-06T15:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                David Nield\n                      ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                David Nield\n                            \n        \n            David Nield\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceDavid Nield is a technology journalist from Manchester in the U.K. who has been writing about gadgets and apps for more than 20 years. He has a bachelor's degree in English Literature from Durham University, where he also spent a term as editor of the award-winning student newspaper Palatinate. His journalism career started in print media, where he contributed to and edited several technology magazines and bookazines sold in the U.K. and internationally. More recently, he has worked as a freelancer for some of the biggest technology publications on the web, covering everything from on-the-ground reporting about product launches, to detailed explainers and how-to guides on apps, gadgets, and platforms. His expertise covers broad areas of consumer tech, including smartphones, laptops, wearables, and AI.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 6, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Sharaf Maksumov / Lifehacker\n                            \n    Table of Contents\n    \n        \n        A few months ago, ChatGPT got an app store of its own, which means you can access tools like Photoshop and Apple Music right inside the ChatGPT prompt box. Now Malwarebytes has joined the ChatGPT app store, which means you can get some expert help when investigating web links, emails, text messages, domains, and phone numbers you think might be suspicious.The app is free to use for everyone, whether or not they're signed up to a paid ChatGPT subscription, and you can enable the tool via the ChatGPT app store or by entering the prompt \"Malwarebytes, is this a scam?\" Once you've used the app for the first time, you can access it again via the + (plus) button on the prompt box.Malwarebytes' ChatGPT app can test links, sites, and phone numbers\n    \n            \n            Malwarebytes will do a deep security dive into links you provide.\n                                        Credit: Lifehacker\n                    \n    \nYou can paste just about anything you like into a conversation with the Malwarebytes plugin, but there are certain approaches that scammers will often take—including links contained in phishing emails—that make for good candidates to test this thing out. I dived deep into my email spam folder to find some URLs to test Malwarebytes on, and gave it a few trustworthy web addresses as well—you just copy the link into the prompt box and ask the app for an assessment.\nMalwarebytes successfully sifted out the scam links from the safe ones, even when it didn't have any specific information in its databases about the links I was providing. When it was unsure, it said so, with lots of extra context: For example, for one URL I was told the address was \"a legitimate email security and tracking service used by companies to rewrite links\" but one that scammers also used to conceal the link destination.You also get an assessment of the domain name: When given a link to a Lifehacker article, the plugin correctly identified that it was a legitimate domain with a registered owner, even though it didn't have any specific information about the URL. Malwarebytes was also able to spot domain redirecting, a trick frequently used by scammers.Phone numbers can be given to Malwarebytes as well: When I tested this out with a few scam calls I've had, these numbers were correctly identified as coming from scammers or at least being suspicious. I like the way the app gives you some context to its thinking (explaining how spam call centers work, for example), and will also offer up advice about next steps and how to stay safe.Something else I appreciated was that the Malwarebytes app has a memory inside ChatGPT: If you post a series of links and numbers in the same chat thread, as I did, then it will try and put them all in context (explaining why one URL is potentially more dangerous than another, for example).The Malwarebytes ChatGPT app can also look at messages and emails\n    \n            \n            You'll get a list back of red flags in email and text message content.\n                                        Credit: Lifehacker\n                    \n    \nYou can also give the Malwarebytes app some text you've come across in an email or text message and get a verdict on this too—you can even type in a transcript of a conversation you're having on the phone, if you want. The plugin will scan the text for phrasing that scammers often use and will alert you of any other red flags.\n            \n                What do you think so far?\n            \n        \nI tried this out with a variety of spammy text, and again Malwarebytes scored highly in terms of recognizing anything dodgy. As before, if it came across something it wasn't sure about, it would explain the reasons why and suggest some next steps. The responses also include some detail on why different scam approaches are taken and why they sometimes work, and how they might escalate—so if you get a message purporting to be from a family member asking for help, Malwarebytes tells you why these scams are common and how they're used to steal identities or money.It's an intelligent system, in that it'll ask you questions about the texts or emails you've received: If it's not sure about something, you'll be told about extra checks you can run (like looking at the \"reply to\" address on an email). However, the usual ChatGPT sycophancy does start to grate a bit, as you're constantly told that you're doing the right thing and that you're right to be suspicious.The app taps into Malwarebytes Threat Intelligence, so it should be able to keep you protected against the latest threats (making it more helpful than a Google search or just a regular ChatGPT query). From the examples I used at least, it comes across as a security tool that's accurate, comprehensive, and easy to use—one that's well worth keeping close at hand if you come across potential scams you're not sure about.Disclosure: Ziff Davis, Mashable’s parent company, in April 2025 filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "I Tried Malwarebytes' ChatGPT App, and It's Actually Good at Detecting Scams",
      "image": [
        "https://lifehacker.com/imagery/articles/01KGSJ8K8YYSPM82BZDG46DYXW/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-06T15:00:00.000Z",
      "dateModified": "2026-02-06T15:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "How to Stream Super Bowl LX Without Cable",
    "url": "https://lifehacker.com/entertainment/how-to-watch-super-bowl-lx-without-cable-2026?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01HN3S83XW1VRJP7THNSSWMSCA/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-06T13:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 6, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n    We may earn a commission from links on this page.\n    \n            Credit: San Francisco Chronicle/Hearst Newspapers / Contributor via Getty Images\n                            \n    Table of Contents\n    \n        \n        Super Bowl LX kicks off on Sunday, Feb. 8 at 6:30 p.m. ET. This year's broadcast, hosted on NBC, includes pregame coverage starting at 1 p.m. ET and a pregame show featuring Green Day at 6 p.m. ET. Even if you don't have cable, there are a few ways, both paid and free, that you can watch all the action live from Levi's Stadium in Santa Clara, CA. You can watch Super Bowl LX on PeacockThe game will be shown on NBC-owned streaming service Peacock, which is available on the web as well as iOS, Android, smart TVs, and gaming consoles. Peacock doesn't have a free trial, and you have to subscribe to the middle tier—Peacock Premium, which costs $11 per month—to get live sports. Or you can pay $17 per month for ad-free Premium Plus (live sports still have ads). There are a few ways to get around subscribing at full price. Peacock Premium is a perk of both a Walmart+ subscription ($98 per year after a 30-day free trial) and an Instacart+ subscription ($99 per year after a 14-day free trial), so if you have or would benefit from either of these services, now may be the time to sign up. Students qualify for a discounted rate of $6 per month for Peacock Premium. Note that Peacock will also have streaming and on-demand coverage of the Winter Olympics, which begin this weekend, so subscribing for a month may be well worth $11. \nSign up for a live TV streaming serviceThere are a handful of streaming services with live TV that include NBC. Before signing up, check the channel listings for your zip code to confirm NBC is available in your local market. DirectTV Stream: $50 per month for the first month with current promotions, 5-day free trialHulu + Live TV: $90 per month, 3-day free trial (includes ads on Hulu)YouTube TV: Currently $70 per month with promo, 21-day free trial for new usersSling TV (in limited markets): $46 per monthWhen signing up for a free trial, make sure you know when you'll be billed for a paid subscription and cancel before your trial expires. The game will be available in 4K for YouTube TV subscribers (included in the free trial but at an additional fee or at a higher tier with paid plans). The Spanish-language broadcast will be on Telemundo, which is also available on most live TV streaming services. \n            \n                What do you think so far?\n            \n        \nHow to watch Super Bowl LX over the airAnother free (ish) way to get the game is with over-the-air (OTA) TV. Of course, this requires you to invest in a digital TV antenna and have a place to put it that gets good reception. You should check the FCC's reception map to see what signals are available in your area and try your antenna out before game day. Your mileage may vary, so if you want a stress-free watch experience, this probably isn't the best option. Other ways to watch the Super BowlYou can also watch the game through the NFL+ mobile app—a subscription costs $7 per month. Fubo previously carried NBC channels but has been in a contract dispute with NBCUniversal since last 2025. \n            \n    \n    \n        The Daily Newsletter\n            Ready to do everything better?\n        \n        \n            Jordan Calhoun\n            \n        \n        Get daily tips, tricks, and tech guides from our expert team.\n            The Daily NewsletterReady to do everything better?\n                    Get daily tips, tricks, and tech guides from our expert team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "How to Stream Super Bowl LX Without Cable",
      "image": [
        "https://lifehacker.com/imagery/articles/01HN3S83XW1VRJP7THNSSWMSCA/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-06T13:30:00.000Z",
      "dateModified": "2026-02-06T13:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Study's List of the Most Invasive AI Browser Extensions Includes a Few You Probably Use",
    "url": "https://lifehacker.com/tech/invasive-ai-browser-extensions-study-grammarly?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH0F0DCSGGX7YXWDCMW41CCN/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-09T15:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Smith Collection/Gado / Archive Photos via Getty Images\n                            \n            \n                Key Takeaways\n                                            A host of AI-powered browser extensions that have been installed by tens of millions of users may also be invading your privacy.\n                                            The most invasive extensions fall in the programming and mathematical aid category followed closely by meeting assistants and audio transcribers.\n                                            When adding an extension (or installing an app or program), carefully review the permissions requested.\n                                    \n            \n    Table of Contents\n    \n        \n        Browser extensions, even ones from trustworthy sources, are not without privacy and security risks. I've written before about add-ons that manage to slip through official store safeguards and even some that \"wake up\" as malware after operating normally for several years, so it should come as no surprise that a host of AI-powered browser extensions—collectively  installed by tens of millions of users—may also be invading your privacy. Researchers at data removal service Incogni looked at browser extensions available in the Chrome Web Store that included \"AI\" in their name or description and employed AI as part of their core functionality. By analyzing the data collected and permissions required, they assessed both how likely extensions are to be used maliciously and their potential to cause significant damage if compromised.AI-powered browser extensions collect extensive user dataIncogni found that website content, such as text, images, sounds, videos, and hyperlinks, was the most commonly collected data type (by nearly a third of AI-powered extensions). More than 29% of extensions investigated harvest personally identifiable information (PII)—name, address, email, age, identification number, for example—from users. Other forms of data collected include user activity, authentication information, personal communication, location, financial and payment information, web history, and health information. \nThe most invasive extensions fall in the programming and mathematical aid category (such as Classology AI and StudyX), followed closely by meeting assistants and audio transcribers. Writing and personal assistants also pose privacy risks—and many of these are also among the most downloaded AI-powered extensions in Chrome. How popular AI-powered Chrome extensions stack up on privacyIncogni also assigned \"privacy-invasiveness\" scores to the most downloaded AI-powered extensions, a combination of the amount of data collected and both general and sensitive permissions required: \n            \n                What do you think so far?\n            \n        \nGrammarly: AI Writing Assistant and Grammar Checker App (tied for #1)Quillbot: AI Writing and Grammar Checker Tool (tied for #1)Sider: Chat wiht all AI (tied for #3)AI Grammar Checker & Paraphraser — LanguageTool (tied for #3)Google Translate (tied for #4)WPS PDF — Read, Edit, Fill, Convert, and AI Chat PDF with Ease (tied for #4)Monica: All-in-One AI Assist  (tied for #4)AI Chat for Google (tied for #4)Immersive Translate — Translate Web & PDFChatGPT searchGrammarly and Quillbot were found to collect PII and website content as well as location data like region, IP address, and GPS coordinates. Grammarly also harvest user activity through network monitoring, clicks, mouse and scroll positions, and keystroke logging. While both also require sensitive permissions—such as the ability to inject code into websites and access active browser tabs—they have a relatively low risk of being used maliciously. How to protect your personal informationBrowser extensions that use AI aren't inherently bad, but you should be aware of what information they are collecting and what permissions they are requiring. The most common type of sensitive permissions required are scripting, which allows the extension to interact with pages as you navigate online, as well as activeTab, which lets it read or modify the page for the current session. When adding an extension (or installing an app or program), carefully review the permissions requested. If they aren't essential to the extension's functionality–or if they are but don't seem justified—you may be putting your data or device at risk by allowing them. As Incogni points out, users have to decide how much privacy to sacrifice in order to use apps and services. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Study's List of the Most Invasive AI Browser Extensions Includes a Few You Probably Use",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH0F0DCSGGX7YXWDCMW41CCN/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-09T15:30:00.000Z",
      "dateModified": "2026-02-09T15:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "YouTube TV Will Soon Offer a Cheaper, Sports-Only Plan",
    "url": "https://lifehacker.com/entertainment/youtube-tv-sports-only-plan?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH1Y33RZNJJK1NXJPPWZEY6E/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-09T20:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                            \n        \n            Justin Pot\n                \n                                                                        Editorial Author\n                                                            \n            \n            \n        \n            ExperienceJustin Pot is a freelance journalist who helps people get more out of technology. If you've ever searched online for a specific tech problem you've read Justin's work, because he's been doing it for a long time. Since 2009, he has written tutorials and essays about technology for outlets including WIRED, The Atlantic, PCMag, Popular Science, How-to Geek, and The Wall Street Journal. For Lifehacker, he mostly writes about software, with a particular focus on open source programs and indie apps. Justin has a bachelor's degree in Communications and International Relations. He once worked in marketing for a software company and hated it, but it did teach him a lot about why software tends to get worse over time in large companies. He lives in Oregon with his cat (and his wife). He enjoys brewing beer, exploring nature, and spending time with friends. You can follow Justin on Mastodon and Bluesky, or sign up for his newsletter, Connectivity.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: NurPhoto / Contributor via Getty Images\n                            \n            \n                Key Takeaways\n                                            YouTube TV will soon offer a number of new plans with more tailored options for less than the current subscription price.\n                                            Options will include a sports-only package, an entertainment-focused package, and at least 10 others.\n                                            YouTube TV currently costs $82.99 per month, but these new plans seem to cost about $10-$30 less per month, depending on the plan.\n                                    \n            \n    Table of Contents\n    \n        \n        Traditional TV works best for live events, and for many people, that means sports. Most of the online services providing access to traditional TV, however, don't allow you to only subscribe to sports. That's going to change.Today YouTube TV announced new plans that are a little bit cheaper than the current cost of $82.99 per month. Among them is a $64.99-per-month Sports plan, which includes access to the big national sports channels including FS1, NBC Sports Network, and all of the ESPN channels, along with access to network television. Basically, if a game is broadcast nationally, this package should give you access. And it will eventually give you access to many out-of-market—the post mentions that ESPN Unlimited will be part of the bundle starting in the fall.The new plan is only an $18 discount over the \"main\" YouTube TV plan, but if you're already paying for YouTube TV and are only ever watching sports, this could be a nice discount, particularly if you get access to ESPN Unlimited. \nThere are a few other discounted plans included in the announcement: The Sports + News package adds CNBC, Fox News, MSNow (formerly MSNBC), CNN, and more to the sports bundle, and costs $71.99. That's only $11 cheaper than the full plan, but is still a nice discount if you were only watching sports and news.\n            \n                What do you think so far?\n            \n        \nBut maybe the biggest savings are for people who don't want to watch sports at all. The Entertainment plan costs $54.99, which is $28 cheaper than the main plan ($336 cheaper per year). If you only watch entertainment channels, with no news or sports, this is the package to look into.There will be more than 10 plans like this rolling out in the next few weeks, according to YouTube TV. I've long dreamed of a world where I could pay only for the cable channels I care about at an affordable rate. This isn't perfect, but it's a bit closer than what YouTube TV offered before.\n            \n    \n    \n        The Daily Newsletter\n            Ready to do everything better?\n        \n        \n            Jordan Calhoun\n            \n        \n        Get daily tips, tricks, and tech guides from our expert team.\n            The Daily NewsletterReady to do everything better?\n                    Get daily tips, tricks, and tech guides from our expert team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "YouTube TV Will Soon Offer a Cheaper, Sports-Only Plan",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH1Y33RZNJJK1NXJPPWZEY6E/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-09T20:00:00.000Z",
      "dateModified": "2026-02-09T20:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "YouTube Music Just Put Lyrics Behind the Paywall",
    "url": "https://lifehacker.com/tech/youtube-music-lyrics-paywall?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH1N1V7RDJPK83P0W7Y6EFAK/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-09T19:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: miss.cabul/Shutterstock\n                            \n            \n                Key Takeaways\n                                            YouTube Music is making lyrics a Premium-only feature.\n                                            Free users will have a limited number of lyrics views each month.\n                                            Other free music services that offer lyrics, including Spotify.\n                                    \n            \n    Table of Contents\n    \n        \n        My subscription fatigue is real, but at the end of the day, I do recognize that companies need to make money. If one of them manages to put together a compelling package of features for a reasonable price, I can decide whether or not I find that value worth the money. That's fine. What isn't fine is offering a feature for free for years, and then suddenly deciding to lock it behind a paywall. It seems YouTube didn't get that memo. Starting on Saturday, outlets like 9to5Google began reporting that YouTube Music had started to remove the ability to vie lyrics for free users. If you want a full lyrics experience, you'll need to subscribe to either YouTube Music Premium, or YouTube Premium (the latter includes Music Premium). The service hasn't cut these users off cold turkey. According to anecdotal user experiences, YouTube Music is opening lyrics access to free users for five songs per month. Once they play song number six, they'll only have access to the first two lines of each song, as the rest of the lyrics will be blurred out. These users will have to wait until the following month to view another five songs.  There appears to be no confusion about why the lyrics are blurred out, either. When you switch to the \"Lyrics\" tab on YouTube Music as a free account, a new banner appears, telling you how many views you have remaining. Beneath this, you'll see the option to \"Unlock lyrics with Premium,\" a clear message that, unless you pay up, you only get a limited number of lyrics views. This, apparently, follows a months-long period where YouTube Music tested lyrics as a Premium-only feature. \nFor what it's worth, when I tried to see what the current lyrics situation looks like on my free YouTube Music app, the service gave me two weeks of Premium for free, with no option to skip it. That's, um, nice of YouTube, but since I already have an Apple Music subscription, the only real consequence here is that I can't test these new lyrics limitations out.  Free music services that offer lyricsI don't see the strategy here. Lyrics aren't something I feel people would feel compelled to pay for specifically—but they might be annoyed enough at losing them to look elsewhere. Spotify, for example, offers a full lyrics experience for free users. It was only last week the company added offline lyric downloads for Premium users only, but, even then, that's adding a feature for the subscription tier—not taking away an existing feature from free users. \n            \n                What do you think so far?\n            \n        \nIt's not just Spotify, either. Other free music streaming services offers lyrics, as well, including Pandora, Amazon Music Free, and Freefy. These are largely radio services, so you may not have as much flexibility as you would have with YouTube Music free—but, hey, you at least have lyrics. Losing lyrics isn't the end of the world for free YouTube Music users, either. Just about any song's lyrics can be found on the internet. Sometimes, the lyrics show up in a Google search window without you needing to even click a link. Otherwise, sites like Genius and AZLyrics do exist. It's just a bummer YouTube feels the need to gatekeep the in-app experience.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "YouTube Music Just Put Lyrics Behind the Paywall",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH1N1V7RDJPK83P0W7Y6EFAK/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-09T19:00:00.000Z",
      "dateModified": "2026-02-09T19:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Apple and Google Just Made It Easier to Switch Between iPhone and Android",
    "url": "https://lifehacker.com/tech/apple-and-google-just-made-it-easier-to-switch-between-iphone-and-android?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KBZW51YD9RTK9TT6NWP3RZ28/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T19:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 12, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Mr.Mikla / Shutterstock.com\n                            \n            \n                Key Takeaways\n                                            Apple and Google actually worked together on a method to make switching between iPhone and Android easier.\n                                            With iOS 26.3, iPhone users can access the tool to simplify the process of transferring data like photos, messages, contacts and more.\n                                            However, Apple says health data, devices paired with Bluetooth, and \"protected items\" cannot be transferred.\n                                    \n            \n    Table of Contents\n    \n        \n        When it's time to buy a new car, you don't necessarily need to stick with the one you had before. You don't lose your cloud-based photos by switching from Toyota to Subaru, nor will your friends yell at you for ruining the group chat by buying a Kia. That's not the case with smartphones: When you buy an iPhone, it's tough to switch away from it. The same goes for Android: While it's easy enough to switch within the Android ecosystem, such as between Pixel or Galaxy, moving from Android to iPhone can also be a pain. Tech companies tend to make it tempting to stick with their platform, and introduce friction when you try to leave. That, of course, is entirely business-based. Apple hasn't traditionally made it easy to move to Android, because, well, you might actually do it. It doesn't have to be this way, either. There's nothing inherent to smartphones that should make it so challenging to break out of any particular ecosystem. All it takes is some intentional design: If smartphones were made to be traded, you could migrate from one to another, without worrying about losing pictures, messages, or any other important data or processes. As it happens, that intentional design is here. Apple and Google actually worked together to make it easier to transfer data between iPhone and Androids, which makes switching between the two platforms more seamless. \nNews first broke about this partnership back in December, and, at that time, Google released some of this progress as part of the latest Android Canary, the company's earliest pre-release software. Shortly after, Apple released the first beta for iOS 26.3, which featured the transfer tool. Now, iOS 26.3 is here, and with it, an easier way to switch from iPhone to a device made by Google, Samsung, or any other Android OEM.   How to use the new iPhone-to-Android option in iOS 26.3The feature seems easy enough to use. Once you update your iPhone to iOS 26.3, you can head to Settings > General, then scroll down to \"Transfer or Reset iPhone.\" Tap this option, then choose \"Transfer to Android.\" Here, iOS will present a pop-up, telling you to place your iPhone next to your new Android device, where you can transfer photos, messages, and apps, among other data points. (That said, health data, devices paired with Bluetooth, and \"protected items\" cannot be transferred.)You'll need to make sure both devices are running the latest updates, are connected to wifi, and have Bluetooth enabled. However, Apple also says your Android device should be in the \"setup process,\" which means you likely won't be able to use this feature if your Android phone is already set up. From here, your iPhone will ask you to scan a QR code that should appear on your Android device. Alternatively, you'll be able to tap \"Other Options\" on your iPhone to enter the Session ID and Pairing Code that should appear on your Android.    \n            \n                What do you think so far?\n            \n        \nNow, you can choose the data you want to transfer, including photos, contacts, calendars, call history, and messages. Tap \"Continue\" once complete, then choose to transfer your eSIM, if applicable. (You'll need to double-click the side of your iPhone when prompted to complete the eSIM transfer.) This works in the other direction too, though Apple says you do still need to use the Move to iOS app on Android—at least until Google sets up a similar protocol on its end.  More flexibility from Apple and Google is better for everyone Apple and Google might not be motivated by charity, of course, as the EU has been cracking down on restrictive practices by tech companies in recent years. But while both companies may see this as a way to lose customers, it's also a way to gain them: Sure, some iPhone users may switch to Android if it's easier to do so, but some Android users may do the reverse for the same reasons.More choice is good for everyone—even if it doesn't guarantee exponential growth to shareholders.  \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Apple and Google Just Made It Easier to Switch Between iPhone and Android",
      "image": [
        "https://lifehacker.com/imagery/articles/01KBZW51YD9RTK9TT6NWP3RZ28/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T19:30:00.000Z",
      "dateModified": "2026-02-12T19:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
    "url": "https://lifehacker.com/tech/23andme-data-breach-payout?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-11T14:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Jennie Book/Shutterstock\n                            \n            \n                Key Takeaways\n                                            If you were affected by 23andMe's data breach, you have just a few more days to claim your compensation.\n                                            \"Extraordinary\" claims may qualify for up to a $10,000 payout.\n                                            Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed.\n                                    \n            \n    Table of Contents\n    \n        \n        If you were affected by 23andMe's data breach—which involved the information of approximately 6.4 million U.S. residents—you have just a few more days to claim your compensation. Following the 2023 credential-stuffing attack, 23AndMe in 2024 agreed to a $30–$50 million payout for impacted consumers. The genetic testing company then filed for Chapter 11 bankruptcy in 2025 (introducing new privacy concerns around the potential sale of customer data).  The courts approved the deal last month, and class members have until Feb. 17 to submit claims related to the cyber incident. How much you'll receive from the 23andMe settlementThere are several tiers of payouts with the 23andMe settlement. Users with an \"extraordinary claim\"—those who experienced identity theft or fraudulent tax filings as a result of the breach—could qualify for up to $10,000 to reimburse verified expenses, including costs for physical or cyber security systems as well as mental health treatment. Claimants who received notices that certain health information was leaked in the breach will be paid up to $165. Eligible data include raw genotype data, health reports (including health predisposition reports, wellness reports, and carrier status reports), and self-reported health conditions. Individuals residing in Alaska, California, Illinois, and Oregon will receive an additional $100 thanks to state privacy laws. Note that payments will likely take time to be distributed. \nThe settlement also provides for five years of identity monitoring services through a customized program called Privacy & Medical Shield + Genetic Monitoring. This is available to all class members regardless of payout.  \n            \n                What do you think so far?\n            \n        \nHow to file a 23andMe claimConsumers who were impacted by the 2023 data breach can file a Cyber Security Incident Claim, which must be submitted by Feb. 17, 2026 (unless you received a notice in 2026 indicating otherwise). To be eligible, you must have been a 23andMe customer between May 1, 2023 and October 1, 2023 and have received a notice (via letter or email) that your information was compromised in the breach. You also must attest that you incurred damages (monetary or non-monetary) as a result of the incident. Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed. To complete a claim, you must provide some personal information as well as details about the harm incurred with supporting documentation, such as bank or credit card statements substantiating losses. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
      "image": [
        "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-11T14:30:00.000Z",
      "dateModified": "2026-02-11T14:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Ring Just Ended Its Controversial Partnership With Flock Safety",
    "url": "https://lifehacker.com/tech/ring-ended-controversial-partnership-with-flock-safety?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHBR0KCJS1YGKPFR454NNA8B/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T15:12:40.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: CC Photo Labs/Shutterstock\n                            \n            \n                Key Takeaways\n                                            In a blog post on Friday, Ring announced the end of its partnership with Flock Safety.\n                                            The announcement follows backlash to Ring's \"Search Party\" Super Bowl ad, which critics have seen as a slippery slope to infringing user privacy.\n                                            Ring says that the Flock Safety integration never went through, so no Ring footage was ever sent to the organization.\n                                    \n            \n    Table of Contents\n    \n        \n        Ring isn't having the week it probably thought it would have. The Amazon-owned company aired an ad on Super Bowl Sunday for \"Search Party,\" its new feature that turns a neighborhood's collective Ring cameras into one network, with the goal of locating lost dogs. Viewers, however, saw this as a major privacy violation—it doesn't take much to imagine using this type of surveillance tech to locate people, not pets.The backlash wasn't just isolated to the ad, however. The controversy reignited criticisms of the company's partnership with Flock Safety, a security company that sells security cameras that track vehicles, notably for license plate recognition. But the partnership with Ring wasn't about tracking vehicles: Instead, Flock Safety's role was to make it easier for law enforcement agencies that use Flock Safety software to request Ring camera footage from users. Agencies could put in a request to an area where a crime supposedly took place, and Ring users would be notified about the request. They didn't have to agree to share footage, however. Law enforcement could already request footage from Ring users, through the platform's existing \"Community Requests\" feature. But this partnership would let agencies make these requests directly through Flock Safety's software. If a user submitted footage following a request, Ring said that data would be \"securely packaged\" by Flock Safety and share to the agency through FlockOS or Flock Nova.\nThat partnership is officially over. On Friday, Ring published a blog post announcing the end of its relationship with Flock Safety. The company said, after a review, the integration \"would require significantly more time and resources than anticipated.\" As such, both parties have agree to cancel the partnership. \n            \n                What do you think so far?\n            \n        \nImportantly, Ring says that since the integration never actually launched, no user footage was ever sent to Flock Safety—despite the company announcing the partnership four months ago. Social media influencers had spread the false claim that Flock Safety was seeding Ring footage directly to law enforcement agencies, such as ICE. While those claims are inaccurate, they were likely fueled by reporting from 404 Media that ICE has been able to access Flock Safety's data in its investigations. Had Ring's partnership with Flock Safety gone ahead, there would be legitimate cause to believe that agencies like ICE could tap into the footage Ring users had shared—even if those users were under the impression they were only sharing footage with local agencies to solve specific cases.  While privacy advocates will likely celebrate this news, the cancelled partnership has no effect on Community Requests. Law enforcement agencies will still be able to request footage from Ring users, and those users will still have a say in whether or not they send that footage. Ring sees the feature as an objective good, allowing users to voluntarily share footage that could help law enforcement solve important cases. In its announcement on Friday, Ring cited the December 2025 Brown University shooting, in which seven users shared 168 video clips with law enforcement. According to Ring, one of those videos assisted police in identifying the suspect's car, which, in turn, solved the case.    \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Ring Just Ended Its Controversial Partnership With Flock Safety",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHBR0KCJS1YGKPFR454NNA8B/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T15:12:40.000Z",
      "dateModified": "2026-02-13T15:12:40.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  }
]