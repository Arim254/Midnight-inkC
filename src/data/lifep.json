[
  {
    "title": "That Political 'Call to Action' Might Actually Be a Scam",
    "url": "https://lifehacker.com/tech/political-call-to-action-might-be-a-scam?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KG65AQZT1BGJW2MP7E11RTHY/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-06T19:00:00.000Z",
    "description": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n            ",
    "body": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n                    No, SendGrid isn't adding a \"Support ICE\" link to your company's emails.\n            \n                        \n    \n                    \n        \n        \n        \n    \n                                Justin Pot\n                            \n        \n            Justin Pot\n                \n                                                                        Editorial Author\n                                                            \n            \n            \n        \n            ExperienceJustin Pot is a freelance journalist who helps people get more out of technology. If you've ever searched online for a specific tech problem you've read Justin's work, because he's been doing it for a long time. Since 2009, he has written tutorials and essays about technology for outlets including WIRED, The Atlantic, PCMag, Popular Science, How-to Geek, and The Wall Street Journal. For Lifehacker, he mostly writes about software, with a particular focus on open source programs and indie apps. Justin has a bachelor's degree in Communications and International Relations. He once worked in marketing for a software company and hated it, but it did teach him a lot about why software tends to get worse over time in large companies. He lives in Oregon with his cat (and his wife). He enjoys brewing beer, exploring nature, and spending time with friends. You can follow Justin on Mastodon and Bluesky, or sign up for his newsletter, Connectivity.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                            \n        \n        \n        February 6, 2026\n            \n            \n                        Credit: Ian Moore/Lifehacker/Adobe Stock\n                            \n    \n        \n        I'm just a humble immigrant, but as a mere (legal!) guest in the U.S., I can't help but notice that the country is rather, shall we say, politically divided these days (sorry if pointing that out seems rude). It seems international scammers have also noticed—and are taking advantage in subtle ways.Recently, investor Fred Benenson blogged about a sophisticated phishing campaign targeting SendGrid users. Phishers sent emails claiming the company was going to add a large \"Support ICE\" button at the bottom of every outgoing email unless users opted out. The emails also featured a large blue button promising to help you disable the message, which, when clicked, naturally led to a fake version of SendGrid that would allow the scammers to steal login information.As scams go, it's not a bad play: Phishing emails work best when they induce a sense of panic—that way you're less likely to think critically about them, and just act. It's not hard to imagine this particular email being effective, given the political climate right now. Say you're running a fair trade coffee company—you wouldn't want a giant \"Support ICE\" button below your signature at this moment in history.But the trick didn't just target left-wing organizations: Variations on the theme claimed the company was going to add pro-LGBT+ and Black Lives Matter banners as well. The differing political messages aren't really the point of the scam, you see—the point is to get business owners to panic about projecting the \"wrong\" values so that they will click the link and give away their login information. Scammers rely on psychological tricks to rope in their victims, all of them designed to get you to stop thinking rationally. Exploiting America's political divide seems to be an excellent way to do that.Political phishing schemes are nothing newThis is just the latest example of a scam that uses politics as a tool. Back in 2020, a fake Black Lives Matter voting campaign spread malware by pretending to be from a county official looking for feedback on the then-exploding political movement. People on both side of the partisan divide ended up clicking through and getting infected.And then there are the campaigns where people pretend to be politicians and beg for donations: Back in 2024 Lifehacker reported on a rash of political donation scams that popped up during the presidential election cycle. That trend is still growing, according to Stacey Wood, a fraud expert writing for Psychology Today. \"What is especially challenging for consumers and voters is that legitimate campaign operatives use many of the same common persuasion techniques employed by scammers,\" she writes.\n            \n                What do you think so far?\n            \n        \nAll of which is to say that international scammers have equal access to American media outlets, are aware of our political divides, and are effective at using them to exploit your emotions in order to steal your money.How to spot a political phishing scamWhat can you do to protect yourself? First, be aware of the tricks that scammers use, and always approach your email inbox with skepticism. Before you click any link from an unfamiliar sender or in an unsolicited email, hover over it to see if it's going to a website that looks legit. Even better: Avoid clicking links altogether, and head to the website for a given service directly by typing it into your browser.Remember, it's easier to fall for a scam than you think, so it pays to be skeptical, especially when you encounter a call to action designed to get you to react in a panic.\n            \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n                        \n                \n            \n                    \n                                            \n                \n            \n                Justin Pot\n                                \n                                            Justin Pot is a freelance journalist who helps people get more out of technology.\n                                    \n                Read Justin's full bio\n                            \n        \n                \n                                            \n    More by Justin\n        \n        \n                        \n                \n                    \n                \n            \n        \n                    \n                \n                    \n                \n            \n        \n                                        \n            \n                                    \n                                            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "That Political 'Call to Action' Might Actually Be a Scam",
      "image": [
        "https://lifehacker.com/imagery/articles/01KG65AQZT1BGJW2MP7E11RTHY/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-06T19:00:00.000Z",
      "dateModified": "2026-02-06T19:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "WhatsApp's Web App Is Getting a Huge Upgrade",
    "url": "https://lifehacker.com/tech/whatsapps-web-app-audio-video-calling?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH4GKF97FEFMJAZ2RWTSK25W/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T20:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Hengki Tj/Shutterstock\n                            \n            \n                Key Takeaways\n                                            WhatsApp is finally rolling out audio and video calls for its web app.\n                                            The option is launching in beta for individual chats, but will roll out to all users soon.\n                                            You can try it now by enrolling in the WhatsApp web app beta.\n                                            WhatsApp is also working on group chat calling in the web app, but this is not yet available in beta.\n                                    \n            \n    Table of Contents\n    \n        \n        While there are a lot of chat apps out there, WhatsApp is the undeniable leader of the pack. The app has over three billion monthly active users, constantly messaging and calling one another across the globe. However, currently those calls are all happening over the mobile app, or maybe the desktop app. Though WhatsApp does have a web app, the service has never supported audio or video calls outside of its downloadable apps—until now. You can now make calls from the WhatsApp web appAccording to WABetaInfo, WhatsApp is slowly rolling out audio and video calls to its web app. At launch, the functionality is coming to individual chats with users who elect to enroll in the WhatsApp web app's beta, but the company plans to roll out the feature to all web app users over the coming weeks.WABetaInfo notes that voice and audio calls work about the same as they do in the WhatsApp desktop app. When you open an individual chat in the web app, you'll now see a video call icon at the top. Click this, and you'll find two options: one to place a voice call, and one to place a video call. These calls are still end-to-end encrypted, as they are on WhatsApp's desktop and mobile apps, meaning only the users who are a part of the calls can hear what's being said. In addition, the web app's video call client supports Screen Share, so you can share a live stream of your computer's screen to another WhatsApp contact. \nWhatsApp is also reportedly working on group chat calls for web app users, as well. While that feature won't roll out alongside individual calls, when it does launch, you'll be able to join group chats with up to 32 people. If you tend to use the WhatsApp desktop or mobile apps, this might not seem like huge news—but it is pretty substantial for a few subsets of WhatsApp users. One, of course, is the user base that just prefers using WhatsApp in their computer's web browser—but the other is Linux users. WhatsApp doesn't actually offer a version of its desktop app for Linux, so those users have to use the web app if they want to run WhatsApp on their computers. That means they've never before been able to place calls without pulling out a mobile device.\n            \n                What do you think so far?\n            \n        \nHow to sign up for the WhatsApp web app betaThis feature will soon roll out to all web app users, but until then, you need to be running the WhatsApp web app beta in order to try it.Luckily, it's pretty easy to get up and running. To start, open the web app, then head to the settings menu, choose \"Help,\" then choose the \"Join beta\" option. This will immediately switch you over to the beta version of the web app. (You should see a \"Beta\" label on your screen.) Now that you're running the beta, should you find the option to place calls in individual chats. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "WhatsApp's Web App Is Getting a Huge Upgrade",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH4GKF97FEFMJAZ2RWTSK25W/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T20:00:00.000Z",
      "dateModified": "2026-02-10T20:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Aggressive Spyware Is Targeting Both Android and iOS Devices",
    "url": "https://lifehacker.com/tech/aggressive-spyware-targeting-android-ios-devices?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH6WXXANC515RHZS40RVFH01/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-11T19:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Credit: Zooey Liao/Lifehacker/Getty Images\n                            \n            \n                Key Takeaways\n                                            A new spyware platform known as ZeroDayRAT is reportedly being sold on Telegram, complete with customer support and updates.\n                                            Once deployed, it allows everything from user profiling and location tracking to live surveillance and financial theft.\n                                            ZeroDayRAT can infect your device only if a malicious binary—an APK on Android or iOS payload—is downloaded and installed.\n                                    \n            \n    Table of Contents\n    \n        \n        Threat actors don't have to work that hard to obtain sophisticated malware to deploy against unsuspecting targets. A new spyware platform known as ZeroDayRAT is reportedly being sold on Telegram, complete with customer support and updates. According to mobile security company iVerify, this aggressive spyware grants full remote control over devices running Android 15 through 16 and iOS versions up to iOS 26. Once deployed, it allows everything from user profiling and location tracking to live surveillance and financial theft. What ZeroDayRAT can gather from your deviceThis spyware has wide-ranging capabilities that, according to iVerify, have traditionally been found on platforms sponsored by state actors. Here's a look at what ZeroDayRAT can do: \nCollect information about the device, such as model, OS, battery, country, lock status, SIM and carrier info, app usage, live activity, and SMS message previews. This allows threat actors to develop user profiles for further targeting.Pull GPS coordinates, capture notifications from apps and systems, and harvest account information, such as usernames and emails. Send SMS messages and receive verification codes to bypass two-factor authentication. Log keystrokes (including biometric unlocks, gestures, and app launches), access the camera and microphone, and screen record.  Log crypto wallet addresses and target banking and payment app credentials via overlay attacks. How to protect against spywareZeroDayRAT can infect your device only if a malicious binary—an APK on Android or iOS payload—is downloaded and installed. These may be distributed through phishing, such as links sent via emails, texts, or messaging platforms, as well as in fake app stores. \n            \n                What do you think so far?\n            \n        \nAll standard guidance for avoiding scams and malware applies: never click links in unsolicited communication, including conversations in apps like Telegram and WhatsApp, and only download apps and extensions from official, trusted sources. Users at high risk of being targeted and anyone who wants an extra layer of security can consider enabling Lockdown Mode (iOS) or Advanced Protection (Android). \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Aggressive Spyware Is Targeting Both Android and iOS Devices",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH6WXXANC515RHZS40RVFH01/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-11T19:00:00.000Z",
      "dateModified": "2026-02-11T19:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "YouTube Music Just Put Lyrics Behind the Paywall",
    "url": "https://lifehacker.com/tech/youtube-music-lyrics-paywall?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH1N1V7RDJPK83P0W7Y6EFAK/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-09T19:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: miss.cabul/Shutterstock\n                            \n            \n                Key Takeaways\n                                            YouTube Music is making lyrics a Premium-only feature.\n                                            Free users will have a limited number of lyrics views each month.\n                                            Other free music services that offer lyrics, including Spotify.\n                                    \n            \n    Table of Contents\n    \n        \n        My subscription fatigue is real, but at the end of the day, I do recognize that companies need to make money. If one of them manages to put together a compelling package of features for a reasonable price, I can decide whether or not I find that value worth the money. That's fine. What isn't fine is offering a feature for free for years, and then suddenly deciding to lock it behind a paywall. It seems YouTube didn't get that memo. Starting on Saturday, outlets like 9to5Google began reporting that YouTube Music had started to remove the ability to vie lyrics for free users. If you want a full lyrics experience, you'll need to subscribe to either YouTube Music Premium, or YouTube Premium (the latter includes Music Premium). The service hasn't cut these users off cold turkey. According to anecdotal user experiences, YouTube Music is opening lyrics access to free users for five songs per month. Once they play song number six, they'll only have access to the first two lines of each song, as the rest of the lyrics will be blurred out. These users will have to wait until the following month to view another five songs.  There appears to be no confusion about why the lyrics are blurred out, either. When you switch to the \"Lyrics\" tab on YouTube Music as a free account, a new banner appears, telling you how many views you have remaining. Beneath this, you'll see the option to \"Unlock lyrics with Premium,\" a clear message that, unless you pay up, you only get a limited number of lyrics views. This, apparently, follows a months-long period where YouTube Music tested lyrics as a Premium-only feature. \nFor what it's worth, when I tried to see what the current lyrics situation looks like on my free YouTube Music app, the service gave me two weeks of Premium for free, with no option to skip it. That's, um, nice of YouTube, but since I already have an Apple Music subscription, the only real consequence here is that I can't test these new lyrics limitations out.  Free music services that offer lyricsI don't see the strategy here. Lyrics aren't something I feel people would feel compelled to pay for specifically—but they might be annoyed enough at losing them to look elsewhere. Spotify, for example, offers a full lyrics experience for free users. It was only last week the company added offline lyric downloads for Premium users only, but, even then, that's adding a feature for the subscription tier—not taking away an existing feature from free users. \n            \n                What do you think so far?\n            \n        \nIt's not just Spotify, either. Other free music streaming services offers lyrics, as well, including Pandora, Amazon Music Free, and Freefy. These are largely radio services, so you may not have as much flexibility as you would have with YouTube Music free—but, hey, you at least have lyrics. Losing lyrics isn't the end of the world for free YouTube Music users, either. Just about any song's lyrics can be found on the internet. Sometimes, the lyrics show up in a Google search window without you needing to even click a link. Otherwise, sites like Genius and AZLyrics do exist. It's just a bummer YouTube feels the need to gatekeep the in-app experience.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "YouTube Music Just Put Lyrics Behind the Paywall",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH1N1V7RDJPK83P0W7Y6EFAK/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-09T19:00:00.000Z",
      "dateModified": "2026-02-09T19:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Google Is Rolling Out Two New Ways to Remove Your Sensitive Data From Search",
    "url": "https://lifehacker.com/tech/google-is-rolling-out-two-ways-to-remove-sensitive-data-from-search?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH27C4ZZ1PTDF491RFHTWZ7P/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T14:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Galeh Nur Wihantara/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Google is rolling out two new tools to request to remove sensitive data from Search.\n                                            The first lets you tell Google to remove government ID numbers like driver's licenses, passports, and Social Security numbers from Search.\n                                            The second makes it easier to request the removal of non-consensual explicit images.\n                                            These tools won't remove this content from the internet, but Google can remove them from Search results.\n                                    \n            \n    Table of Contents\n    \n        \n        Google announced two new ways for users to remove their sensitive information from the web Tuesday morning—or, at least, remove that data from Google Search. The first lets users request that Google remove sensitive government ID information from Search, while the second gives users new tools to request the same for non-consensual explicit images. Google's \"Results about you\" tool is getting an update\n    \n            \n            \n                                        Credit: Google\n                    \n    \nFirst, Google is updating its existing \"Results about you\" tool, which helps users scour the internet for their personal information. Before today, this tool could already locate data points like your name, phone number, email addresses, and home addresses. Following the update, you can now find and request the deletion of search results containing highly sensitive information, including your driver's license, passport, or Social Security number.To launch this tool, click here. If you've never used \"Results about you\" before, you'll need to set it up to tell Google what to look out for. Once you do, you'll be able to add government ID numbers, such as your driver's license, passport, and Social Security number. If Google finds a match, the company will let you know. You can receive an alert from the Google app on your smartphone, which takes you to a summary of what data was found and where. From here, you can choose from \"Request to remove,\" or \"Mark as reviewed.\"  \nUnfortunately, this tool won't remove the data from the websites that are hosting it, but it will eventually remove the search results—sharply reducing the chance that someone will find your data on their own. Google says these changes will roll out in the U.S. over the \"coming days,\" while it is working on bringing them to other countries in the future.  \n            \n                What do you think so far?\n            \n        \nGoogle's simpler way to remove explicit images from Search\n    \n            \n            \n                                        Credit: Google\n                    \n    \nIn addition to these changes, Google is now rolling out a simpler tool for users to request the remove of non-consensual explicit images (NCEI) from Search. If you find such an image on Search, you can tap the three dots on that image, choose \"remove result,\" then \"it shows a sexual image of me.\" You'll have the choice to report whether the photo is real, or is artificially generated, as well, and you can report multiple images at once, if needed. Your requests will all appear in the Results about you hub, so you can track the progress of each.The tool lets you opt-in to an option that will filter additional explicit results in other searches. Google says it will also share links to \"emotional and legal support\" after you submit a request.  \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Google Is Rolling Out Two New Ways to Remove Your Sensitive Data From Search",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH27C4ZZ1PTDF491RFHTWZ7P/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T14:00:00.000Z",
      "dateModified": "2026-02-10T14:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
    "url": "https://lifehacker.com/health/ai-chatbots-are-even-worse-at-medical-advice-than-we-thought?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T15:00:00.000Z",
    "description": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n            ",
    "body": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n                    Even when they have the “right” information, they can lead you astray.\n            \n                        \n    \n                    \n        \n        \n        \n    \n                                Beth Skwarecki\n                            \n        \n            Beth Skwarecki\n                \n                                            Senior Health Editor\n                                    \n            \n            \n        \n            ExperienceBeth Skwarecki is Lifehacker’s Senior Health Editor, and holds certifications as a personal trainer and weightlifting coach. She has been writing about health for over 10 years.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                            \n        \n        \n        February 12, 2026\n            \n            \n                        Credit: Jeffrey Hazelwood/Lifehacker/Getty Images\n                            \n    \n        \n        It’s tempting to think that an LLM chatbot can answer any question you pose it, including those about your health. After all, chatbots have been trained on plenty of medical information, and can regurgitate it if given the right prompts. But that doesn’t mean they will give you accurate medical advice, and a new study shows how easily AI’s supposed expertise breaks down. In short, they are even worse at it than I thought.In the study, researchers first quizzed several chatbots about medical information. In these carefully conducted tests, ChatGPT-4o, Llama 3, and Command R+ correctly diagnosed medical scenarios an impressive 94% of the time—though they were able to recommend the right treatment a much less impressive 56% of the time. But that wasn’t a real-world test for the chatbots medical utility. The researchers then gave medical scenarios to 1,298 people, and asked them to use an LLM to figure out what might be going on in that scenario, plus what they should do about it (for example, whether they should call an ambulance, follow up with their doctor when convenient, or take care of the issue on their own). The participants were recruited through an online platform that reported it verifies that research subjects are real humans and not bots themselves. Some participants were in a control group that was told to research the scenario on their own, and not using any AI tools. In the end, the no-AI control group did far better than the LLM-using group in correctly identifying medical conditions, including most serious “red flag” scenarios. How a chatbot with “correct” information can lead people astrayAs the researchers write, “Strong performance from the LLMs operating alone is not sufficient for strong performance with users.” Plenty of previous research has shown that chatbot output is sensitive to the exact phrasing people use when asking questions, and that chatbots seem to prioritize pleasing a user over giving correct information. Even if an LLM bot can correctly answer an objectively phrased question, that doesn’t mean it will give you good advice when you need it. That’s why it doesn’t really matter that ChatGPT can “pass” a modified medical licensing exam—success at answering formulaic multiple choice questions is not the same thing as telling you when you need to go to the hospital.  The researchers analyzed chat logs to figure out where things broke down. Here are some of the issues they identified:The users didn’t always give the bot all of the relevant information. As non-experts, the users certainly didn’t know what was most important to include. If you’ve been to a doctor about anything potentially serious, you know they’ll pepper you with questions to be sure you aren’t leaving out something important. The bots don’t necessarily do that. The bots “generated several types of misleading and incorrect information.” Sometimes they ignored important details to narrow in on something else; sometimes they recommended calling an emergency number but gave the wrong one (such as an Australian emergency number for U.K. users).Responses could be drastically different for similar prompts. In one example, two users gave nearly identical messages about a subarachnoid hemorrhage. One response told the user to seek emergency care; the other said to lie down in a dark room. People varied in how they conversed with the chatbot. For example, some asked specific questions to constrain the bot’s answers, but some let the bot take the lead. Either method could introduce unreliability into the LLM's output.Correct answers were often grouped with incorrect answers. On average, each LLM gave 2.21 answers for the user to choose from. People understandably did not always choose correctly from those options. Overall, people who didn't use LLMs were 1.76 times more likely to get the right diagnosis. (Both groups were similarly likely to figure out the right course of action, but that's not saying much—on average, they only got it right about 43% of the time.) The researchers described the control group as doing \"significantly better\" at the task. And this may represent a best-case scenario: the researchers point out that they provided clear examples of common conditions, and LLMs would likely do worse with rare conditions or more complicated medical scenarios. They conclude: “Despite strong performance from the LLMs alone, both on existing benchmarks and on our scenarios, medical expertise was insufficient for effective patient care.”\n            \n                What do you think so far?\n            \n        \nChatbots are a risk for doctors, tooPatients may not know how to talk to an LLM, or how to vet its output, but surely doctors would fare better, right? Unfortunately, people in the medical field are also using AI chatbots for medical information in ways that create risks to patient care. ECRI, a medical safety nonprofit, put the misuse of AI chatbots in the number one spot on its list of health technology hazards of 2026. While the AI hype machine is trying to convince you to give ChatGPT your medical information, ECRI correctly points out that it’s wrong to think of these chatbots as having human personalities or cognition: “While these models produce humanlike responses, they do so by predicting the next word based on large datasets, not through genuine comprehension of the information.”ECRI reports that physicians are, in fact, using generative AI tools for patient care, and that research has already shown the serious risks involved. Using LLMs does not improve doctors’ clinical reasoning. LLMs will elaborate confidently on incorrect details included in prompts. Google’s Med-Gemini model, created for medical use, made up a nonexistent body part whose name was a mashup of two unrelated real body parts; Google told a Verge reporter that the mistake was a “typo.”  ECRI argues that “because LLM responses often sound authoritative, the risk exists that clinicians may subconsciously factor AI-generated suggestions into their judgments without critical review.”Even in situations that don’t seem like life-and-death cases, consulting a chatbot can cause harm. ECRI asked four LLMs to recommend brands of gel that could be used with a certain ultrasound device on a patient with an indwelling catheter near the area being scanned. It’s important to use a sterile gel in this situation, because of the risk of infection. Only one of the four chatbots identified this issue and made appropriate suggestions; the others just recommended regular ultrasound gels. In other cases, ECRI’s tests resulted in chatbots giving unsafe advice on electrode placement and isolation gowns. Clearly, LLM chatbots are not ready to be trusted to keep people safe when seeking medical care, whether you’re the person who needs care, the doctor treating them, or even the staffer ordering supplies. But the services are already out there, being widely used and aggressively promoted. (Their makers are even fighting in the Super Bowl ads.) There’s no good way to be sure these chatbots aren’t involved in your care, but at the very least we can stick with good old Dr. Google—just make sure to disable AI-powered search results. \n            \n    \n        The Daily Newsletter\n            Ready to do everything better?\n        \n        \n            Jordan Calhoun\n            \n        \n        Get daily tips, tricks, and tech guides from our expert team.\n            The Daily NewsletterReady to do everything better?\n                    Get daily tips, tricks, and tech guides from our expert team.\n            \n        \n    \n                        \n                \n            \n                    \n                                            \n                \n            \n                Beth Skwarecki\n                                    Senior Health Editor\n                                \n                                            Covering health, fitness tech, home gym equipment, and more.\n                                    \n                Read Beth's full bio\n                            \n        \n                \n                                            \n    More by Beth\n        \n        \n                        \n                \n                    \n                \n            \n        \n                    \n                \n                    \n                \n            \n        \n                                        \n            \n                                    \n                                            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T15:00:00.000Z",
      "dateModified": "2026-02-12T15:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Claude Has a Surprisingly Great Way to Add Multiple Appointments to Your Calendar at Once",
    "url": "https://lifehacker.com/tech/use-claude-create-ical-files?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH9WBZB32S8QG90GGBESCX4N/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-13T13:30:01.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                            \n        \n            Justin Pot\n                \n                                                                        Editorial Author\n                                                            \n            \n            \n        \n            ExperienceJustin Pot is a freelance journalist who helps people get more out of technology. If you've ever searched online for a specific tech problem you've read Justin's work, because he's been doing it for a long time. Since 2009, he has written tutorials and essays about technology for outlets including WIRED, The Atlantic, PCMag, Popular Science, How-to Geek, and The Wall Street Journal. For Lifehacker, he mostly writes about software, with a particular focus on open source programs and indie apps. Justin has a bachelor's degree in Communications and International Relations. He once worked in marketing for a software company and hated it, but it did teach him a lot about why software tends to get worse over time in large companies. He lives in Oregon with his cat (and his wife). He enjoys brewing beer, exploring nature, and spending time with friends. You can follow Justin on Mastodon and Bluesky, or sign up for his newsletter, Connectivity.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Smith Collection/Gado / Contributor / Archive Photos via Getty Images\n                            \n    Table of Contents\n    \n        \n        I rely heavily on my digital calendar—as far as I'm concerned, if something isn't there, it doesn't exist. It's annoying, then, when someone hands me a piece of paper or even an email stating when multiple meetings are going to happen. I need to either manually add everything to my calendar—which is time consuming—or try to keep track of everything separately from my calendar.I've found a better way, though. As of this week, even the free version of Claude can create files for you, including iCal ones. These files are handy for quickly adding multiple appointments to the Apple, Google, and Microsoft calendar services.How Claude can create custom iCal files for youFor example, say you wanted every Olympic men's hockey game on your calendar (I'm Canadian—what else was I going to use as a demonstration?) All you need to do is take a screenshot of the schedule, upload that screenshot to Claude, and ask for it to create an iCal download using the information. I tried this and it worked perfectly.\nThe Olympics thing is just an example, though. Say you're at a conference and the staff gives you a paper schedule—you could take a photo, ask Claude for the iCal file, and add everything to your calendar at once.Note that you might need to inform Claude about time zones. In my example, the screenshot I had mentioned what time zone the events were happening in, and Claude worked it out. In other tests, I found I needed to mention any potential time zone complications before asking for the file.\n            \n                What do you think so far?\n            \n        \nHow to import Claude's iCal files to your calendarUsing these files on a Mac is easy: just open it and the Calendar app will ask you which calendar you want to add the appointments to. But it's also not hard on Google Calendar or Outlook.On Google Calendar, click the gear icon near the top-right corner, then click Settings and find the Import option in the left side bar. Click \"Select file from your computer\" and point it toward the file you downloaded from Claude.\n    \n            \n            \n                                        Credit: Justin Pot\n                    \n    \nThe steps for Microsoft Outlook are similar. In Outlook, click File, then Open & Export, then Import/Export, then select Import and iCalendar (.ics) or vCalendar (.vcs). Select which calendar you want to add the appointments to and you're done—the appointments will all show up.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Claude Has a Surprisingly Great Way to Add Multiple Appointments to Your Calendar at Once",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH9WBZB32S8QG90GGBESCX4N/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-13T13:30:01.000Z",
      "dateModified": "2026-02-13T13:30:01.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "OpenAI Actually Shut Down GPT-4o",
    "url": "https://lifehacker.com/tech/openai-actually-shut-down-gpt-4o?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHC6XAVZ3AGTFBN2NPVGZF02/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T20:15:41.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Matthew Nichols1\n                            \n            \n                Key Takeaways\n                                            OpenAI finally deprecated its GPT-4o model on Friday, two weeks after announcing the news.\n                                            The company tried to shut down the model in August, but brought it back following intense user backlash.\n                                            4o is at the center of lawsuits accusing ChatGPT of encouraging delusional thinking, including, in some cases, suicide.\n                                    \n            \n    Table of Contents\n    \n        \n        They actually did it. OpenAI officially deprecated GPT-4o on Friday, despite the model's particularly passionate fan base. This news shouldn't have been such a surprise. In fact, the company announced that Feb. 13 would mark the end of GPT-4o—as well as models like GPT-4.1, GPT-4.1 mini, and o4-mini—just over two weeks ago. However, whether you're one of the many who are attached to this model, or you simply know how dedicated 4o's user base is, you might be surprised OpenAI actually killed its most agreeable AI. This isn't the first time the company depreciated the model, either. OpenAI previously shut down GPT-4o back in August, to coincide with the release of GPT-5. Users quickly revolted against the company, some because they felt GPT-5 was a poor upgrade compared to 4o, while others legitimately mourned connections they had developed with the model. The backlash was so strong that OpenAI relented, and rereleased the models it had deprecated, including 4o.   If you're a casual ChatGPT user, you might just use the app as-is, and assume the newest version tends to be the best, and wonder what all the hullabaloo surrounding these models is all about. After all, whether it's GPT-4o, or GPT-5.2, the model spits out generations that read like AI, complete with flowery word choices, awkward similes, and constant affirmations. 4o, however, does tend to lean even more into affirmations than other models, which is what some users love about it. But critics accuse it of being too agreeable: 4o is at the center of lawsuits accusing ChatGPT of enabling delusional thinking, and, in some cases, helping users take their own lives. As TechCrunch highlights, 4o is OpenAI's highest-scoring model for sycophancy.   \nI'm not sure where 4o's most devoted fans go from here, nor do I know how OpenAI is prepared to deal with the presumed backlash to this deprecation. But I know it's not a good sign that so many people feel this attached to an AI model. \n            \n                What do you think so far?\n            \n        \nDisclosure: Ziff Davis, Mashable’s parent company, in April 2025 filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "OpenAI Actually Shut Down GPT-4o",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHC6XAVZ3AGTFBN2NPVGZF02/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T20:15:41.000Z",
      "dateModified": "2026-02-13T20:15:41.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
    "url": "https://lifehacker.com/tech/23andme-data-breach-payout?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-11T14:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Jennie Book/Shutterstock\n                            \n            \n                Key Takeaways\n                                            If you were affected by 23andMe's data breach, you have just a few more days to claim your compensation.\n                                            \"Extraordinary\" claims may qualify for up to a $10,000 payout.\n                                            Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed.\n                                    \n            \n    Table of Contents\n    \n        \n        If you were affected by 23andMe's data breach—which involved the information of approximately 6.4 million U.S. residents—you have just a few more days to claim your compensation. Following the 2023 credential-stuffing attack, 23AndMe in 2024 agreed to a $30–$50 million payout for impacted consumers. The genetic testing company then filed for Chapter 11 bankruptcy in 2025 (introducing new privacy concerns around the potential sale of customer data).  The courts approved the deal last month, and class members have until Feb. 17 to submit claims related to the cyber incident. How much you'll receive from the 23andMe settlementThere are several tiers of payouts with the 23andMe settlement. Users with an \"extraordinary claim\"—those who experienced identity theft or fraudulent tax filings as a result of the breach—could qualify for up to $10,000 to reimburse verified expenses, including costs for physical or cyber security systems as well as mental health treatment. Claimants who received notices that certain health information was leaked in the breach will be paid up to $165. Eligible data include raw genotype data, health reports (including health predisposition reports, wellness reports, and carrier status reports), and self-reported health conditions. Individuals residing in Alaska, California, Illinois, and Oregon will receive an additional $100 thanks to state privacy laws. Note that payments will likely take time to be distributed. \nThe settlement also provides for five years of identity monitoring services through a customized program called Privacy & Medical Shield + Genetic Monitoring. This is available to all class members regardless of payout.  \n            \n                What do you think so far?\n            \n        \nHow to file a 23andMe claimConsumers who were impacted by the 2023 data breach can file a Cyber Security Incident Claim, which must be submitted by Feb. 17, 2026 (unless you received a notice in 2026 indicating otherwise). To be eligible, you must have been a 23andMe customer between May 1, 2023 and October 1, 2023 and have received a notice (via letter or email) that your information was compromised in the breach. You also must attest that you incurred damages (monetary or non-monetary) as a result of the incident. Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed. To complete a claim, you must provide some personal information as well as details about the harm incurred with supporting documentation, such as bank or credit card statements substantiating losses. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
      "image": [
        "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-11T14:30:00.000Z",
      "dateModified": "2026-02-11T14:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
    "url": "https://lifehacker.com/tech/malicious-ai-assistants-google-chrome?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T20:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Zooey Liao/Lifehacker/Getty Images\n                            \n            \n                Key Takeaways\n                                            AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information.\n                                            In the latest campaign—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants.\n                                            Always vet extensions carefully—don't just rely on a familiar name like ChatGPT.\n                                    \n            \n    Table of Contents\n    \n        \n        AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information. Researchers at security firm LayerX have analyzed multiple campaigns in recent months involving malicious browser extensions, including the widespread GhostPoster scheme targeting Chrome, Firefox, and Edge. In the latest one—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants, including Claude, ChatGPT, Gemini, Grok, and \"AI Gmail.\" Collectively, these fakes have more than 300,000 installs. Fake Chrome extensions look like popular AI assistantsThe Chrome extensions identified as part of AiFrame look like legitimate AI tools commonly used for summarizing, chat, writing, and Gmail assistance. But once installed, they grant attackers wide-ranging remote access to the user's browser. Some of the capabilities observed include voice recognition, pixel tracking, and email content readability. Researchers note that extensions are broadly capable of harvesting data and monitoring user behavior. Though the extensions analyzed by LayerX used a variety of names and branding, all 30 were found to have the same internal structure, logic, permissions, and backend infrastructure. Instead of implementing functionality locally on the user's device, they render a full-screen iframe that loads remote content as the extension's interface. This allows attackers to push changes silently at any time without a requiring Chrome Web Store update. \nLayerX has a complete list of the names and extension IDs to refer to. Because threat actors use familiar and/or generic branding, such as \"Gemini AI Sidebar\" and \"ChatGPT Translate,\" you may not be able to identify fakes at first glance. If you have an AI assistant installed in Chrome, go to chrome://extensions, toggle on Developer mode in the top-right corner, and search for the ID below the extension name. Remove any malicious add-ons and reset passwords. \n            \n                What do you think so far?\n            \n        \nAs BleepingComputer reports, some of the malicious extensions have already been removed from the Chrome Web Store, but others remain. Several have received the \"Featured\" badge, adding to their legitimacy. Threat actors have also been able to quickly republish add-ons under new names using the existing infrastructure, so this campaign and others like it may persist. Always vet extensions carefully—don't just rely on a familiar name like ChatGPT—and note that even AI-powered add-ons from trusted sources can be highly invasive. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T20:00:00.000Z",
      "dateModified": "2026-02-13T20:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This New iOS 26 Feature Helps Eliminate Text Spam",
    "url": "https://lifehacker.com/tech/ios-26-screen-unknown-senders-feature?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH2K5S97KXYRF7TY347M8YKK/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T16:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Talukdar David/Shutterstock \n                            \n    Table of Contents\n    \n        \n        With iOS 26, Apple made it easier for users to reduce spam and overall clutter in their Messages inbox. Your iPhone will detect and hide spam messages, and with the Screen Unknown Senders feature, you can filter out texts from anyone you don't know. You can also disable push notifications for these conversations to reduce how often you're alerted for messages you don't need to see. Note that this feature works only on iOS, so if you have Messages synced on your Mac, you'll see everything and receive notifications for all messages unless you mute specific conversations. How to reduce clutter in Messages on iOSTo send messages from numbers you don't know to a separate folder, go to Settings > Apps > Messages and toggle on Screen Unknown Senders. You can also get here through the Messages app on your iPhone by tapping the three horizontal menu lines in the top-right corner and selecting Manage Filtering. Enabling Screen Unknown Senders will hide notifications and move messages to your Unknown Senders list. If you want to allow (or disallow) certain types of notifications, tap Allow Notifications and toggle categories on or off: \nTime Sensitive includes alerts, verification codes, and urgent requests. Personal includes messages identified as not sent by a business or organization. Transactions include order updates, receipts, and confirmations. Promotions include general offers and updates sent to multiple recipients. Most users will want to enable time-sensitive notifications to receive messages that include time-based one-time passwords (TOTPs) and other urgent alerts. You may also want to allow personal notifications so you don't miss messages directed to you individually from real people who aren't saved in your contacts.  \n            \n                What do you think so far?\n            \n        \nWhen you allow notifications, texts identified in those categories will appear in your Messages list for only 12 hours before being moved to Unknown Senders—a behavior that keeps your primary inbox streamlined. If you want to make an unknown sender a known sender to prevent future messages from being filtered out, open the conversation and tap Mark as Known at the bottom or add the number to your contacts. A known sender is anyone you've added to your Contacts, sent a message to, or marked as known in the conversation. Finally, if you enable Filter Spam under the same menu in your device settings, Apple will send messages identified as spam to a separate Spam list and hide notifications. You can view these and conversations from unknown senders at any time via Messages > Menu. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This New iOS 26 Feature Helps Eliminate Text Spam",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH2K5S97KXYRF7TY347M8YKK/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T16:00:00.000Z",
      "dateModified": "2026-02-10T16:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Your Browser's Extensions May Be Reading Your Passwords",
    "url": "https://lifehacker.com/tech/browser-extensions-passwords-in-plain-text?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH1ZP1WQYWD4BJTGVVV5KH2C/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-09T21:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: ERIK Miheyeu/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Researchers at the University of Wisconsin–Madison discovered a large number of websites store sensitive information in plain text.\n                                            Researchers found over 1,000 websites designed this way, and 17,300 extensions with the permissions to read this data.\n                                            While it's on developers to fix the security vulnerabilities, you can take steps to protect your sensitive data when sharing it online.\n                                    \n            \n    Table of Contents\n    \n        \n        We should all take common-sense steps to make sure our data stays safe and secure: use strong passwords with our accounts, and never reuse passwords; employ two-factor authentication on any account that offers it; and avoid clicking strange links in emails or text messages. But even when you follow all those rules, your personal data can still be at risk, strictly because the services you rely on aren't following these rules themselves. Some websites are putting your passwords at riskResearchers at the University of Wisconsin-Madison discovered that a concerning number of browser extensions can access sensitive information that you enter into websites. Think passwords, credit card info, and Social Security numbers. The team behind the discovery says they weren't out looking to break a security story. Instead, they were \"messing around with login pages,\" specifically Google login pages, when they found that the sites' HTML source code could see the passwords they entered in plain text. They turned their sights onto other websites—more than 7,000, reportedly—and found that about 15% of them were also storing sensitive information in plain text. That's over 1,000 websites exposing important data.\nThat, of course, is not supposed to happen: When you enter sensitive data into a website—say, your password into Google's login page—that site shouldn't see your password at all. In short, the sites confirm your passwords through hashing algorithms—essentially, jumbling your password into a code that can be checked against the code the site stores on their end. They can then confirm you entered the right password without ever exposing the actual text. By storing things like passwords and Social Security numbers in plain text, those sites are exposing that data to anyone in the know. Importantly, that includes browser extensions. The researchers claim that 17,300 Chrome extensions—or 12.5% of the extensions available for download on Google's browser—have the permissions they need to view this sensitive plain text data. Think about the permissions you ignore when setting up a new extension, including permissions that give extensions full access to see and change what you enter on a webpage. Researchers didn't expose any extensions by name, as the situation is not necessarily the fault of the extensions, but considering the scope, it's possible some of the extensions you use can access sensitive information you enter in certain sites. Again, legitimate extensions are not the priority: Instead, it's the risk that a developer will create an extension with the intent of scraping sensitive info stored in plain text. While the researchers claim there are no extensions actively abusing this vulnerability yet, this isn't a theoretical problem. Researchers created an extension from scratch that could pull this user data, uploaded it to the Chrome Web Store, and got it approved. They took it down immediately, but proved it's possible for a hacker to get such a malicious extension on the official store. Even if the hacker didn't make the extension, they could acquire a legitimate extension with an existing user base, adjust the code to take advantage of the vulnerability, and spring the updated extension on unsuspecting users. It happens all the time, and not just on Chrome.  \n            \n                What do you think so far?\n            \n        \nHow to protect your sensitive data from malicious browser extensionsUnfortunately, there's little you can do to prevent these sites from storing your passwords, credit cards, and Social Security numbers in plain text. The hope is, following these discoveries, websites will improve their security and kill the vulnerabilities on their end. But that's on them, not you. There are some steps you can take to mitigate the damage, however. First, make sure to limit your use of browser extensions. The fewer extensions you use, the less likely it is you'll use a malicious one. Use only extensions you fully trust, and frequently check in on updates. If the extension changes hands to a new developer, vet that new owner before continuing to use it. You could even disable your extensions when sharing sensitive information with websites. If you need to provide your Social Security number on an official web form, for example, you could disable your extensions to prevent them from reading the data.You can also limit the data you share that could stored in plain text. If given the option, use passkeys instead of passwords, as passkeys don't actually use any plain text data that hackers could steal. Similarly, use secure payment systems, such as Apple Pay or Google Pay, which don't actually share your credit card information with the website you're making a payment on. The name of the game is to avoiding typing out your sensitive details unless absolutely necessary—and then, reducing the parties who can see those details. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Your Browser's Extensions May Be Reading Your Passwords",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH1ZP1WQYWD4BJTGVVV5KH2C/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-09T21:00:00.000Z",
      "dateModified": "2026-02-09T21:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Study's List of the Most Invasive AI Browser Extensions Includes a Few You Probably Use",
    "url": "https://lifehacker.com/tech/invasive-ai-browser-extensions-study-grammarly?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH0F0DCSGGX7YXWDCMW41CCN/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-09T15:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Smith Collection/Gado / Archive Photos via Getty Images\n                            \n            \n                Key Takeaways\n                                            A host of AI-powered browser extensions that have been installed by tens of millions of users may also be invading your privacy.\n                                            The most invasive extensions fall in the programming and mathematical aid category followed closely by meeting assistants and audio transcribers.\n                                            When adding an extension (or installing an app or program), carefully review the permissions requested.\n                                    \n            \n    Table of Contents\n    \n        \n        Browser extensions, even ones from trustworthy sources, are not without privacy and security risks. I've written before about add-ons that manage to slip through official store safeguards and even some that \"wake up\" as malware after operating normally for several years, so it should come as no surprise that a host of AI-powered browser extensions—collectively  installed by tens of millions of users—may also be invading your privacy. Researchers at data removal service Incogni looked at browser extensions available in the Chrome Web Store that included \"AI\" in their name or description and employed AI as part of their core functionality. By analyzing the data collected and permissions required, they assessed both how likely extensions are to be used maliciously and their potential to cause significant damage if compromised.AI-powered browser extensions collect extensive user dataIncogni found that website content, such as text, images, sounds, videos, and hyperlinks, was the most commonly collected data type (by nearly a third of AI-powered extensions). More than 29% of extensions investigated harvest personally identifiable information (PII)—name, address, email, age, identification number, for example—from users. Other forms of data collected include user activity, authentication information, personal communication, location, financial and payment information, web history, and health information. \nThe most invasive extensions fall in the programming and mathematical aid category (such as Classology AI and StudyX), followed closely by meeting assistants and audio transcribers. Writing and personal assistants also pose privacy risks—and many of these are also among the most downloaded AI-powered extensions in Chrome. How popular AI-powered Chrome extensions stack up on privacyIncogni also assigned \"privacy-invasiveness\" scores to the most downloaded AI-powered extensions, a combination of the amount of data collected and both general and sensitive permissions required: \n            \n                What do you think so far?\n            \n        \nGrammarly: AI Writing Assistant and Grammar Checker App (tied for #1)Quillbot: AI Writing and Grammar Checker Tool (tied for #1)Sider: Chat wiht all AI (tied for #3)AI Grammar Checker & Paraphraser — LanguageTool (tied for #3)Google Translate (tied for #4)WPS PDF — Read, Edit, Fill, Convert, and AI Chat PDF with Ease (tied for #4)Monica: All-in-One AI Assist  (tied for #4)AI Chat for Google (tied for #4)Immersive Translate — Translate Web & PDFChatGPT searchGrammarly and Quillbot were found to collect PII and website content as well as location data like region, IP address, and GPS coordinates. Grammarly also harvest user activity through network monitoring, clicks, mouse and scroll positions, and keystroke logging. While both also require sensitive permissions—such as the ability to inject code into websites and access active browser tabs—they have a relatively low risk of being used maliciously. How to protect your personal informationBrowser extensions that use AI aren't inherently bad, but you should be aware of what information they are collecting and what permissions they are requiring. The most common type of sensitive permissions required are scripting, which allows the extension to interact with pages as you navigate online, as well as activeTab, which lets it read or modify the page for the current session. When adding an extension (or installing an app or program), carefully review the permissions requested. If they aren't essential to the extension's functionality–or if they are but don't seem justified—you may be putting your data or device at risk by allowing them. As Incogni points out, users have to decide how much privacy to sacrifice in order to use apps and services. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Study's List of the Most Invasive AI Browser Extensions Includes a Few You Probably Use",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH0F0DCSGGX7YXWDCMW41CCN/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-09T15:30:00.000Z",
      "dateModified": "2026-02-09T15:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "The Telegram App Has a New Look, and a Weird New Feature",
    "url": "https://lifehacker.com/tech/telegram-has-a-new-look-and-some-new-features?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH7A5JFYZZTP9BVTRZ5KRK3A/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-11T22:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Ascannio/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Telegram announced some new changes and features to its iOS and Android app on Monday.\n                                            The biggest announcement is an overhauled UI for Android, with a new bottom navigation bar.\n                                            The iOS version gets new Liquid Glass UI elements, such as an updated media viewer.\n                                            There are also some new features, including one that lets you craft NFT-like \"collectibles.\"\n                                    \n            \n    Table of Contents\n    \n        \n        If your chat app of choice is Telegram, you have some changes to look forward to. The company announced a number of updates this week, chief among them a new look for its Android and iOS apps—the former is getting a total overhaul, but iPhone users will still note some new UI elements when chatting with friends on Telegram. There are also some new features, including one I find a little odd. There's a new look for Telegram on mobile\n    \n            \n            \n                                        Credit: Telegram\n                    \n    \nPer the announcement, the biggest changes come via UI updates, particularly on Android. Telegram says that its Android app has a \"fully redesigned interface\" intended to make navigating the app quicker and more intuitive—Telegram notes the interface code itself was entirely rebuilt to meet these goals. Changes include a new iOS-like bottom bar that lets you switch between your chats, settings, and profile, among other functionality. If you find the new interface effects to be too much, or too big a draw on your battery, Telegram says you can adjust them from Settings > Power Saving. The company also updated its iOS app, though not quite in the same way. Telegram says it added \"even more Liquid Glass\" to its iOS app, Apple's new design language for iOS 26, including a redesigned media viewer, sticker and emoji pack preview panels, and new context menus in profiles when choosing messages.\nYou can now transfer a Telegram group chat to a new admin\n    \n            \n            \n                                        Credit: Telegram\n                    \n    \nAs of this latest update, if the owner of a Telegram group chat leaves that conversation, the ownership of the group will transfer automatically to one of the group's admins after a week. However, the departing group owner can also choose their own admin if they want to, as Telegram now presets an option to appoint another admin when leaving the group. The company adds that admins can transfer ownership at any time, even if they don't leave.    Telegram bots are now more colorful\n    \n            \n            \n                                        Credit: Telegram\n                    \n    \nA small change, but if you develop bots for Telegram, you now have the option to add colors and emojis to those buttons. It's far from a radical update, but it could make it a bit easier to tell options apart at a glance. \n            \n                What do you think so far?\n            \n        \nThere's a new send message shortcut on the Telegram iPad appA small but noteworthy feature for any Telegram users on iPad: Now, you can send a message using the shortcut \"Command + Enter.\"You can now \"craft\" gifts in TelegramAnd here's that weird new feature: I don't usually expect my chat app to offer collectible gifts, but apparently Telegram does. It previously introduced the ability to send gifts to other people, and even upgrade those gifts to collectibles that can be auctioned on NFT marketplaces (which requires real money).Now, Telegram is reportedly expanding this gift system in the latest update with the ability to combine existing gifts in a new \"crafting\" system to create \"Uncommon, Rare, Epic or Legendary\" versions. You can combine up to four gifts at once, and adding multiple gifts with the same \"attributes\" raises the chance the crafted gift will have that attribute as well. Again, this is the last thing I'd expect or want from a chat app, but, as it's part of this update, so I'm telling you about it.  \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "The Telegram App Has a New Look, and a Weird New Feature",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH7A5JFYZZTP9BVTRZ5KRK3A/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-11T22:00:00.000Z",
      "dateModified": "2026-02-11T22:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "YouTube Finally Released an App for the Apple Vision Pro",
    "url": "https://lifehacker.com/tech/youtube-app-for-apple-vision-pro?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH9SVASV7VEXA78TP418XENK/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T21:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Stephen Johnson\n                  ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Stephen Johnson\n                            \n        \n            Stephen Johnson\n                \n                                            Senior Staff Writer\n                                    \n            \n            \n        \n            ExperienceStephen Johnson is a senior staff writer at Lifehacker covering pop culture and technology, including the columns “The Out-of-Touch Adults’ Guide to Kid Culture” and “What People Are Getting Wrong This Week.”\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 12, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: YouTube\n                            \n            \n                Key Takeaways\n                                            A YouTube app is now available for Apple Vision Pro.\n                                            Users can stream every video on YouTube, even 8K video.\n                                            The standalone YouTube app was designed with Vision's spatial computing in mind.\n                                    \n            \n    Table of Contents\n    \n        \n        YouTube has finally come to Apple Vision Pro. YouTube for Vision OS is a free, standalone app that lets users log into their existing YouTube accounts through their Vision headsets and stream videos like they would expect to, including standard videos, 180° videos, 360° videos, and YouTube Shorts. Vision Pro M5 users can stream 8K videos, and premium YouTube members can download videos directly to their headsets, a must for long flights.  Google, YouTube's parent company, has apparently been working on the app for a while. In 2024, a spokesperson confirmed that a standalone Vision Pro app was \"on our roadmap,\" but until today, the only way Vision users could watch YouTube on their headsets was through the Safari web browser. The new YouTube app is designed to fit into Vision's spatial computing environments. \"Rather than just responding to different screen sizes, we needed something that responds to different spaces, volumes and use cases,\" YouTube's senior UX designer Brendan Polley told Apple. \"We built an entirely new design system that isolated core elements—comments, the play button, 'like' and 'dislike'—to fit any layout.\"\n            \n                What do you think so far?\n            \n        \nHaving downloaded the app, it works exactly as intended. If you're looking for something that demonstrates Vision Pro's immersive video capabilities, you should check out the just-released 360° videos from the Milano Cortina winter Olympics on NBC's channel. Immersive luge is terrifying! \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "YouTube Finally Released an App for the Apple Vision Pro",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH9SVASV7VEXA78TP418XENK/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T21:30:00.000Z",
      "dateModified": "2026-02-12T21:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  }
]