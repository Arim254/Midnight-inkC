[
  {
    "title": "Apple Just Patched Its First Zero-Day Security Vulnerability of 2026",
    "url": "https://lifehacker.com/tech/apple-just-patched-its-first-zero-day-security-vulnerability-of-2026?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH9B1B0Q2NK5PAYNYW5KKY8R/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-12T18:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 12, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Tada Images/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Apple just released a whole host of security patches, including a fix for an actively exploited zero-day affecting iOS 26 and iPadOS 26.\n                                            The flaw could allow attackers with memory write capability to execute arbitrary code.\n                                            You can confirm that you're on the latest OS version under Settings > General > Software Update.\n                                    \n            \n    Table of Contents\n    \n        \n        It's once again time to update your Apple devices. The company just released a whole host of security patches, including a fix for an actively exploited zero-day affecting iOS 26, iPadOS 26, and macOS Tahoe. These updates arrived alongside the official release of iOS 26.3, which includes features like more seamless data transfer between iPhone and Android. Other security patches address bugs in Photos, VoiceOver, and Screenshots, to name a few.  iOS 26.3 patches a zero-day affecting dyldAccording to Apple's latest security bulletin, the zero-day—tracked as CVE-2026-20700—is a memory corruption issue in dyld, Apple's \"Dynamic Link Editor.\" The flaw could allow attackers with memory write capability to execute arbitrary code—or, in other words, run their own code on your device.Apple says that the vulnerability may have been exploited in an \"extremely sophisticated attack against specific targeted individuals\" in earlier versions of iOS alongside CVE-2025-14174 and CVE-2025-43529. Those at greatest risk with this bug are likely high-profile users with access to sensitive data—users who might be inclined to use Apple's Lockdown Mode—but everyone should install the update to patch the issue. \nThe patch for this flaw is available for the following iOS and iPadOS devices, in addition to all Macs that run macOS Tahoe:\n            \n                What do you think so far?\n            \n        \niPhone 11 and lateriPad Pro 12.9-inch 3rd generation and lateriPad Pro 11-inch 1st generation and lateriPad Air 3rd generation and lateriPad 8th generation and lateriPad mini 5th generation and laterHow to install the latest security update for iPhoneYou should have automatic updates enabled to ensure you receive critical security patches ASAP, but you can confirm that you're on the latest OS version under Settings > General > Software Update. As a reminder, Apple won't message you urging you to click links, download attachments, or install apps related to security updates. Always go through your device settings to receive official fixes. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Apple Just Patched Its First Zero-Day Security Vulnerability of 2026",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH9B1B0Q2NK5PAYNYW5KKY8R/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-12T18:00:00.000Z",
      "dateModified": "2026-02-12T18:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Popular AI Chat App Exposed 300 Million Private Messages",
    "url": "https://lifehacker.com/tech/ai-chat-app-exposed-300-million-private-messages?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH24D7NJCV0WX105DT6VYV7Y/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-09T22:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Justin Pot\n                            \n        \n            Justin Pot\n                \n                                                                        Editorial Author\n                                                            \n            \n            \n        \n            ExperienceJustin Pot is a freelance journalist who helps people get more out of technology. If you've ever searched online for a specific tech problem you've read Justin's work, because he's been doing it for a long time. Since 2009, he has written tutorials and essays about technology for outlets including WIRED, The Atlantic, PCMag, Popular Science, How-to Geek, and The Wall Street Journal. For Lifehacker, he mostly writes about software, with a particular focus on open source programs and indie apps. Justin has a bachelor's degree in Communications and International Relations. He once worked in marketing for a software company and hated it, but it did teach him a lot about why software tends to get worse over time in large companies. He lives in Oregon with his cat (and his wife). He enjoys brewing beer, exploring nature, and spending time with friends. You can follow Justin on Mastodon and Bluesky, or sign up for his newsletter, Connectivity.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Apple App Store\n                            \n    Table of Contents\n    \n        \n        Have you ever used an application called Chat & Ask AI? If so, there's a good chance your messages were exposed last month. In January, an independent researcher was able to easily access some 300 million messages on the service, according to 404 Media's Emanual Maiberg. The data included chat logs related to all kinds of sensitive topics, from drug use to suicide.Chat & Ask AI, an app offered by the Istanbul-based company Codeway that is available on both Apple and Google app stores, claims to have around 50 million users. The application essentially resells access to large language models from other companies, including OpenAI, Claude, and Google, providing limited free access to its users.The problem that lead to the data leak was related to an insecure Google Firebase configuration, a relatively common vulnerability. The researcher was easily able to make himself an \"authenticated\" user, at which point he could read messages from 25 million of the app's users. He reportedly extracted and analyzed around 60,000 messages before reporting the issue to Codeway.\n            \n                What do you think so far?\n            \n        \nThe good news: The issue was quickly patched. More good news: there have been no reports of these messages leaking to the broader internet. Still, this is yet one more reason to carefully consider the kinds of messages you send AI chatbots. Remember, conversations with AI chatbots aren't private—by their nature, these systems often save your conversations to \"remember\" them later. In the case of a data breach, that could potentially lead to embarrassment, or worse—and using an reseller like Chat & Ask AI to access large language models adds another layer of potential security risks, as this recent leak demonstrates.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Popular AI Chat App Exposed 300 Million Private Messages",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH24D7NJCV0WX105DT6VYV7Y/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-09T22:00:00.000Z",
      "dateModified": "2026-02-09T22:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Ring Just Ended Its Controversial Partnership With Flock Safety",
    "url": "https://lifehacker.com/tech/ring-ended-controversial-partnership-with-flock-safety?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHBR0KCJS1YGKPFR454NNA8B/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T15:12:40.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: CC Photo Labs/Shutterstock\n                            \n            \n                Key Takeaways\n                                            In a blog post on Friday, Ring announced the end of its partnership with Flock Safety.\n                                            The announcement follows backlash to Ring's \"Search Party\" Super Bowl ad, which critics have seen as a slippery slope to infringing user privacy.\n                                            Ring says that the Flock Safety integration never went through, so no Ring footage was ever sent to the organization.\n                                    \n            \n    Table of Contents\n    \n        \n        Ring isn't having the week it probably thought it would have. The Amazon-owned company aired an ad on Super Bowl Sunday for \"Search Party,\" its new feature that turns a neighborhood's collective Ring cameras into one network, with the goal of locating lost dogs. Viewers, however, saw this as a major privacy violation—it doesn't take much to imagine using this type of surveillance tech to locate people, not pets.The backlash wasn't just isolated to the ad, however. The controversy reignited criticisms of the company's partnership with Flock Safety, a security company that sells security cameras that track vehicles, notably for license plate recognition. But the partnership with Ring wasn't about tracking vehicles: Instead, Flock Safety's role was to make it easier for law enforcement agencies that use Flock Safety software to request Ring camera footage from users. Agencies could put in a request to an area where a crime supposedly took place, and Ring users would be notified about the request. They didn't have to agree to share footage, however. Law enforcement could already request footage from Ring users, through the platform's existing \"Community Requests\" feature. But this partnership would let agencies make these requests directly through Flock Safety's software. If a user submitted footage following a request, Ring said that data would be \"securely packaged\" by Flock Safety and share to the agency through FlockOS or Flock Nova.\nThat partnership is officially over. On Friday, Ring published a blog post announcing the end of its relationship with Flock Safety. The company said, after a review, the integration \"would require significantly more time and resources than anticipated.\" As such, both parties have agree to cancel the partnership. \n            \n                What do you think so far?\n            \n        \nImportantly, Ring says that since the integration never actually launched, no user footage was ever sent to Flock Safety—despite the company announcing the partnership four months ago. Social media influencers had spread the false claim that Flock Safety was seeding Ring footage directly to law enforcement agencies, such as ICE. While those claims are inaccurate, they were likely fueled by reporting from 404 Media that ICE has been able to access Flock Safety's data in its investigations. Had Ring's partnership with Flock Safety gone ahead, there would be legitimate cause to believe that agencies like ICE could tap into the footage Ring users had shared—even if those users were under the impression they were only sharing footage with local agencies to solve specific cases.  While privacy advocates will likely celebrate this news, the cancelled partnership has no effect on Community Requests. Law enforcement agencies will still be able to request footage from Ring users, and those users will still have a say in whether or not they send that footage. Ring sees the feature as an objective good, allowing users to voluntarily share footage that could help law enforcement solve important cases. In its announcement on Friday, Ring cited the December 2025 Brown University shooting, in which seven users shared 168 video clips with law enforcement. According to Ring, one of those videos assisted police in identifying the suspect's car, which, in turn, solved the case.    \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Ring Just Ended Its Controversial Partnership With Flock Safety",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHBR0KCJS1YGKPFR454NNA8B/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T15:12:40.000Z",
      "dateModified": "2026-02-13T15:12:40.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
    "url": "https://lifehacker.com/tech/malicious-ai-assistants-google-chrome?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-13T20:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 13, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Zooey Liao/Lifehacker/Getty Images\n                            \n            \n                Key Takeaways\n                                            AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information.\n                                            In the latest campaign—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants.\n                                            Always vet extensions carefully—don't just rely on a familiar name like ChatGPT.\n                                    \n            \n    Table of Contents\n    \n        \n        AI-powered browser extensions continue to be a popular vector for threat actors looking to harvest user information. Researchers at security firm LayerX have analyzed multiple campaigns in recent months involving malicious browser extensions, including the widespread GhostPoster scheme targeting Chrome, Firefox, and Edge. In the latest one—dubbed AiFrame—threat actors have pushed approximately 30 Chrome add-ons that impersonate well-known AI assistants, including Claude, ChatGPT, Gemini, Grok, and \"AI Gmail.\" Collectively, these fakes have more than 300,000 installs. Fake Chrome extensions look like popular AI assistantsThe Chrome extensions identified as part of AiFrame look like legitimate AI tools commonly used for summarizing, chat, writing, and Gmail assistance. But once installed, they grant attackers wide-ranging remote access to the user's browser. Some of the capabilities observed include voice recognition, pixel tracking, and email content readability. Researchers note that extensions are broadly capable of harvesting data and monitoring user behavior. Though the extensions analyzed by LayerX used a variety of names and branding, all 30 were found to have the same internal structure, logic, permissions, and backend infrastructure. Instead of implementing functionality locally on the user's device, they render a full-screen iframe that loads remote content as the extension's interface. This allows attackers to push changes silently at any time without a requiring Chrome Web Store update. \nLayerX has a complete list of the names and extension IDs to refer to. Because threat actors use familiar and/or generic branding, such as \"Gemini AI Sidebar\" and \"ChatGPT Translate,\" you may not be able to identify fakes at first glance. If you have an AI assistant installed in Chrome, go to chrome://extensions, toggle on Developer mode in the top-right corner, and search for the ID below the extension name. Remove any malicious add-ons and reset passwords. \n            \n                What do you think so far?\n            \n        \nAs BleepingComputer reports, some of the malicious extensions have already been removed from the Chrome Web Store, but others remain. Several have received the \"Featured\" badge, adding to their legitimacy. Threat actors have also been able to quickly republish add-ons under new names using the existing infrastructure, so this campaign and others like it may persist. Always vet extensions carefully—don't just rely on a familiar name like ChatGPT—and note that even AI-powered add-ons from trusted sources can be highly invasive. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "These Malicious AI Assistants in Chrome Are Stealing User Credentials",
      "image": [
        "https://lifehacker.com/imagery/articles/01KHC36S2FS26DJCSZWGYRZHGX/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-13T20:00:00.000Z",
      "dateModified": "2026-02-13T20:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
    "url": "https://lifehacker.com/health/ai-chatbots-are-even-worse-at-medical-advice-than-we-thought?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T15:00:00.000Z",
    "description": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n            ",
    "body": "\n    \n        \n            \n                \n            \n        \n    \n            \n                                                    \n                    Even when they have the “right” information, they can lead you astray.\n            \n                        \n    \n                    \n        \n        \n        \n    \n                                Beth Skwarecki\n                            \n        \n            Beth Skwarecki\n                \n                                            Senior Health Editor\n                                    \n            \n            \n        \n            ExperienceBeth Skwarecki is Lifehacker’s Senior Health Editor, and holds certifications as a personal trainer and weightlifting coach. She has been writing about health for over 10 years.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                            \n        \n        \n        February 12, 2026\n            \n            \n                        Credit: Jeffrey Hazelwood/Lifehacker/Getty Images\n                            \n    \n        \n        It’s tempting to think that an LLM chatbot can answer any question you pose it, including those about your health. After all, chatbots have been trained on plenty of medical information, and can regurgitate it if given the right prompts. But that doesn’t mean they will give you accurate medical advice, and a new study shows how easily AI’s supposed expertise breaks down. In short, they are even worse at it than I thought.In the study, researchers first quizzed several chatbots about medical information. In these carefully conducted tests, ChatGPT-4o, Llama 3, and Command R+ correctly diagnosed medical scenarios an impressive 94% of the time—though they were able to recommend the right treatment a much less impressive 56% of the time. But that wasn’t a real-world test for the chatbots medical utility. The researchers then gave medical scenarios to 1,298 people, and asked them to use an LLM to figure out what might be going on in that scenario, plus what they should do about it (for example, whether they should call an ambulance, follow up with their doctor when convenient, or take care of the issue on their own). The participants were recruited through an online platform that reported it verifies that research subjects are real humans and not bots themselves. Some participants were in a control group that was told to research the scenario on their own, and not using any AI tools. In the end, the no-AI control group did far better than the LLM-using group in correctly identifying medical conditions, including most serious “red flag” scenarios. How a chatbot with “correct” information can lead people astrayAs the researchers write, “Strong performance from the LLMs operating alone is not sufficient for strong performance with users.” Plenty of previous research has shown that chatbot output is sensitive to the exact phrasing people use when asking questions, and that chatbots seem to prioritize pleasing a user over giving correct information. Even if an LLM bot can correctly answer an objectively phrased question, that doesn’t mean it will give you good advice when you need it. That’s why it doesn’t really matter that ChatGPT can “pass” a modified medical licensing exam—success at answering formulaic multiple choice questions is not the same thing as telling you when you need to go to the hospital.  The researchers analyzed chat logs to figure out where things broke down. Here are some of the issues they identified:The users didn’t always give the bot all of the relevant information. As non-experts, the users certainly didn’t know what was most important to include. If you’ve been to a doctor about anything potentially serious, you know they’ll pepper you with questions to be sure you aren’t leaving out something important. The bots don’t necessarily do that. The bots “generated several types of misleading and incorrect information.” Sometimes they ignored important details to narrow in on something else; sometimes they recommended calling an emergency number but gave the wrong one (such as an Australian emergency number for U.K. users).Responses could be drastically different for similar prompts. In one example, two users gave nearly identical messages about a subarachnoid hemorrhage. One response told the user to seek emergency care; the other said to lie down in a dark room. People varied in how they conversed with the chatbot. For example, some asked specific questions to constrain the bot’s answers, but some let the bot take the lead. Either method could introduce unreliability into the LLM's output.Correct answers were often grouped with incorrect answers. On average, each LLM gave 2.21 answers for the user to choose from. People understandably did not always choose correctly from those options. Overall, people who didn't use LLMs were 1.76 times more likely to get the right diagnosis. (Both groups were similarly likely to figure out the right course of action, but that's not saying much—on average, they only got it right about 43% of the time.) The researchers described the control group as doing \"significantly better\" at the task. And this may represent a best-case scenario: the researchers point out that they provided clear examples of common conditions, and LLMs would likely do worse with rare conditions or more complicated medical scenarios. They conclude: “Despite strong performance from the LLMs alone, both on existing benchmarks and on our scenarios, medical expertise was insufficient for effective patient care.”\n            \n                What do you think so far?\n            \n        \nChatbots are a risk for doctors, tooPatients may not know how to talk to an LLM, or how to vet its output, but surely doctors would fare better, right? Unfortunately, people in the medical field are also using AI chatbots for medical information in ways that create risks to patient care. ECRI, a medical safety nonprofit, put the misuse of AI chatbots in the number one spot on its list of health technology hazards of 2026. While the AI hype machine is trying to convince you to give ChatGPT your medical information, ECRI correctly points out that it’s wrong to think of these chatbots as having human personalities or cognition: “While these models produce humanlike responses, they do so by predicting the next word based on large datasets, not through genuine comprehension of the information.”ECRI reports that physicians are, in fact, using generative AI tools for patient care, and that research has already shown the serious risks involved. Using LLMs does not improve doctors’ clinical reasoning. LLMs will elaborate confidently on incorrect details included in prompts. Google’s Med-Gemini model, created for medical use, made up a nonexistent body part whose name was a mashup of two unrelated real body parts; Google told a Verge reporter that the mistake was a “typo.”  ECRI argues that “because LLM responses often sound authoritative, the risk exists that clinicians may subconsciously factor AI-generated suggestions into their judgments without critical review.”Even in situations that don’t seem like life-and-death cases, consulting a chatbot can cause harm. ECRI asked four LLMs to recommend brands of gel that could be used with a certain ultrasound device on a patient with an indwelling catheter near the area being scanned. It’s important to use a sterile gel in this situation, because of the risk of infection. Only one of the four chatbots identified this issue and made appropriate suggestions; the others just recommended regular ultrasound gels. In other cases, ECRI’s tests resulted in chatbots giving unsafe advice on electrode placement and isolation gowns. Clearly, LLM chatbots are not ready to be trusted to keep people safe when seeking medical care, whether you’re the person who needs care, the doctor treating them, or even the staffer ordering supplies. But the services are already out there, being widely used and aggressively promoted. (Their makers are even fighting in the Super Bowl ads.) There’s no good way to be sure these chatbots aren’t involved in your care, but at the very least we can stick with good old Dr. Google—just make sure to disable AI-powered search results. \n            \n    \n        The Daily Newsletter\n            Ready to do everything better?\n        \n        \n            Jordan Calhoun\n            \n        \n        Get daily tips, tricks, and tech guides from our expert team.\n            The Daily NewsletterReady to do everything better?\n                    Get daily tips, tricks, and tech guides from our expert team.\n            \n        \n    \n                        \n                \n            \n                    \n                                            \n                \n            \n                Beth Skwarecki\n                                    Senior Health Editor\n                                \n                                            Covering health, fitness tech, home gym equipment, and more.\n                                    \n                Read Beth's full bio\n                            \n        \n                \n                                            \n    More by Beth\n        \n        \n                        \n                \n                    \n                \n            \n        \n                    \n                \n                    \n                \n            \n        \n                                        \n            \n                                    \n                                            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AI Chatbots Are Even Worse at Giving Medical Advice Than We Thought",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH4VNDPMV1RN3JEVQ4YTSPXQ/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T15:00:00.000Z",
      "dateModified": "2026-02-12T15:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Apple and Google Just Made It Easier to Switch Between iPhone and Android",
    "url": "https://lifehacker.com/tech/apple-and-google-just-made-it-easier-to-switch-between-iphone-and-android?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KBZW51YD9RTK9TT6NWP3RZ28/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-12T19:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 12, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Mr.Mikla / Shutterstock.com\n                            \n            \n                Key Takeaways\n                                            Apple and Google actually worked together on a method to make switching between iPhone and Android easier.\n                                            With iOS 26.3, iPhone users can access the tool to simplify the process of transferring data like photos, messages, contacts and more.\n                                            However, Apple says health data, devices paired with Bluetooth, and \"protected items\" cannot be transferred.\n                                    \n            \n    Table of Contents\n    \n        \n        When it's time to buy a new car, you don't necessarily need to stick with the one you had before. You don't lose your cloud-based photos by switching from Toyota to Subaru, nor will your friends yell at you for ruining the group chat by buying a Kia. That's not the case with smartphones: When you buy an iPhone, it's tough to switch away from it. The same goes for Android: While it's easy enough to switch within the Android ecosystem, such as between Pixel or Galaxy, moving from Android to iPhone can also be a pain. Tech companies tend to make it tempting to stick with their platform, and introduce friction when you try to leave. That, of course, is entirely business-based. Apple hasn't traditionally made it easy to move to Android, because, well, you might actually do it. It doesn't have to be this way, either. There's nothing inherent to smartphones that should make it so challenging to break out of any particular ecosystem. All it takes is some intentional design: If smartphones were made to be traded, you could migrate from one to another, without worrying about losing pictures, messages, or any other important data or processes. As it happens, that intentional design is here. Apple and Google actually worked together to make it easier to transfer data between iPhone and Androids, which makes switching between the two platforms more seamless. \nNews first broke about this partnership back in December, and, at that time, Google released some of this progress as part of the latest Android Canary, the company's earliest pre-release software. Shortly after, Apple released the first beta for iOS 26.3, which featured the transfer tool. Now, iOS 26.3 is here, and with it, an easier way to switch from iPhone to a device made by Google, Samsung, or any other Android OEM.   How to use the new iPhone-to-Android option in iOS 26.3The feature seems easy enough to use. Once you update your iPhone to iOS 26.3, you can head to Settings > General, then scroll down to \"Transfer or Reset iPhone.\" Tap this option, then choose \"Transfer to Android.\" Here, iOS will present a pop-up, telling you to place your iPhone next to your new Android device, where you can transfer photos, messages, and apps, among other data points. (That said, health data, devices paired with Bluetooth, and \"protected items\" cannot be transferred.)You'll need to make sure both devices are running the latest updates, are connected to wifi, and have Bluetooth enabled. However, Apple also says your Android device should be in the \"setup process,\" which means you likely won't be able to use this feature if your Android phone is already set up. From here, your iPhone will ask you to scan a QR code that should appear on your Android device. Alternatively, you'll be able to tap \"Other Options\" on your iPhone to enter the Session ID and Pairing Code that should appear on your Android.    \n            \n                What do you think so far?\n            \n        \nNow, you can choose the data you want to transfer, including photos, contacts, calendars, call history, and messages. Tap \"Continue\" once complete, then choose to transfer your eSIM, if applicable. (You'll need to double-click the side of your iPhone when prompted to complete the eSIM transfer.) This works in the other direction too, though Apple says you do still need to use the Move to iOS app on Android—at least until Google sets up a similar protocol on its end.  More flexibility from Apple and Google is better for everyone Apple and Google might not be motivated by charity, of course, as the EU has been cracking down on restrictive practices by tech companies in recent years. But while both companies may see this as a way to lose customers, it's also a way to gain them: Sure, some iPhone users may switch to Android if it's easier to do so, but some Android users may do the reverse for the same reasons.More choice is good for everyone—even if it doesn't guarantee exponential growth to shareholders.  \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Apple and Google Just Made It Easier to Switch Between iPhone and Android",
      "image": [
        "https://lifehacker.com/imagery/articles/01KBZW51YD9RTK9TT6NWP3RZ28/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-12T19:30:00.000Z",
      "dateModified": "2026-02-12T19:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Microsoft's February Patch Tuesday Update Fixes Six Zero-Day Exploits",
    "url": "https://lifehacker.com/tech/microsofts-february-patch-tuesday-update?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH5ESZQAD4AGMV8N9G6S3Y5P/hero-image.fill.size_1200x675.png",
    "tag": "Life",
    "date": "2026-02-11T17:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Daniel Chetroni / Shutterstock.com\n                            \n            \n                Key Takeaways\n                                            The latest \"Patch Tuesday\" fixes 58 vulnerabilities in total, six of which are zero-day flaws.\n                                            Three of the six actively exploited zero-days fixed in February are security feature bypass vulnerabilities.\n                                            Machines receive updates automatically, but you can check your settings to be sure.\n                                    \n            \n    Table of Contents\n    \n        \n        Microsoft's February security update is a big one. This latest \"Patch Tuesday\" fixes 58 vulnerabilities in total, six of which are zero-day flaws. As a reminder, a zero-day is a vulnerability that has been either actively exploited in the wild or publicly disclosed before an official fix is released by the developer. As BleepingComputer reports, security flaws were found in the following categories: 25 elevation-of-privilege vulnerabilities, five security feature bypass vulnerabilities, 12 remote code-execution vulnerabilities, six information disclosure vulnerabilities, three denial of service vulnerabilities, and seven spoofing vulnerabilities. Three of the elevation of privilege vulnerabilities and two of the information disclosure vulnerabilities are considered \"critical.\" (These numbers do not include the three Microsoft Edge vulnerabilities patched earlier in February.)Patch Tuesday updates are typically released around 10 am PT on the second Tuesday of every month, and your device should receive them automatically. BleepingComputer reports that this month's release also includes Secure Boot certificate updates for 2011 certificates that are expiring in June. \nSix zero-days patched in FebruaryThree of the six actively exploited zero-days fixed in February are security feature bypass vulnerabilities: CVE-2026-21510: This is a flaw the Windows Shell that allows an attacker to execute content without warning or gaining user consent, though the user does need to open a malicious link or shortcut file. CVE-2026-21513: This MSHTML Framework vulnerability allows an unauthorized attacker to bypass a security feature over a network. Microsoft has not released details on how this flaw was exploited. CVE-2026-21514: This vulnerability in Microsoft Word allows an attacker to bypasses OLE mitigations in Microsoft 365 and Microsoft Office once a user has opened a malicious Office file. All three of the above flaws have been attributed to Microsoft Threat Intelligence Center (MSTIC), Microsoft Security Response Center (MSRC), Office Product Group Security Team, and Google Threat Intelligence Group along with an anonymous researcher for CVE-2026-21510 and CVE-2026-21514.\n            \n                What do you think so far?\n            \n        \nTwo of the zero-days are elevation of privilege vulnerabilities. CVE-2026-21519 is a Desktop Windows Manager flaw that allows an attacker to gain SYSTEM privileges, while CVE-2026-21533 is a Windows Remote Desktop Services flaw that allows an attacker to elevate privileges locally. The former has been attributed to MSTIC and MSRC, while the latter was discovered by the Advanced Research Team at CrowdStrike.Finally, CVE-2026-21525 is a denial of service vulnerability in the Windows Remote Access Connection Manager that allows an unauthorized attacker to deny service locally. This flaw was discovered by the ACROS Security team with 0patch—it was reportedly found in a public malware repository in December 2025. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Microsoft's February Patch Tuesday Update Fixes Six Zero-Day Exploits",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH5ESZQAD4AGMV8N9G6S3Y5P/hero-image.fill.size_1200x675.png"
      ],
      "datePublished": "2026-02-11T17:00:00.000Z",
      "dateModified": "2026-02-11T17:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
    "url": "https://lifehacker.com/tech/23andme-data-breach-payout?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-11T14:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 11, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Jennie Book/Shutterstock\n                            \n            \n                Key Takeaways\n                                            If you were affected by 23andMe's data breach, you have just a few more days to claim your compensation.\n                                            \"Extraordinary\" claims may qualify for up to a $10,000 payout.\n                                            Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed.\n                                    \n            \n    Table of Contents\n    \n        \n        If you were affected by 23andMe's data breach—which involved the information of approximately 6.4 million U.S. residents—you have just a few more days to claim your compensation. Following the 2023 credential-stuffing attack, 23AndMe in 2024 agreed to a $30–$50 million payout for impacted consumers. The genetic testing company then filed for Chapter 11 bankruptcy in 2025 (introducing new privacy concerns around the potential sale of customer data).  The courts approved the deal last month, and class members have until Feb. 17 to submit claims related to the cyber incident. How much you'll receive from the 23andMe settlementThere are several tiers of payouts with the 23andMe settlement. Users with an \"extraordinary claim\"—those who experienced identity theft or fraudulent tax filings as a result of the breach—could qualify for up to $10,000 to reimburse verified expenses, including costs for physical or cyber security systems as well as mental health treatment. Claimants who received notices that certain health information was leaked in the breach will be paid up to $165. Eligible data include raw genotype data, health reports (including health predisposition reports, wellness reports, and carrier status reports), and self-reported health conditions. Individuals residing in Alaska, California, Illinois, and Oregon will receive an additional $100 thanks to state privacy laws. Note that payments will likely take time to be distributed. \nThe settlement also provides for five years of identity monitoring services through a customized program called Privacy & Medical Shield + Genetic Monitoring. This is available to all class members regardless of payout.  \n            \n                What do you think so far?\n            \n        \nHow to file a 23andMe claimConsumers who were impacted by the 2023 data breach can file a Cyber Security Incident Claim, which must be submitted by Feb. 17, 2026 (unless you received a notice in 2026 indicating otherwise). To be eligible, you must have been a 23andMe customer between May 1, 2023 and October 1, 2023 and have received a notice (via letter or email) that your information was compromised in the breach. You also must attest that you incurred damages (monetary or non-monetary) as a result of the incident. Claims can be filed online via the settlement website, or you can mail a hard copy of your claim form (postmarked by Feb. 17) to the address listed. To complete a claim, you must provide some personal information as well as details about the harm incurred with supporting documentation, such as bank or credit card statements substantiating losses. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Claim Your Payout From the 23andMe Data Breach Before It's Too Late",
      "image": [
        "https://lifehacker.com/imagery/articles/01JV5C7A284BR4Q698FBBHS8JJ/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-11T14:30:00.000Z",
      "dateModified": "2026-02-11T14:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "AI-Generated Playlists Are Coming to YouTube Music",
    "url": "https://lifehacker.com/tech/ai-playlists-youtube-music?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH454WXYEZ47X1T21SA9STS5/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T17:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Emre Akkoyun/Shutterstock\n                            \n            \n                Key Takeaways\n                                            YouTube Music now offers users an AI playlist generator.\n                                            You can tell the AI what you want in a playlist, and it makes one for you.\n                                            The feature is only available to YouTube Premium or YouTube Music Premium subscribers, and follows similar features from services like Spotify.\n                                    \n            \n    Table of Contents\n    \n        \n        If you're of a certain age, you might remember mixtapes: cassettes made up of a series of tracks you or a friend think work well together, or otherwise enjoy. (They took some work to put together, too.) Digital music sort of killed mixtapes, but, in their place, came playlists. You could easily put together a collection of your favorite songs, and either burn them to a CD, or, as streaming took over, let the playlist itself grow as large as you wanted. Anyone can make a playlist, but there's an art to it. Someone with a keen ear for music can build a playlist you can let play for hours. Maybe you have a friend who's good at making playlists, or maybe you're that friend in your group. They can be a fun way to share music, and find some new music to add to your own library. Now, generative AI wants to replace human intervention altogether. Rather than you or a friend building a playlist, you can ask AI to do it for you. And YouTube Music is the latest service to give it a try.\nYouTube announced its new AI playlist generator in a post on X on Monday. If you subscribe to either YouTube Premium or YouTube Music Premium, you can ask YouTube's AI to make a playlist based on whatever parameters you want. To try it out, open YouTube Music, then head to your Library and tap \"New.\" Next, choose the new \"AI Playlist\" option, then enter the type of music you're looking for. You could ask YouTube Music to generate a playlist of pop-punk songs, or to make something to play when focusing on work. Really, it's whatever you want, and if the AI gets it wrong, you can try it again. \n            \n                What do you think so far?\n            \n        \n\n    \n        This Tweet is currently unavailable. It might be loading or has been removed.\n    \n\nIt's pretty straightforward, and nothing revolutionary. Other music streaming services have their own AI playlist generators too. Spotify, for example, has had one for a couple of years, but recently rolled out Prompted Playlist as well, which lets you generate playlists that update with time, and takes your listening history into account. With this update, however, YouTube is likely trying to drum up some interest in its streaming service and encourage users to pay for it. Just this week, the company put lyrics—once a free feature—behind the Premium paywall. I suppose it thinks that if you can't read what your favorite artists are singing, and you'd like to have a bot make your playlists for you, you might just subscribe to its platform. This could be a good change in the long run for YouTube Music subscribers. I'm on Apple Music, so I don't really use AI-generated playlists. I like the Apple-curated playlists, as well as the ones my friends and I make and share. But who knows: Maybe human-generated playlists are going the way of the mixtape.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AI-Generated Playlists Are Coming to YouTube Music",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH454WXYEZ47X1T21SA9STS5/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T17:00:00.000Z",
      "dateModified": "2026-02-10T17:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Bluesky Finally Has Drafts",
    "url": "https://lifehacker.com/tech/bluesky-finally-has-drafts?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH44A7CD186WD3C961XGVYVQ/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T18:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Michelle Ehrhardt\n                ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Michelle Ehrhardt\n                            \n        \n            Michelle Ehrhardt\n                \n                                            Associate Tech Editor\n                                    \n            \n            \n        \n            ExperienceMichelle is Lifehacker's Associate Tech Editor, and has been reviewing games, laptops, phones, and more for over 10 years. She is based in New York City and holds a master's degree from NYU.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Bluesky\n                            \n            \n                Key Takeaways\n                                            Drafts are now rolling out in Bluesky.\n                                            Drafts work with singular posts and pre-written threads.\n                                            Other commonly requested features include an edit button, but you'll need to rely on third-party tools for that.\n                                    \n            \n    Table of Contents\n    \n        \n        I'm one of those folks who has completely moved from X to Bluesky, and for the most part, it's been a pretty seamless experience. It's not hard to move your following list over; you can upload (almost) all of your old tweets if you want; and the scrolling and posting experience is almost identical to what you'll remember from the old days of Twitter. The only feature I've missed? Drafts.Finally, drafts have arrived. In a post to the official Bluesky account, the company announced that it's added drafts to the platform, and that they're rolling out now. To create a draft, just start writing a post, and instead of tapping the Post button, hit Cancel or Drafts instead and choose Save draft. What you've written will be saved as a draft that you can return to later. The feature works for pre-written threads, too (made using the + button on the post screen). To see your saved drafts, open a blank post and hit Drafts before typing anything else. You'll see a list of your stored drafts, and you can either tap on a draft to open it, or hit the three-dots button to the right of the drift and then Discard to delete it.Drafts were a big part of Twitter for me—not just because they helped save posts if my connection dropped in the middle of writing them, but because they also gave me some time to consider if I really wanted to post something before taking it live. It's a handy feature for a platform with such a small character limit, where it might be easy to toss a stray thought out into the ether without really knowing how it might land or if you've expressed yourself as well as you could have. \nI'm not alone, here: A common trend on Twitter was posting screenshots of draft libraries, to give your followers a peak at the half-formed ideas you didn't think were quite ready for prime time. It's a bit of culture I've missed in moving over to the new site, and I'm glad it's now possible once agin.\n            \n                What do you think so far?\n            \n        \nAs for where Bluesky could go next, responses to the drafts announcement include requests for more robust DMs or an edit button, although Bluesky staffers have expressed both logistical and ethical concerns with implementing these. In the meantime, there are third-party tools that try to add some of this functionality, but they do come with wonky formatting that an official solution could probably avoid.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Bluesky Finally Has Drafts",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH44A7CD186WD3C961XGVYVQ/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T18:00:00.000Z",
      "dateModified": "2026-02-10T18:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "You Can Opt Out of Ads on ChatGPT, but It Might Not Be Worth It",
    "url": "https://lifehacker.com/tech/ads-on-chatgpt-free?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH26KJW3KJD43H7MWGTR35FH/hero-image.fill.size_1200x675.webp",
    "tag": "Life",
    "date": "2026-02-09T22:20:40.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: OpenAI\n                            \n            \n                Key Takeaways\n                                            OpenAI is rolling out ads to all ChatGPT Free and Go users.\n                                            The company says that ads are private, but are informed by your current and past chats.\n                                            You can opt out of ads for free, but you will reduce your ChatGPT message limits.\n                                    \n            \n    Table of Contents\n    \n        \n        It finally happened. After months of speculation, ChatGPT officially has ads. OpenAI revealed the news on Monday, announcing that ads would roll out in testing for logged-in adult users on Free and Go subscriptions. If you or your organization pays for ChatGPT, such as with a Plus, Pro, Business, Enterprise, or Education account, you won't see ads with the bot.OpenAI says that ads do not have an impact on the answers ChatGPT generates, and that these posts are always clearly separated from ChatGPT's actual responses. In addition, ads are labeled as \"Sponsored.\" That being said, it's not exactly a church-and-state situation here. OpenAI says that it decides which ads to show you based on your current and past chats, as well as your past interactions with ChatGPT ads. If you're asking for help with a dinner recipe, you might get an ad for a meal kit or grocery service. The company claims it keeps your chats away from advertisers. The idea, according to the company, is strictly funding-based so that OpenAI can expand ChatGPT access to more users. That's reportedly why ads are starting as a test, not a hardcoded feature: OpenAI says it wants to \"learn, listen, and make sure [it gets] the experience right.\" As such, advertisers don't have access to chats, chat histories, memories, or your personal details. They do have access to aggregate information about ad performance, including views and click metrics.   \nOpenAI will only show ads to adults. If the service detects that you are under 18, it will block ads from populating in your chats. Ads also will not appear if you're talking to ChatGPT about something related to health, medicine, or politics. You can offer OpenAI feedback on the ads you do see, which should inform the ads you receive in the future. You can also delete your ad data and manage ad personalization, if you want to reset the information OpenAI is using to send you ads.\n    \n            \n            \n                                        Credit: OpenAI\n                    \n    \nThe thing is, you don't actually have to deal with ads, even if you use ChatGPT for free. That's not just by upgrading to a paid ChatGPT plan, though OpenAI does suggest that option in its announcement. In addition, OpenAI is offering Free and Go users a dedicated choice to opt out of ads here. There is, of course, a pretty sizable catch: You have to agree to fewer daily free messages with ChatGPT. OpenAI doesn't offer specifics here, so it's not clear how limited the ad-free experience will be. But if you hate ads, or if you simply don't want to see an ad for something irrelevant to your ChatGPT conversation, it's an option.\n            \n                What do you think so far?\n            \n        \nIf you like that trade-off, here's how to opt out of ads. Open ChatGPT, then head to your profile, which opens your profile's Settings page. Here, scroll down to \"Ads controls,\" then choose \"Change plan to go ad-free.\" Select \"Reduce message limits,\" and ChatGPT will confirm ads are off for your account. You can return to this page at any time to turn ads back on and restore your message limits.  Disclosure: Ziff Davis, Mashable’s parent company, in April 2025 filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "You Can Opt Out of Ads on ChatGPT, but It Might Not Be Worth It",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH26KJW3KJD43H7MWGTR35FH/hero-image.fill.size_1200x675.webp"
      ],
      "datePublished": "2026-02-09T22:20:40.000Z",
      "dateModified": "2026-02-09T22:20:40.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This New iOS 26 Feature Helps Eliminate Text Spam",
    "url": "https://lifehacker.com/tech/ios-26-screen-unknown-senders-feature?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH2K5S97KXYRF7TY347M8YKK/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T16:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Talukdar David/Shutterstock \n                            \n    Table of Contents\n    \n        \n        With iOS 26, Apple made it easier for users to reduce spam and overall clutter in their Messages inbox. Your iPhone will detect and hide spam messages, and with the Screen Unknown Senders feature, you can filter out texts from anyone you don't know. You can also disable push notifications for these conversations to reduce how often you're alerted for messages you don't need to see. Note that this feature works only on iOS, so if you have Messages synced on your Mac, you'll see everything and receive notifications for all messages unless you mute specific conversations. How to reduce clutter in Messages on iOSTo send messages from numbers you don't know to a separate folder, go to Settings > Apps > Messages and toggle on Screen Unknown Senders. You can also get here through the Messages app on your iPhone by tapping the three horizontal menu lines in the top-right corner and selecting Manage Filtering. Enabling Screen Unknown Senders will hide notifications and move messages to your Unknown Senders list. If you want to allow (or disallow) certain types of notifications, tap Allow Notifications and toggle categories on or off: \nTime Sensitive includes alerts, verification codes, and urgent requests. Personal includes messages identified as not sent by a business or organization. Transactions include order updates, receipts, and confirmations. Promotions include general offers and updates sent to multiple recipients. Most users will want to enable time-sensitive notifications to receive messages that include time-based one-time passwords (TOTPs) and other urgent alerts. You may also want to allow personal notifications so you don't miss messages directed to you individually from real people who aren't saved in your contacts.  \n            \n                What do you think so far?\n            \n        \nWhen you allow notifications, texts identified in those categories will appear in your Messages list for only 12 hours before being moved to Unknown Senders—a behavior that keeps your primary inbox streamlined. If you want to make an unknown sender a known sender to prevent future messages from being filtered out, open the conversation and tap Mark as Known at the bottom or add the number to your contacts. A known sender is anyone you've added to your Contacts, sent a message to, or marked as known in the conversation. Finally, if you enable Filter Spam under the same menu in your device settings, Apple will send messages identified as spam to a separate Spam list and hide notifications. You can view these and conversations from unknown senders at any time via Messages > Menu. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This New iOS 26 Feature Helps Eliminate Text Spam",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH2K5S97KXYRF7TY347M8YKK/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T16:00:00.000Z",
      "dateModified": "2026-02-10T16:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Google Is Rolling Out Two New Ways to Remove Your Sensitive Data From Search",
    "url": "https://lifehacker.com/tech/google-is-rolling-out-two-ways-to-remove-sensitive-data-from-search?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KH27C4ZZ1PTDF491RFHTWZ7P/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-10T14:00:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 10, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Galeh Nur Wihantara/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Google is rolling out two new tools to request to remove sensitive data from Search.\n                                            The first lets you tell Google to remove government ID numbers like driver's licenses, passports, and Social Security numbers from Search.\n                                            The second makes it easier to request the removal of non-consensual explicit images.\n                                            These tools won't remove this content from the internet, but Google can remove them from Search results.\n                                    \n            \n    Table of Contents\n    \n        \n        Google announced two new ways for users to remove their sensitive information from the web Tuesday morning—or, at least, remove that data from Google Search. The first lets users request that Google remove sensitive government ID information from Search, while the second gives users new tools to request the same for non-consensual explicit images. Google's \"Results about you\" tool is getting an update\n    \n            \n            \n                                        Credit: Google\n                    \n    \nFirst, Google is updating its existing \"Results about you\" tool, which helps users scour the internet for their personal information. Before today, this tool could already locate data points like your name, phone number, email addresses, and home addresses. Following the update, you can now find and request the deletion of search results containing highly sensitive information, including your driver's license, passport, or Social Security number.To launch this tool, click here. If you've never used \"Results about you\" before, you'll need to set it up to tell Google what to look out for. Once you do, you'll be able to add government ID numbers, such as your driver's license, passport, and Social Security number. If Google finds a match, the company will let you know. You can receive an alert from the Google app on your smartphone, which takes you to a summary of what data was found and where. From here, you can choose from \"Request to remove,\" or \"Mark as reviewed.\"  \nUnfortunately, this tool won't remove the data from the websites that are hosting it, but it will eventually remove the search results—sharply reducing the chance that someone will find your data on their own. Google says these changes will roll out in the U.S. over the \"coming days,\" while it is working on bringing them to other countries in the future.  \n            \n                What do you think so far?\n            \n        \nGoogle's simpler way to remove explicit images from Search\n    \n            \n            \n                                        Credit: Google\n                    \n    \nIn addition to these changes, Google is now rolling out a simpler tool for users to request the remove of non-consensual explicit images (NCEI) from Search. If you find such an image on Search, you can tap the three dots on that image, choose \"remove result,\" then \"it shows a sexual image of me.\" You'll have the choice to report whether the photo is real, or is artificially generated, as well, and you can report multiple images at once, if needed. Your requests will all appear in the Results about you hub, so you can track the progress of each.The tool lets you opt-in to an option that will filter additional explicit results in other searches. Google says it will also share links to \"emotional and legal support\" after you submit a request.  \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Google Is Rolling Out Two New Ways to Remove Your Sensitive Data From Search",
      "image": [
        "https://lifehacker.com/imagery/articles/01KH27C4ZZ1PTDF491RFHTWZ7P/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-10T14:00:00.000Z",
      "dateModified": "2026-02-10T14:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Scammers Are Sending Fake Invites With Malware",
    "url": "https://lifehacker.com/tech/scammers-are-sending-fake-invites-with-malware?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KGZ6YPTHD2KZC8JCB7KNJ83W/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-09T15:00:59.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                       ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Emily Long\n                            \n        \n            Emily Long\n                \n                                                                        Freelance Writer\n                                                            \n            \n            \n        \n            ExperienceEmily Long is a freelance writer based in Salt Lake City. After graduating from Duke University, she spent several years reporting on the federal workforce for Government Executive, a publication of Atlantic Media Company, in Washington, D.C. She has nearly a decade of experience as a freelancer covering tech (including issues related to security, privacy, and streaming) as well as personal finance and travel. In addition to Lifehacker, her work has been featured on Wirecutter, Tom’s Guide, and ZDNET. Emily has also worked as a travel guide around the U.S. and as a content editor. She has a masters in social work and is a licensed therapist in Utah.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 9, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: Supapich Methaset / Shutterstock.com\n                            \n    Table of Contents\n    \n        \n        If you receive an event invitation via email, verify it's legit before you RSVP, as you may not actually be invited to anything. Malwarebytes Labs has identified a new scam in which threat actors are using party invites to trick users into installing a remote access tool (RAT) that gives them full control over infected devices. (This specific campaign seems to be limited to the UK, but similar tactics could easily spread.) These malicious invites contain a ScreenConnect installerThe scam starts with an innocuous-looking email invitation with an informal \"Save the Date\" vibe that may appear to come from a friend or acquaintance. The message contains a link to \"View Invitation\" for event details. If you click through, you'll end up on a landing page with a bold \"You're Invited\" header and a button to download your invitation, but you don't actually need to take any further action—your browser automatically triggers the download of a .msi file, which is not actually a party invitation or RSVP form but an installer. The MSI silently installs ScreenConnect Client, a legitimate IT support tool that allows remote access into the user's machine. Once this connection is established, attackers have the ability to see your screen, control your mouse and keyboard, and upload or download files—even if you restart your computer. All of this happens in the background with no obvious indicators that a remote access tool has been installed and is now running, so victims are unlikely to have cause for concern. \nYou should know these remote access red flagsAs Malwarebytes points out, this scheme is successful because it relies on normal human behavior around a seemingly low-risk situation: opening an event invitation. What's unusual is that there's little pressure or urgency in the initial message. Instead, the landing page has language like \"a friend has sent you an invitation\" and \"I opened mine and it was so easy,\" which is a form of social proof that guides users to take the desired action. You should always be alert to unsolicited invites sent via regular email with a link to an external site as well as any communication that prompts you to download or install software. These days, invitations are commonly delivered through apps and digital services like Partiful, Paperless Post, Evite, or Apple Invites, which are generally more trustworthy than random emails with hyperlinked text. If you're unsure whether the invite is real, verify with the sender through another channel before clicking or downloading anything. \n            \n                What do you think so far?\n            \n        \nAs mentioned, victims of this scam may not immediately notice that a RAT has been installed on their device. But there are some red flags, such as unexplained cursor movement or windows opening or closing on their own. You can check your machine for a file named \"RSVPPartyInvitationCard.msi\" or a service called ScreenConnect Client with additional random characters in the title.  If you've already downloaded ScreenConnect from a malicious invite, Malwarebytes recommends disconnecting from the internet and uninstalling the program immediately. Run a security scan to check your device for malware, and change important passwords from a separate device. \n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    \n        \n                \n                    \n                Lifehacker has been a go-to source of tech help and life advice since 2005. Our mission is to offer reliable tech help and credible, practical, science-based life advice to help you live better.\n                \n                \n                    \n                        Our Mission\n                        Our Team\n                        Newsletter\n                    \n                \n            \n        \n                © 2001-2026 Ziff Davis, LLC., A ZIFF DAVIS COMPANY. ALL RIGHTS RESERVED.\n                Lifehacker is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate\n                    any affiliation or the\n                    endorsement of Lifehacker. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n            \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Scammers Are Sending Fake Invites With Malware",
      "image": [
        "https://lifehacker.com/imagery/articles/01KGZ6YPTHD2KZC8JCB7KNJ83W/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-09T15:00:59.000Z",
      "dateModified": "2026-02-09T15:00:59.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This Substack Data Breach May Have Compromised Nearly 700,000 User Records",
    "url": "https://lifehacker.com/tech/substack-user-records-data-breach?utm_medium=RSS",
    "image": "https://lifehacker.com/imagery/articles/01KGT4BA905YCK53HNVCFP4JGG/hero-image.fill.size_1200x675.jpg",
    "tag": "Life",
    "date": "2026-02-06T19:30:00.000Z",
    "description": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                    ",
    "body": "\n        \n    \n                                    \n        \n        \n        \n    \n                                Jake Peterson\n                            \n        \n            Jake Peterson\n                \n                                            Senior Technology Editor\n                                    \n            \n            \n        \n            ExperienceJake Peterson is Lifehacker’s Tech Editor, and has been covering tech news and how-tos for nearly a decade. His team covers all things technology, including AI, smartphones, computers, game consoles, and subscriptions.\n        \n        \n            Areas of Expertise\n        \n        Read Full Bio\n    \n\n    \n                                        \n        \n        \n        February 6, 2026\n                \n        Add as a preferred source on Google\n\n    \n    \n        Add as a preferred source on Google\n\n            Credit: PJ McDonnell/Shutterstock\n                            \n            \n                Key Takeaways\n                                            Substack disclosed a data breach this week that occurred in October of 2025.\n                                            Hackers compromised email addresses, phone numbers, and \"other internal metadata.\"\n                                            One threat actor claims the breach resulted in the loss of nearly 700,000 user records.\n                                    \n            \n    Table of Contents\n    \n        \n        When you sign up for a subscription on Substack, you're thinking you'll receive newsletters and posts from online creators, not lose the data you share with the platform. But like any digital service, the data you provide when signing up is at the mercy of Substack, or anyone who happens to gain access to that data. Unfortunately, that's now the case. As reported by BleepingComputer, Substack recently disclosed a significant data breach. The company's CEO, Chris Best, sent users a notice of the breach this week, sharing that email addresses, phone numbers, and \"other internal metadata\" were shared from Substack accounts without their permission. The company reportedly discovered the breach on Feb. 3, even though hackers accessed the data itself in October of 2025. That means the data was in unauthorized hands for roughly four months before Substack identified the breach. Best explained that Substack has since fixed the problem with the system that allowed an unauthorized third party to access this data. The company is launching an investigation and is reportedly taking steps to prevent this type of breach from happening going forward. On the bright side, Best claims that credit card numbers, passwords, and financial information were not accessed in the breach. \nWhat Best doesn't share is the scope of the breach. For that, we have to turn to BleepingComputer, which found a post from a \"threat actor\" on the hacking forum BreachForums. The actor posted a database of 697,313 Substack records, sharing that the Substack user base is much larger, but the scraping method was \"noisy and patched fast.\" This actor says the data compromised includes email addresses, phone numbers, names, user IDs, Stripe IDs, profile pictures, and bios—a bit more detailed than the report from Substack's CEO.700,000 records isn't the same as 700,000 users: Each record is something like an email address or a phone number, which means one Substack user could have lost multiple records in the breach. Still, it's a large number of data points, and is little consolation to the users who have lost information here. \n            \n                What do you think so far?\n            \n        \nWhat Substack can do after this breachUnfortunately, there's not much users can do to mitigate a data breach once it's happened. The data stolen from Substack is already lost, and you won't be able to undo that. However, there are some steps you can take to protect yourself in the wake of the breach, and to prevent this data loss in the future. First, closely monitor your incoming texts and emails. Hackers will take advantage of the data here to target Substack users in phishing schemes. If you receive messages from strangers, or even suspicious messages claiming to come from Substack, exercise caution. As per usual, never click on links in messages from senders you don't know, and, even more importantly, never download files or applications if instructed. You may also want to consider masking your email address going forward. Use a service like Apple's \"Hide My Email\" or DuckDuckGo's email protection to generate a \"burner\" address each time you need to share your email with a service. The service will send messages to the burner address, which gets forwarded to your real address. That way, the service doesn't know your real address, and, if hacked, won't compromise it. Hackers will only get the burner, which you can shut down at any time.\n            \n    \n    \n        The Download Newsletter\n            Never miss a tech story\n        \n        \n            Jake Peterson\n            \n        \n        Get the latest tech news, reviews, and advice from Jake and the team.\n            The Download NewsletterNever miss a tech story.\n                    Get the latest tech news, reviews, and advice from Jake and the team.\n            \n        \n    \n    ",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This Substack Data Breach May Have Compromised Nearly 700,000 User Records",
      "image": [
        "https://lifehacker.com/imagery/articles/01KGT4BA905YCK53HNVCFP4JGG/hero-image.fill.size_1200x675.jpg"
      ],
      "datePublished": "2026-02-06T19:30:00.000Z",
      "dateModified": "2026-02-06T19:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  }
]