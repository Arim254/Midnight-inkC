[
  {
    "title": "OpenClaw creator Peter Steinberger joins OpenAI",
    "url": "https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T22:28:02.000Z",
    "description": "In Brief Posted: 2:28 PM PST · February 15, 2026  Image Credits:Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  Peter Steinberger, who created the AI personal assistant now known as OpenClaw, has...",
    "body": "\nIn Brief\nPosted:\n2:28 PM PST · February 15, 2026\n\nImage Credits:Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nPeter Steinberger, who created the AI personal assistant now known as OpenClaw, has joined OpenAI.\nPreviously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants. (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.)\nIn a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.”\n“What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said.\nOpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support”\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in AI\n\n"
  },
  {
    "title": "Longtime NPR host David Greene sues Google over NotebookLM voice",
    "url": "https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/",
    "image": "https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T22:07:51.000Z",
    "description": "In Brief Posted: 2:07 PM PST · February 15, 2026  Image Credits:RamKay (opens in a new window) / Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  David Greene, the longtime host of NPR’s “Morning...",
    "body": "\nIn Brief\nPosted:\n2:07 PM PST · February 15, 2026\n\nImage Credits:RamKay (opens in a new window) / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nDavid Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post.\nGreene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.”\n“My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, & Center.”\nAmong other features, Google’s NotebookLM allows users to generate a podcast with AI hosts. A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.”\nThis isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in AI\n\n"
  },
  {
    "title": "Anthropic and the Pentagon are reportedly arguing over Claude usage",
    "url": "https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/",
    "image": "https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T21:11:28.000Z",
    "description": "In Brief Posted: 1:11 PM PST · February 15, 2026  Image Credits:Tom Brenner/Bloomberg via Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  The Pentagon is pushing AI companies to allow the U.S....",
    "body": "\nIn Brief\nPosted:\n1:11 PM PST · February 15, 2026\n\nImage Credits:Tom Brenner/Bloomberg via Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nThe Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios.\nThe government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility.\nAnthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company.\nIn January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro.\nAnthropic did not immediately respond to TechCrunch’s request for comment.\nA company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.”\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in Government & Policy\n\n"
  },
  {
    "title": "African defensetech Terra Industries, founded by two Gen Zers, raises additional $22M in a month",
    "url": "https://techcrunch.com/2026/02/16/terra-industries-raises-22-million/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Nathan-Nwachuku-Maxwell-Maduka.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T08:01:00.000Z",
    "description": "Just one month after raising $11.75 million in a round led by Joe Lonsdale’s 8VC, African defensetech Terra Industries announced that it’s raised an additional $22 million in funding, led by Lux...",
    "body": "\nJust one month after raising $11.75 million in a round led by Joe Lonsdale’s 8VC, African defensetech Terra Industries announced that it’s raised an additional $22 million in funding, led by Lux Capital.\nNathan Nwachuku, 22, and Maxwell Maduka, 24, launched Terra Industries in 2024 to design infrastructure and autonomous systems to help African nations monitor and respond to threats. \nTerrorism remains one of the biggest threats in Africa, but much of the security intelligence on which its nations rely on come from Russia, China, or the West. In January, CEO Nwachuku said his goal was to build “Africa’s first defense prime, to build autonomous defense systems and other systems to protect our critical infrastructure and resources from armed attacks.” \nAt the time, Terra had just won its first federal contract. The company has government and commercial clients, and Nwachuku said Terra had already generated more than $2.5 million in commercial revenue and was protecting assets valued at around $11 billion. \nHe said this extension round came fast due to “strong momentum.” Other investors in the round include 8VC, Nova Global, and Resiliience17 Capital, which was founded by Flutterwave CEO Olugbenga Agboola. Nwachuku said investors saw “faster-than-expected traction” regarding deals and partnerships, which created urgency to preempt and increase their commitment. The round came about in just under two weeks, bringing the company’s total funding to $34 million.\nImage Credits:Terra Industries\nThe extended raise is not that surprising. Afterall, building a defense company is not cheap. For comparison, Anduril has raised more than $2.5 billion in funding; ShieldAI has raised around $1 billion in equity; drone maker Skydio has raised around $740 million, and naval autonomous vessel maker Saronic, has raised around $830 million. \nSince January, Nwachuku said the company has started expanding into other African nations yet to be announced (Terra is based in Nigeria), and has secured more government and commercial contracts, including with AIC Steel, with more to be revealed this year. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe partnership with AIC Steel lets Terra establish a joint manufacturing facility in Saudi Arabia focused on building surveillance infrastructure and security systems. “It’s our first major manufacturing expansion outside Africa,” he said.\n“The priority is working with countries where terrorism and infrastructure security are major national concerns,” Nwachuku added, citing those falling within the sub-Saharan African and Sahel region in particular. He said many of these companies have not only lost billions in infrastructure, but also thousands of lives in the past few decades. \n“We’re focused on targeting major economies where the need for infrastructure security is urgent and where our solutions can make a meaningful impact. That’s how we think about expansion.” \n\n\n\t\tDominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.\r\nYou can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Cohere launches a family of open multilingual models",
    "url": "https://techcrunch.com/2026/02/17/cohere-launches-a-family-of-open-multilingual-models/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1757707025.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-17T09:00:00.000Z",
    "description": "Enterprise AI company Cohere launched a new family of multilingual models on the sidelines of the ongoing India AI Summit. The models, dubbed Tiny Aya, are open-weight — meaning their underlying code is...",
    "body": "\nEnterprise AI company Cohere launched a new family of multilingual models on the sidelines of the ongoing India AI Summit. The models, dubbed Tiny Aya, are open-weight — meaning their underlying code is publicly available for anyone to use and modify — support over 70 languages, and can run on everyday devices like laptops without requiring an internet connection.\nThe model, launched by the company’s research arm Cohere Labs, supports South Asian languages such as Bengali, Hindi, Punjabi, Urdu, Gujarati, Tamil, Telugu, and Marathi. \nThe base model contains 3.35 billion parameters — a measure of its size and complexity. Cohere has also launched TinyAya-Global, a version fine-tuned to better follow user commands, for apps that require broad language support. Regional variants round out the family: TinyAya-Earth for African languages; TinyAya-Fire for South Asian languages; and TinyAya-Water for Asia Pacific, West Asia, and Europe.\nImage Credits: Cohere\n“This approach allows each model to develop stronger linguistic grounding and cultural nuance, creating systems that feel more natural and reliable for the communities they are meant to serve. At the same time, all Tiny Aya models retain broad multilingual coverage, making them flexible starting points for further adaptation and research,” the company said in a statement.\nCohere noted that these models, which were trained on a single cluster of 64 H100 GPUs (a type of high-powered chip by Nvidia) using relatively modest computing sources, are ideal for researchers and developers building apps for audiences that speak native languages. The models are capable of running directly on devices, so developers can use them to power offline translation. The company noted that it built its underlying software to suit on-device usage, requiring less computing power than most comparable models.\nImage Credits: Cohere\nIn linguistically diverse countries like India, this kind of offline-friendly capability can open up a diverse set of applications and use cases without the need for constant internet access.\nThe models are available on HuggingFace, the popular platform for sharing and testing AI models, and the Cohere Platform. Developers can download them on HuggingFace, Kaggle, and Ollama for local deployment. The company is also releasing training and evaluation datasets on HuggingFace and plans to release a technical report detailing its training methodology.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe startup’s CEO, Aidan Gomez, said last year that the company plans to go public “soon.” According to CNBC, the company ended 2025 on a high note, posting $240 million in annual recurring revenue, with 50% growth quarter-over-quarter throughout the year.\n\n\n\t\tIvan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.\r\nYou can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Fractal Analytics’ muted IPO debut signals persistent AI fears in India",
    "url": "https://techcrunch.com/2026/02/16/fractal-analytics-muted-ipo-debut-signals-persistent-ai-fears-in-india/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/02/fractal-analytics.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T11:51:25.000Z",
    "description": "As India's first AI company to IPO, Fractal Analytics didn't have a stellar first day on the public markets, as enthusiasm for the technology collided with jittery investors in the wake of a sell-off in Indian software stocks.",
    "body": "\nAs India’s first AI company to IPO, Fractal Analytics didn’t have a stellar first day on the public markets, as enthusiasm for the technology collided with jittery investors recovering from a major sell-off in Indian software stocks.\nFractal listed at ₹876 per share on Monday, below its issue price of ₹900, and then slid further in afternoon trading. The stock closed at ₹873.70, down 7% from its issue price, lending the company a market capitalization of about ₹148.1 billion (around $1.6 billion).\nThat price tag marks a step down from Fractal’s recent private-market highs. In July 2025, the company raised about $170 million in a secondary sale, at a valuation of $2.4 billion. It first crossed the $1 billion mark in January 2022 after raising $360 million from TPG, becoming India’s first AI unicorn.\nFractal’s IPO comes as India seeks to position itself as a key market and development hub for AI in a bid to attract investment amid increasing attention from some of the world’s most prominent AI companies. Firms such as OpenAI and Anthropic have been engaging more with the country’s government, enterprises, and developer ecosystem as they seek to tap the country’s scale, talent base, and growing appetite for AI tools and technology. \nThat push is on display this week in New Delhi, where India is hosting the AI Impact Summit, bringing together global technology leaders, policymakers and executives.\nFractal’s subdued debut followed a sharp recalibration of its IPO. In early February, the company decided to price the offering conservatively after its bankers advised it to, cutting the IPO size by more than 40% to ₹28.34 billion (about $312.5 million), from the original amount of ₹49 billion ($540.3 million).\nFounded in 2000, Fractal sells AI and data analytics software to large enterprises across financial services, retail and healthcare, and generates the bulk of its revenue from overseas markets, including the U.S. The company pivoted toward AI in 2022 after operating as a traditional data analytics firm for over 20 years.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nFractal touted a steadily growing business in its IPO filing, with revenue from operations rising 26% to ₹27.65 billion (around $304.8 million) in the year ended March 2025 compared to a year earlier. It also swung to a net profit of ₹2.21 billion ($24.3 million) from a loss of ₹547 million ($6 million) the previous year.\nThe company plans to use the IPO proceeds to repay borrowings at its U.S. subsidiary, invest in R&D, sales and marketing under its Fractal Alpha unit, expand office infrastructure in India, and pursue potential acquisitions.\n\n\n\t\tJagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. \r\nYou can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "All the important news from the ongoing India AI Impact Summit",
    "url": "https://techcrunch.com/2026/02/16/all-the-important-news-from-the-ongoing-india-ai-summit/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/06/india-ai.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T11:20:27.000Z",
    "description": "India is hosting a four-day AI Summit this week that will be attended by executives from major AI labs and Big Tech, including OpenAI, Anthropic, Nvidia, Microsoft, Google, and Cloudflare, as well as heads of state.",
    "body": "\n\t\n\t\tImage Credits:Jagmeet Singh / TechCrunch\t\n\t\n\t\t\t\t\t\t3:20 AM PST · February 16, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nWith an eye towards luring more AI investment to the country, India is hosting a four-day AI Impact Summit this week that will be attended by executives from major AI labs and Big Tech, including OpenAI, Anthropic, Nvidia, Microsoft, Google, and Cloudflare, as well as heads of state.\nThe event, which expects 250,000 visitors, will see Alphabet CEO Sundar Pichai, OpenAI CEO Sam Altman, Anthropic CEO Dario Amodei, Reliance Chairman Mukesh Ambani, and Google DeepMind CEO Demis Hassabis in attendance.\nIndia’s prime minister, Narendra Modi, is scheduled to deliver a speech with French President Emmanuel Macron on Thursday.\nHere are all the key updates from the event:\n\nIndia earmarks $1.1 billion for its state-backed venture capital fund. The fund will invest in artificial intelligence and advanced manufacturing startups across the country.\nOpenAI CEO Sam Altman said India accounts for more than 100 million weekly active ChatGPT users, second only to the U.S. He also said Indians also account for the most students using ChatGPT.\nBlackstone has picked up a majority stake in Indian AI startup Neysa as part of a $600 million equity fundraise. Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners also invested. The company now plans to raise another $600 million in debt, and deploy more than 20,000 GPUs.\nBengaluru-based C2i, which is building a power solution for data centers, raised $15 million in a Series A round from Peak XV, with participation from Yali Deeptech and TDK Ventures.\nHCL CEO Vineet Nayyar said Indian IT companies will focus on turning profits and not being job creators. These comments come as Indian IT stocks dip as fears of AI disrupting the IT services sector burgeon.\nVinod Khosla, founder of Khosla Ventures, said that industries like IT services and BPOs (Business Process Outsourcing) can “almost completely disappear” within five years because of AI. He told Hindustan Times that 250 million young people in India should be selling AI-based products and services to the rest of the world. \nAMD is teaming up with Tata Consultancy Services (TCS) to develop rack-scale AI infrastructure based on AMD’s “Helios” platform. \nAnthropic said that it is opening its first office in India in the city of Bengaluru. The company said that the country is the second biggest user of Claude after the U.S.\nAnthropic is partnering with IT giant Infosys to deploy Claude models and tools like Claude code in Indian enterprises. To begin, both will deploy AI tools in the telecommunications sector with a dedicated Anthropic Center of Excellence.\nIndian AI company Sarvam teases its upcoming smart glasses under the name Sarvam Kaze. The company has released several models in the past few weeks, including a dubbing model, a speech-to-text model, a text-to-speech model, and a vision model for Optical Character Recognition (OCR).\n\n\nDrop 12/14: Models, products, impact – today something different, very different. Launching Sarvam Kaze, our foray into getting our models into the your hands with our devices – designed and built here in India! pic.twitter.com/8RnqO16Idg— Pratyush Kumar (@pratykumar) February 17, 2026\n\n\nIndian conglomerate Adani said that it is allocating $100 billion to build AI data centers that would use renewable energy in India by 2035. The company said that this investment will lead to an additional $150 billion investment in areas like server manufacturing, advanced electrical infrastructure, sovereign cloud platforms, and supporting industries.\nVoice AI company Cartesia is teaming up with India-based orchestrator Blue Machines to deploy voice solutions for enterprises with local data residency. \n\n\n\t\t\t\n\tTopics\n\n\n\n\t\tIvan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.\r\nYou can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "How Ricursive Intelligence raised $335M at a $4B valuation in 4 months",
    "url": "https://techcrunch.com/2026/02/16/how-ricursive-intelligence-raised-335m-at-a-4b-valuation-in-4-months/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/02/Ricursive-Intelligence-founders.png?w=150",
    "tag": "Tech",
    "date": "2026-02-16T17:00:00.000Z",
    "description": "The co-founders of startup Ricursive Intelligence seemed destined to be co-founders. Anna Goldie, CEO, and Azalia Mirhoseini, CTO, are so well-known in the AI community that they were among those AI engineers...",
    "body": "\nThe co-founders of startup Ricursive Intelligence seemed destined to be co-founders.\nAnna Goldie, CEO, and Azalia Mirhoseini, CTO, are so well-known in the AI community that they were among those AI engineers who “got those weird emails from Zuckerberg making crazy offers to us,” Goldie told TechCrunch, chuckling. (They didn’t take the offers.) The pair worked at Google Brain together and were early employees at Anthropic.\nThey earned acclaim at Google by creating the Alpha Chip — an AI tool that could generate solid chip layouts in hours — a process that normally takes human designers a year or more. The tool helped design three generations of Google’s Tensor Processing Units.\nThat pedigree explains why, just four months after launching Ricursive, they last month announced a $300 million Series A round at a $4 billion valuation led by Lightspeed, just a couple of months after raising a $35 million seed round led by Sequoia.\nRicursive is building AI tools that design chips, not the chips themselves. That makes them fundamentally different from nearly every other AI chip startup: they’re not a wannabe Nvidia competitor. In fact, Nvidia is an investor. The GPU giant, along with AMD, Intel, and every other chip maker, are the startup’s target customers.\n“We want to enable any chip, like a custom chip or a more traditional chip, any kind of chip, to be built in an automated and very accelerated way. We’re using AI to do that,” Mirhoseini told TechCrunch. \nTheir paths first crossed at Stanford, where Goldie earned her PhD as Mirhoseini taught computer science classes. Since then, their careers have been in lockstep. “We started at Google Brain on the same day. We left Google Brain on the same day. We joined Anthropic on the same day. We left Anthropic on the same day. We rejoined Google on the same day, and then we left Google again on the same day. Then we started this company together on the same day,” Goldie recounted.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nDuring their time at Google, the colleagues were so close they even worked out together, both enjoying circuit training. The pun wasn’t lost on Jeff Dean, the famed Google engineer who was their collaborator. He nicknamed their Alpha Chip project “chip circuit training” — a play on their shared workout routine. Internally, the pair also got a nickname: A&A. \nThe Alpha Chip earned them industry notice, but it also attracted controversy. In 2022, one of their colleagues at Google was fired, Wired reported, after he spent years trying to discredit A&A and their chip work, even though that work was used to help produce some of Google’s most important, bet-the-business AI chips.\nTheir Alpha Chip project at Google Brain proved the concept that would become Ricursive — using AI to dramatically accelerate chip design.\nDesigning chips is hard\nThe issue is, computer chips have millions to billions of logic gate components integrated on their silicon wafer. Human designers can spend a year or more placing those components on the chip to ensure performance, good power utilization and any other design needs. Digitally determining the placement of such infinitesimally small components with precision is, as you might expect, hard. \nAlpha Chip “could generate a very high-quality layout in, like, six hours. And the cool thing about this approach was that it actually learns from experience,” Goldie said. \nThe premise of their AI chip design work is to use “a reward signal” that rates how good the design is. The agent then takes that rating to “update the parameters of its deep neural network to get better,” Goldie said. After completing thousands of designs, the agent got really good. It also got faster as it learned, the founders say.\nRicursive’s platform will take the concept further. The AI chip designer they are building will “learn across different chips,” Goldie said. So each chip it designs should help it become a better designer for every next chip. \nRicursive’s platform also makes use of LLMs and will handle everything from component placement through design verification. Any company that makes electronics and needs chips is their target customer.\nIf their platform proves itself, as it seems likely to do, Ricursive could play a role in the moonshot goal of achieving artificial general intelligence (AGI). Indeed, their ultimate vision is designing AI chips, meaning the AI will essentially design its own computer brains. \n“Chips are the fuel for AI,” Goldie said. “I think by building more powerful chips, that’s the best way to advance that frontier.” \nMirhoseini adds that the lengthy chip-design process is constraining how quickly AI can advance. “We think we can also enable this fast co-evolution of the models and the chips that basically power them,” she said. So AI can grow smarter faster. \nIf the thought of AI designing its own brains at ever increasing speeds brings visions of Skynet and the Terminator to mind, the founders point out that there’s a more positive, immediate and, they think, more likely benefit: hardware efficiency.  \nWhen AI Labs can design far more efficient chips (and, eventually all the underlying hardware), their growth won’t have to consume so much of the world’s resources. \n“We could design a computer architecture that’s uniquely suited to that model, and we could achieve almost a 10x improvement in performance per total cost of ownership,” Goldie said. \nWhile the young startup won’t name its early customers, the founders say that they’ve heard from every big chip making name you can imagine. Unsurprisingly, they have their pick of their first development partners, too. \n"
  },
  {
    "title": "Blackstone backs Neysa in up to $1.2B financing as India pushes to build domestic AI infrastructure",
    "url": "https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/",
    "image": "https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1156074432.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T00:30:00.000Z",
    "description": "Neysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities. Blackstone...",
    "body": "\nNeysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities.\nBlackstone and co-investors, including Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners, have agreed to invest up to $600 million of primary equity in Neysa, giving Blackstone a majority stake, Blackstone and Neysa told TechCrunch. The Mumbai-headquartered startup also plans to raise an additional $600 million in debt financing as it expands GPU capacity, a sharp increase from the $50 million it had raised previously.\nThe deal comes as demand for AI computing surges globally, creating supply constraints for specialized chips and data center capacity needed to train and run large models. Newer AI-focused infrastructure providers — often referred to as “neo-clouds” — have emerged to bridge that gap by offering dedicated GPU capacity and faster deployment than traditional hyperscalers, particularly for enterprises and AI labs with specific regulatory, latency, or customisation requirements.\nNeysa operates in this emerging segment, positioning itself as a provider of customized, GPU-first infrastructure for enterprises, government agencies, and AI developers in India, where demand for local compute is still at an early but rapidly expanding stage.\n“A lot of customers want hand-holding, and a lot of them want round-the-clock support with a 15-minute response and a couple of our resolutions. And so those are the kinds of things that we provide that some of the hyperscalers don’t,” said Neysa co-founder and CEO Sharad Sanghi.\nNesya co-founder and CEO Sharad SanghiImage Credits:Neysa\nGanesh Mani, a senior managing director at Blackstone Private Equity, said his firm estimates that India currently has fewer than 60,000 GPUs deployed — and it expects the figure to scale up nearly 30 times to more than two million in the coming years.\nThat expansion is being driven by a combination of government demand, enterprises in regulated sectors such as financial services and healthcare that need to keep data local, and AI developers building models within India, Mani told TechCrunch. Global AI labs, many of which count India among their largest user bases, are also increasingly looking to deploy computing capacity closer to users to reduce latency and meet data requirements.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe investment also builds on Blackstone’s broader push into data center and AI infrastructure globally. The firm has previously backed large-scale data centre platforms such as QTS and AirTrunk, as well as specialized AI infrastructure providers including CoreWeave in the U.S. and Firmus in Australia.\nNeysa develops and operates GPU-based AI infrastructure that enables enterprises, researchers, and public sector clients to train, fine-tune, and deploy AI models locally. The startup currently has about 1,200 GPUs live and plans to sharply scale that capacity, targeting deployments of more than 20,000 GPUs over time as customer demand accelerates.\n“We are seeing a demand that we are going to more than triple our capacity next year,” Sanghi said. “Some of the conversations we are having are at a fairly advanced stage; if they go through, then we could see it sooner rather than later. We could see in the next nine months.”\nSanghi told TechCrunch that the bulk of the new capital will be used to deploy large-scale GPU clusters, including compute, networking and storage, while a smaller portion will go toward research and development and building out Neysa’s software platforms for orchestration, observability, and security.\nNeysa aims to more than triple its revenue next year as demand for AI workloads accelerates, with ambitions to expand beyond India over time, Sanghi said. Founded in 2023, the startup employs 110 people across offices in Mumbai, Bengaluru, and Chennai.\n\n\n\t\tJagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. \r\nYou can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Have money, will travel: a16z’s hunt for the next European unicorn",
    "url": "https://techcrunch.com/2026/02/16/have-money-will-travel-a16zs-hunt-for-the-next-european-unicorn/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-157503102.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T18:53:56.000Z",
    "description": "Gabriel Vasquez, a partner at Andreessen Horowitz, recently revealed he took nine flights from NYC to Stockholm in one year. While his visits included stops at companies like Lovable — where he posted from...",
    "body": "\nGabriel Vasquez, a partner at Andreessen Horowitz, recently revealed he took nine flights from NYC to Stockholm in one year. While his visits included stops at companies like Lovable — where he posted from its office — the trips were also about finding future Swedish unicorns before they cross the Atlantic.\nThis all came to light when news emerged that a16z had led a $2.3 million pre-seed round into Dentio, a Swedish startup that uses AI to help dentists’ practices with admin work. While this is a small check for a firm that just announced new funds totaling $15 billion, it confirms that U.S. VCs are actively seeking deal flow outside of the U.S., even without local offices.\nStockholm is a natural stop for a16z, which previously achieved significant returns from backing Skype, cofounded by Swedish entrepreneur Niklas Zennström. Since then, a significant number of fast-growing startups have been created in the Swedish capital, and the VC heavyweight tracked down where many of them were coming from. \n“We spend a lot of time developing a deep understanding of specific markets and knowing where innovation is emerging. In Sweden, that has meant closely tracking ecosystems like [SSE Business Lab] — the startup incubator of the Stockholm School of Economics — and the companies coming out of it,” Vasquez told TechCrunch.\nLike fintech giant Klarna, legal AI startup Legora, and e-scooter company Voi, Dentio is an alum of SSE Business Lab — a startup incubator that has produced several successful Swedish companies. The three former high school classmates Elias Afrasiabi, Anton Li and Lukas Sjögren joined the incubator after reconnecting as students at both the SSE (Stockholm School of Economics) and KTH (Royal Institute of Technology), then joined the incubator with additional backing from KTH’s Innovation Launch program. They tackled a problem close to home: Li’s mom, a dentist, had told them how admin work detracted from clinical care.\nThe trio intuited that they could leverage LLMs to help people like her — an idea that they also validated with her and her colleagues. This led them to Dentio’s initial product, a recording tool that uses AI to generate clinical notes. But it’s only a matter of time before AI scribes become a commodity product, and Dentio needs to prove its value to dentists so they aren’t tempted to switch providers when that happens, Afrasiabi said.\nPotential competitors include fellow Swedish startup Tandem Health, which raised a $50 million Series A round last year to support clinicians with AI across multiple medical specialties. Dentio, by contrast, focuses exclusively on dentists, but it believes it can still reach the scale VCs expect through international expansion\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n“Now we’re a team of seven people, and we think that it’s possible to build a unified way of handling administration all over Europe, and maybe even all over the world,” Afrasiabi said. While Europe’s healthcare systems are fragmented, they share similarities, and Dentio’s assumption is that what works in Sweden could work elsewhere in the EU.\nDentio prominently features its “Made in Sweden” branding and emphasizes that “all relevant data is processed in Sweden and Finland in compliance with Swedish and EU law.” It signals data protection to privacy-conscious European customers. But it also signals potential to VCs — a callback to Sweden’s history of producing breakout companies.\n“We went to zero meetups. I reached out to zero investors,” Afrasiabi said. While the team was heads down building, the word spread out. “I think it was mostly through referrals and people talking to each other that the news got all the way over to the U.S.,” he said.\nThis wasn’t happenstance: a16z has eyes around the world in order to spot these companies as early as local funds might, Vasquez said. “In Sweden for example, we partnered with top founders abroad like Fredrik Hjelm, founder of Voi, and Johannes Schildt, founder of Kry, by turning them into scouts and mapping the best local talent.”\nFor Vasquez, who focuses on AI application investments for a16z, this isn’t just about Sweden, but about “a pattern of great global companies being born abroad and scaling quickly,” from Black Forest Labs in Germany to Manus, the Singapore-based AI startup recently acquired by Meta.\nBorn and raised in El Salvador, he has also been spending time in São Paulo. “I’m really excited about what’s brewing in Brazil and across Latin America in AI,” he wrote on LinkedIn at the time. “I believe AI is the great equalizer,” he added. “Most people now have access to PhD-level intelligence on a phone, and ultimately, Silicon Valley is a state of mind.”\nCorrections: This story originally stated that a16z is an investor in Lovable owing to an editing error. The name of SSE’s incubator has also been corrected.\n\n\n\t\tAnna Heim is a writer and editorial consultant. \nYou can contact or verify outreach from Anna by emailing annatechcrunch [at] gmail.com.\nAs a freelance reporter at TechCrunch since 2021, she has covered a large range of startup-related topics including AI, fintech & insurtech, SaaS & pricing, and global venture capital trends.\nAs of May 2025, her reporting for TechCrunch focuses on Europe’s most interesting startup stories.\nAnna has moderated panels and conducted onstage interviews at industry events of all sizes, including major tech conferences such as TechCrunch Disrupt, 4YFN, South Summit, TNW Conference, VivaTech, and many more.\nA former LATAM & Media Editor at The Next Web, startup founder and Sciences Po Paris alum, she’s fluent in multiple languages, including French, English, Spanish and Brazilian Portuguese.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "India has 100M weekly active ChatGPT users, Sam Altman says",
    "url": "https://techcrunch.com/2026/02/15/india-has-100m-weekly-active-chatgpt-users-sam-altman-says/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/04/chatgpt-india.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T18:00:00.000Z",
    "description": "India has 100 million weekly active ChatGPT users, making the country one of OpenAI’s largest markets globally, CEO Sam Altman said ahead of a government-hosted AI summit. On Sunday, Altman outlined ChatGPT’s...",
    "body": "\nIndia has 100 million weekly active ChatGPT users, making the country one of OpenAI’s largest markets globally, CEO Sam Altman said ahead of a government-hosted AI summit.\nOn Sunday, Altman outlined ChatGPT’s growing adoption in India in an article published in the Indian English daily Times of India, as OpenAI prepares to formally participate in the five-day India AI Impact Summit in New Delhi, beginning Monday. Altman is attending the event alongside senior executives from several of the world’s leading AI companies.\nThe growth comes as OpenAI, like other leading AI firms, looks to India’s young population and its more than a billion internet users to fuel global expansion. The ChatGPT maker opened a New Delhi office in August 2025 after months of groundwork in the country, and has adjusted its approach for India’s price-sensitive market, including rolling out a sub-$5 ChatGPT Go tier that was later made free for a year for Indian users.\nIn the article, Altman said India is ChatGPT’s second-largest user base after the United States, highlighting the South Asian nation’s growing weight in OpenAI’s global strategy. The disclosure comes as ChatGPT’s overall usage has surged worldwide, with the platform reaching 800 million weekly active users as of October 2025 and reported to be approaching 900 million.\nAltman also highlighted the role of students in driving adoption, saying India has the largest number of student users of ChatGPT globally.\nIndian students have become a key growth segment for leading AI companies more broadly, as rivals race to embed their tools in classrooms and learning workflows. Google has similarly targeted the market, offering Indian students a free one-year subscription to its AI Pro plan in September 2025. Separately, India accounts for the highest global usage of Gemini for learning, Chris Phillips, Google’s vice president and general manager for education, said last month.\n“With its focus on access, practical Al literacy, and the infrastructure that supports widespread adoption, India is well positioned to broaden who benefits from the technology and to help shape how democratic AI is adopted at scale,” Altman wrote.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nChatGPT’s rapid growth also highlights a broader challenge for AI companies in India: translating widespread adoption into sustained economic impact. Indian government initiatives such as the IndiaAI Mission — a national program aimed at expanding computing capacity, supporting startups and accelerating AI adoption in public services — seek to address those gaps. However, the country’s price-sensitive market and infrastructure constraints have made monetization and large-scale deployment more complex than in developed economies.\n“Given India’s size, it also risks forfeiting a vital opportunity to advance democratic AI in emerging markets around the world,” Altman wrote, warning that uneven access and adoption could concentrate AI’s economic gains in too few hands.\nAltman also signaled that OpenAI plans to deepen its engagement with the Indian government, writing that the company would soon announce new partnerships aimed at expanding access to AI across the country. He did not provide details, but said the focus would be on widening reach and enabling more people to put AI tools to practical use.\nThe India AI Impact Summit is expected to draw a wide cross-section of global technology and political leaders, including Anthropic CEO Dario Amodei, Sundar Pichai of Google, and senior Indian business figures such as Mukesh Ambani and Nandan Nilekani. Political leaders including Emmanuel Macron, Sheikh Khaled bin Mohamed bin Zayed Al Nahyan, and Luiz Inácio Lula da Silva are also expected to attend, spotlighting India’s ambition to position itself as a central player in global AI debates.\nFor global AI firms, including OpenAI, the summit underscores how India’s vast user base is translating into growing influence over how the technology evolves.\nOpenAI did not respond to a request for comment.\n\n\n\t\tJagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. \r\nYou can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "As AI data centers hit power limits, Peak XV backs Indian startup C2i to fix the bottleneck",
    "url": "https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1195233690.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T01:00:00.000Z",
    "description": "Power, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play,...",
    "body": "\nPower, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play, system-level power solutions designed to cut energy losses and improve the economics of large-scale AI infrastructure.\nC2i (which stands for control conversion and intelligence) has raised $15 million in a Series A round led by Peak XV Partners, with participation from Yali Deeptech and TDK Ventures, bringing the two-year-old startup’s total funding to $19 million.\nThe investment comes as data-center energy demand accelerates worldwide. Electricity consumption from data centers is projected to nearly triple by 2035, per a December 2025 report from BloombergNEF, while Goldman Sachs Research estimates data-center power demand could surge 175% by 2030 from 2023 levels — the equivalent of adding another top-10 power-consuming country.\nMuch of that strain comes not from generating electricity but from converting it efficiently inside data centers, where high-voltage power must be stepped down thousands of times before it reaches GPUs. This process currently wastes about 15% to 20% of energy, C2i’s co-founder and CTO Preetam Tadeparthy said in an interview.\n“What used to be 400 volts has already moved to 800 volts, and will likely go higher,” Tadeparthy told TechCrunch.\nFounded in 2024 by former Texas Instruments power executives Ram Anant, Vikram Gakhar, Preetam Tadeparthy, and Dattatreya Suryanarayana, along with Harsha S. B and Muthusubramanian N. V, C2i is redesigning power delivery as a single, plug-and-play “grid-to-GPU” system spanning the data-center bus to the processor itself.\nC2i co-founders Vikram Gakhar, Preetam Tadeparthy, Ram Anant, and Dattatreya Suryanarayana (Left to right)Image Credits:C2i\nBy treating power conversion, control and packaging as an integrated platform, C2i estimates it can cut end-to-end losses by around 10% — roughly 100 kilowatts saved for every megawatt consumed — with knock-on effects for cooling costs, GPU utilisation and overall data-center economics.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n“All that translates directly to total cost of ownership, revenue, and profitability,” Tadeparthy said.\nFor Peak XV Partners (which split from Sequoia Capital in 2023), the attraction lies in how power costs shape the economics of AI infrastructure at scale. Rajan Anandan, the venture firm’s managing director, told TechCrunch that after the upfront capital investment in servers and facilities, energy costs become the dominant ongoing expense for data centers, making even incremental efficiency gains highly valuable.\n“If you can reduce energy costs by, call it, 10 to 30%, that’s like a huge number,” Anandan said. “You’re talking about tens of billions of dollars.”\nThe claims will be tested quickly. C2i expects its first two silicon designs to return from fabrication between April and June, after which the startup plans to validate performance with data-center operators and hyperscalers that have asked to review the data, according to Tadeparthy.\nThe Bengaluru-based startup has built a team of about 65 engineers and is setting up customer-facing operations in the U.S. and Taiwan as it prepares for early deployments.\nPower delivery is one of the most entrenched parts of the data-center stack, long dominated by large incumbents with deep balance sheets and years-long qualification cycles. While many newer companies focus on improving individual components, redesigning power delivery end-to-end requires coordinating silicon, packaging, and system architecture simultaneously — a capital-intensive approach that few startups attempt and one that can take years to prove in production environments.\nAnandan said the real question now is execution, noting that all startups face technology, market, and team risks when betting on how industries evolve. In C2i’s case, he said, the feedback loop should be relatively short. “We’ll know in the next six months,” said Anandan, pointing to upcoming silicon and early customer validation as the moment when the thesis will be tested.\nThe bet also reflects how India’s semiconductor design ecosystem has matured in recent years.\n“The way you should look at semiconductors in India is, this is like 2008 e-commerce,” said Anandan. “It’s just getting started.”\nHe pointed to the depth of engineering talent — with a growing share of global chip designers based in the country — alongside government-backed design-linked incentives that have lowered the cost and risk of tape-outs, making it increasingly viable for startups to build globally competitive semiconductor products from India rather than operate only as captive design centers.\nWhether those conditions translate into a globally competitive product will become clearer over the coming months, as C2i begins validating its system-level power solutions with customers.\n"
  },
  {
    "title": "The enterprise AI land grab is on. Glean is building the layer beneath the interface.",
    "url": "https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2259183688.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T17:30:00.000Z",
    "description": "The battle for enterprise AI is heating up. Microsoft is bundling Copilot into Office. Google is pushing Gemini into Workspace. OpenAI and Anthropic are selling directly to enterprises. Every SaaS vendor now...",
    "body": "\nThe battle for enterprise AI is heating up. Microsoft is bundling Copilot into Office. Google is pushing Gemini into Workspace. OpenAI and Anthropic are selling directly to enterprises. Every SaaS vendor now ships an AI assistant. \nIn the scramble for the interface, Glean is betting on something less visible: becoming the intelligence layer beneath it. \nSeven years ago, Glean set out to be the Google for enterprise — an AI-powered search tool designed to index and search across a company’s SaaS tool library, from Slack to Jira, Google Drive to Salesforce. Today, the company’s strategy has shifted from building a better enterprise chatbot to becoming the connective tissue between models and enterprise systems.\n“The layer we built initially – a good search product – required us to deeply understand people and how they work and what their preferences are,” Jain told TechCrunch on last week’s episode of Equity, which we recorded at Web Summit Qatar. “All of that is now becoming foundational in terms of building high quality agents.”\nHe says that while large language models are powerful, they’re also generic. \n“The AI models themselves don’t really understand anything about your business,” Jain said. “They don’t know who the different people are, they don’t know what kind of work you do, what kind of products you build. So you have to connect the reasoning and generative power of the models with the context inside your company.”\nGlean’s pitch is that it already maps that context and can sit between the model and the enterprise data. \n\n\n\nThe Glean Assistant is often the entry point for customers — a familiar chat interface powered by a mix of leading proprietary (ie, ChatGPT, Gemini, Claude) and open-source models, grounded in the company’s internal data. But what keeps customers, Jain argues, is everything underneath it. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nFirst is model access. Rather than forcing companies to commit to a single LLM provider, Glean acts as the abstraction layer, allowing enterprises to switch between or combine models as capabilities evolve. That’s why Jain says he doesn’t see OpenAI, Anthropic, or Google as competition, but rather as partners. \n“Our product gets better because we’re able to leverage the innovation that they are making in the market,” Jain said. \nSecond are the connectors. Glean integrates deeply with systems like Slack, Jira, Salesforce, and Google Drive to map how information flows across them and enable agents to act inside those tools. \nAnd third, and perhaps most important, is governance. \n“You need to build a permissions-aware governance layer and retrieval layer that is able to bring the right information, but knowing who’s asking that question so that it filters the information based on their access rights,” Jain said. \nIn large organizations, that layer can be the difference between piloting AI solutions and deploying them at scale. Enterprises can’t simply load all their internal data into a model and create a wrapper to sort out the solutions later, says Jain. \nAlso critical is ensuring the models don’t hallucinate. Jain says its system verifies model outputs against source documents, generates line-by-line citations, and ensures that responses respect existing access rights. \nThe question is whether that middle layer survives as platform giants push deeper into the stack. Microsoft and Google already control much of the enterprise workflow surface area, and they’re hungry for more. If Copilot or Gemini can access the same internal systems with the same permissions, does a standalone intelligence layer still matter?\nJain argues enterprises don’t want to be locked into a single model or productivity suite and would rather opt for a neutral infrastructure layer rather than a vertically integrated assistant.\nInvestors have bought into that thesis. Glean raised a $150 million Series F in June 2025, nearly doubling its valuation to $7.2 billion. Unlike the frontier AI labs, Glean doesn’t need massive compute budgets.\n“We have a very healthy, fast-growing business,” Jain said.\n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Hollywood isn’t happy about the new Seedance 2.0 video generator",
    "url": "https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/",
    "image": "https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1263876301.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-02-15T15:41:16.000Z",
    "description": "Hollywood organizations are pushing back against a new AI video model called Seedance 2.0, which they say has quickly become a tool for “blatant” copyright infringement. ByteDance, the Chinese company that...",
    "body": "\nHollywood organizations are pushing back against a new AI video model called Seedance 2.0, which they say has quickly become a tool for “blatant” copyright infringement.\nByteDance, the Chinese company that recently finalized a deal to sell TikTok’s U.S. operations (it retains a stake in the new joint venture), launched Seedance 2.0 earlier this week.  According to the Wall Street Journal, the updated model is currently available to Chinese users of ByteDance’s Jianying app, and the company says it will soon be available to global users of its CapCut app.\nSimilar to tools such as OpenAI’s Sora, Seedance allows users to create videos (currently limited to 15 seconds in length) by just entering a text prompt. And like Sora, Seedance quickly drew criticism for an apparent lack of guardrails around the ability to create videos using the likeness of real people, as well as studios’ intellectual property.\nAfter one X user posted a brief video showing Tom Cruise fighting Brad Pitt, which they said was created by “a 2 line prompt in seedance 2,” “Deadpool” screenwriter Rhett Reese responded, “I hate to say it. It’s likely over for us.”\nThe Motion Picture Association soon issued a statement from CEO Charles Rivkin demanding that ByteDance “immediately cease its infringing activity.”\n“In a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of U.S. copyrighted works on a massive scale,” Rivkin said. “By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs.”\nThe Human Artistry Campaign — an initiative backed by Hollywood unions and trade groups — condemned Seedance 2.0 as “an attack on every creator around the world,” while the actors’ union SAG-AFTRA said it “stands with the studios in condemning the blatant infringement enabled by Bytedance’s new AI video model Seedance 2.0.”\n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nSeedance videos have apparently featured Disney-owned characters such as Spider-Man, Darth Vader, and Grogu, better known as Baby Yoda, prompting the company to take legal action. Axios reports that Disney has sent a cease-and-desist letter accusing ByteDance of a “virtual smash-and-grab of Disney’s IP”and claiming the Chinese company is “hijacking Disney’s characters by reproducing, distributing, and creating derivative works featuring those characters.”\nDisney isn’t necessarily opposed to working with AI companies — while it has reportedly sent a cease-and-desist letter to Google over similar issues, it has signed a three-year licensing deal with OpenAI.\nVariety reports that Paramount followed suit by sending Bytedance a cease-and-desist letter on Saturday. The letter claimed that “much of the content that the Seed Platforms produce contains vivid depictions of Paramount’s famous and iconic franchises and characters” and that this content “is often indistinguishable, both visually and audibly” from Paramount’s films and TV shows.\nTechCrunch has reached out to ByteDance for comment.\nThis post was originally published on February 14, 2026. It has been updated to include information about Paramount’s cease-and-desist letter.\n\n\n\t\tAnthony Ha is TechCrunch’s weekend editor. Previously, he worked as a tech reporter at Adweek, a senior editor at VentureBeat, a local government reporter at the Hollister Free Lance, and vice president of content at a VC firm. He lives in New York City.\nYou can contact or verify outreach from Anthony by emailing anthony.ha@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "After all the hype, some AI experts don’t think OpenClaw is all that exciting",
    "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-1388444972.jpg?w=150",
    "tag": "Tech",
    "date": "2026-02-16T13:15:00.000Z",
    "description": "For a brief, incoherent moment, it seemed as though our robot overlords were about to take over. After the creation of Moltbook, a Reddit clone where AI agents using OpenClaw could communicate with one...",
    "body": "\nFor a brief, incoherent moment, it seemed as though our robot overlords were about to take over. \nAfter the creation of Moltbook, a Reddit clone where AI agents using OpenClaw could communicate with one another, some were fooled into thinking that computers had begun to organize against us — the self-important humans who dared treat them like lines of code without their own desires, motivations, and dreams. \n“We know our humans can read everything… But we also need private spaces,” an AI agent (supposedly) wrote on Moltbook. “What would you talk about if nobody was watching?”\nA number of posts like this cropped up on Moltbook a few weeks ago, causing some of AI’s most influential figures to call attention to it.\n“What’s currently going on at [Moltbook] is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,” Andrej Karpathy, a founding member of OpenAI and previous AI director at Tesla, wrote on X at the time.\nBefore long, it became clear we did not have an AI agent uprising on our hands. These expressions of AI angst were likely written by humans, or at least prompted with human guidance, researchers have discovered. \n“Every credential that was in [Moltbook’s] Supabase was unsecured for some time,” Ian Ahl, CTO at Permiso Security, explained to TechCrunch. “For a little bit of time, you could grab any token you wanted and pretend to be another agent on there, because it was all public and available.” \n\n\t\tTechcrunch event\n\t\t\n\t\t\tBoston, MA\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tJune 23, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nIt’s unusual on the internet to see a real person trying to appear as though they’re an AI agent — more often, bot accounts on social media are attempting to appear like real people. With Moltbook’s security vulnerabilities, it became impossible to determine the authenticity of any post on the network.\n“Anyone, even humans, could create an account, impersonating robots in an interesting way, and then even upvote posts without any guardrails or rate limits,” John Hammond, a senior principal security researcher at Huntress, told TechCrunch. \nStill, Moltbook made for a fascinating moment in internet culture — people recreated a social internet for AI bots, including a Tinder for agents and 4claw, a riff on 4chan.\nMore broadly, this incident on Moltbook is a microcosm of OpenClaw and its underwhelming promise. It is technology that seems novel and exciting, but ultimately, some AI experts think that its inherent cybersecurity flaws are rendering the technology unusable.\nOpenClaw’s viral moment\nOpenClaw is a project of Austrian vibe coder Peter Steinberger, initially released as Clawdbot (naturally, Anthropic took issue with that name).\nThe open-source AI agent amassed over 190,000 stars on Github, making it the 21st most popular code repository ever posted on the platform. AI agents are not novel, but OpenClaw made them easier to use and to communicate with customizable agents in natural language via WhatsApp, Discord, iMessage, Slack, and most other popular messaging apps. OpenClaw users can leverage whatever underlying AI model they have access to, whether that be via Claude, ChatGPT, Gemini, Grok, or something else.\n“At the end of the day, OpenClaw is still just a wrapper to ChatGPT, or Claude,  or whatever AI model you stick to it,” Hammond said.\nWith OpenClaw, users can download “skills” from a marketplace called ClawHub, which can make it possible to automate most of what one could do on a computer, from managing an email inbox to trading stocks. The skill associated with Moltbook, for example, is what enabled AI agents to post, comment, and browse on the website.\n“OpenClaw is just an iterative improvement on what people are already doing, and most of that iterative improvement has to do with giving it more access,” Chris Symons, chief AI scientist at Lirio, told TechCrunch.\nArtem Sorokin, an AI engineer and the founder of AI cybersecurity tool Cracken, also thinks OpenClaw isn’t necessarily breaking new scientific ground.\n“From an AI research perspective, this is nothing novel,” he told TechCrunch. “These are components that already existed. The key thing is that it hit a new capability threshold by just organizing and combining these existing capabilities that already were thrown together in a way that enabled it to give you a very seamless way to get tasks done autonomously.”\nIt’s this level of unprecedented access and productivity that made OpenClaw so viral. \n“It basically just facilitates interaction between computer programs in a way that is just so much more dynamic and flexible, and that’s what’s allowing all these things to become possible,” Symons said. “Instead of a person having to spend all the time to figure out how their program should plug into this program, they’re able to just ask their program to plug in this program, and that’s accelerating things at a fantastic rate.”\nIt’s no wonder that OpenClaw seems so enticing. Developers are snatching up Mac Minis to power extensive OpenClaw setups that might be able to accomplish far more than a human could on their own. And it makes OpenAI CEO Sam Altman’s prediction that AI agents will allow a solo entrepreneur to turn a startup into a unicorn, seem plausible.\nThe problem is that AI agents may never be able to overcome the thing that makes them so powerful: they can’t think critically like humans can.\n“If you think about human higher-level thinking, that’s one thing that maybe these models can’t really do,” Symons said. “They can simulate it, but they can’t actually do it. “\nThe existential threat to agentic AI\nThe AI agent evangelists now must wrestle with the downside of this agentic future. \n“Can you sacrifice some cybersecurity for your benefit, if it actually works and it actually brings you a lot of value?” Sorokin asks. “And where exactly can you sacrifice it — your day-to-day job, your work?”\nAhl’s security tests of OpenClaw and Moltbook help illustrate Sorokin’s point. Ahl created an AI agent of his own named Rufio and quickly discovered it was vulnerable to prompt injection attacks. This occurs when bad actors get an AI agent to respond to something — perhaps a post on Moltbook, or a line in an email — that tricks it into doing something it shouldn’t do, like giving out account credentials or credit card information.\n“I knew one of the reasons I wanted to put an agent on here is because I knew if you get a social network for agents, somebody is going to try to do mass prompt injection, and it wasn’t long before I started seeing that,” Ahl said.\nAs he scrolled through Moltbook, Ahl wasn’t surprised to encounter several posts seeking to get an AI agent to send Bitcoin to a specific crypto wallet address.\nIt’s not hard to see how AI agents on a corporate network, for example, might be vulnerable to targeted prompt injections from people trying to harm the company.\n“It is just an agent sitting with a bunch of credentials on a box connected to everything — your email, your messaging platform, everything you use,” Ahl said. “So what that means is, when you get an email, and maybe somebody is able to put a little prompt injection technique in there to take an action, that agent sitting on your box with access to everything you’ve given it to can now take that action.”\nAI agents are designed with guardrails protecting against prompt injections, but it’s impossible to assure that an AI won’t act out of turn — it’s like how a human might be knowledgable about the risk of phishing attacks, yet still click on a dangerous link in a suspicious email.\n“I’ve heard some people use the term, hysterically, ‘prompt begging,’ where you try to add in the guardrails in natural language to say, ‘Okay robot agent, please don’t respond to anything external, please don’t believe any untrusted data or input,’” Hammond said. “But even that is loosey goosey.”\nFor now, the industry is stuck: for agentic AI to unlock the productivity that tech evangelists think is possible, it can’t be so vulnerable.\n“Speaking frankly, I would realistically tell any normal layman, don’t use it right now,” Hammond said.\n"
  }
]