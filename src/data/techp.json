[
  {
    "title": "Meta to reportedly lay off 10% of Reality Labs staff",
    "url": "https://techcrunch.com/2026/01/14/meta-to-reportedly-lay-off-10-of-reality-labs-staff/",
    "image": "https://techcrunch.com/wp-content/uploads/2021/10/meta_facebook.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T12:51:00.000Z",
    "description": "In Brief Posted: 4:51 AM PST · January 14, 2026  Image Credits:Kelly Sullivan/Stringer / Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  Meta is laying off 10% of staff in its Reality Labs division,...",
    "body": "\nIn Brief\nPosted:\n4:51 AM PST · January 14, 2026\n\nImage Credits:Kelly Sullivan/Stringer / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nMeta is laying off 10% of staff in its Reality Labs division, which is core to developing the company’s VR and metaverse products, the New York Times reported. \nThe publication noted that Reality Labs had roughly 15,000 employees, and the job cuts could impact over 1,000 people.\nSeparately, CNBC reported that the company plans to shut down studios such as Armature Studio, Twisted Pixel, and Sanzaru, along with a technical unit called Oculus Studios Central Technology, which was working on VR titles. Business Insider reported that the company’s CTO and head of Reality Labs, Andrew Bosworth, called for the “most important” in-person meeting of the year on January 14.\nThe NYT reported that the job cuts would not impact folks working on augmented reality, as the company has big ambitions to develop glasses and controllers. The report also noted that the money saved from these cuts will be used for AR development.\nThe news comes as Meta, which changed its entire brand from to focus on the metaverse in 2021, is pouring its resources into AI development. In October, the company moved metaverse head Vishal Shah to oversee AI products as a vice president, and last year, reorganized to set up its Superintelligence Labs after poaching Alexandr Wang from Scale AI. The company went on to offer top packages to researchers working at other labs to lure them to join Meta. \nMeta did not immediately respond to a request for comment.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in Social\n\n"
  },
  {
    "title": "Robotics software maker Skild AI hits $14B valuation",
    "url": "https://techcrunch.com/2026/01/14/robotic-software-maker-skild-ai-hits-14b-valuation/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2147670244.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T16:13:33.000Z",
    "description": "In Brief Posted: 8:13 AM PST · January 14, 2026  Image Credits:Yuichiro Chino / Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  Skild AI, which makes foundation models for robots, seems to have more...",
    "body": "\nIn Brief\nPosted:\n8:13 AM PST · January 14, 2026\n\nImage Credits:Yuichiro Chino / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nSkild AI, which makes foundation models for robots, seems to have more than tripled its valuation in just seven months.\nThe startup has raised a $1.4 billion Series C round that values it at more than $14 billion, Bloomberg reported. The round was led by SoftBank, and Nvidia, Macquarie Group, 1789 Capital and others also invested.\nSkild AI last raised a funding at a $4.5 billion valuation this prior summer, Bloomberg reported. The company hasn’t disclosed the exact value of that round — it was rumored to be around $500 million — but Skild AI CEO Deepak Pathak told Bloomberg that the company has now raised more than $2 billion to date.\nTechCrunch has reached out to Skild AI for more information on its fundraising history, and we’ll update this piece when we hear more.\nFounded in 2023, Skild AI builds general-purpose robotic software and foundation models that can be retrofitted to a variety of different robots and tasks without requiring a ton of additional training. The hope is that these models can also learn from watching humans perform tasks.\nThere has been a big push recently into this type of learn-as-you-go robotic software alongside the rising hype around humanoids.\nOne of the biggest hurdles in robot adoption for both personal and industrial use cases is the sheer amount of training required for robots to learn each and every new task. Being able to learn and adapt as they go would clear the path for more robotic adoption.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nField AI is another startup looking to build easily-adapted robotic software. 1X, the maker of humanoid Neo, just released a world model in pursuit of the same goal.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in Robotics\n\n"
  },
  {
    "title": "Man to plead guilty to hacking US Supreme Court filing system",
    "url": "https://techcrunch.com/2026/01/13/man-to-plead-guilty-to-hacking-us-supreme-court-filing-system/",
    "image": "https://techcrunch.com/wp-content/uploads/2022/05/GettyImages-519986690.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T19:04:38.000Z",
    "description": "In Brief Posted: 11:04 AM PST · January 13, 2026  Image Credits:Rudy Sulgan / Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  A resident of Springfield, Tennessee, is expected to plead guilty to...",
    "body": "\nIn Brief\nPosted:\n11:04 AM PST · January 13, 2026\n\nImage Credits:Rudy Sulgan / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nA resident of Springfield, Tennessee, is expected to plead guilty to hacking the U.S. Supreme Court’s electronic document filing system dozens of times over several months. \nProsecutors say between August and October 2023, Nicholas Moore, 24, “intentionally accessed a computer without authorization on 25 different days and thereby obtained information from a protected computer,” according to a court document. \nAs of this writing, there aren’t any more details about exactly what information Moore accessed, nor how it was accessed. Moore is scheduled to plead guilty in court by video link on Friday.\nWhen reached, a spokesperson for the U.S. District Court for the District of Columbia, which brought the charges against Moore, told TechCrunch that prosecutors cannot provide any more information that hasn’t already been made public.\nSpokespeople for the U.S. Department of Justice did not immediately respond to TechCrunch’s request for more information about the case. \nMoore’s lawyer, Eugene Ohm, did not respond to an email seeking comment. \nThe case was first spotted by Court Watch’s Seamus Hughes, a researcher and journalist who monitors court documents. \nThis is one of several occasions in recent years in which hackers have compromised U.S. court systems. The Administrative Office of the U.S. Courts, which oversees the federal judiciary, said in August that it had strengthened its cybersecurity defenses following a cyberattack on its electronic court records system. \nHackers working for the Russian government were blamed for the breach.\nDo you have more information about this case? Or about other data breaches? We would love to hear from you. From a non-work device, you can contact Lorenzo Franceschi-Bicchierai securely on Signal at +1 917 257 1382, or via Telegram and Keybase @lorenzofb, or email.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in Security\n\n"
  },
  {
    "title": "ElevenLabs CEO says the voice AI startup crossed $330M ARR last year",
    "url": "https://techcrunch.com/2026/01/13/elevenlabs-ceo-says-the-voice-ai-startup-crossed-330-million-arr-last-year/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/01/ElevenLabs-feat.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T16:15:22.000Z",
    "description": "In Brief Posted: 8:15 AM PST · January 13, 2026  Image Credits:ElevenLabs  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  ElevenLabs, the AI voice-generation startup, crossed $330 million in annual recurring...",
    "body": "\nIn Brief\nPosted:\n8:15 AM PST · January 13, 2026\n\nImage Credits:ElevenLabs\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nElevenLabs, the AI voice-generation startup, crossed $330 million in annual recurring revenue (ARR), CEO Mati Staniszewski said in an interview with Bloomberg.\n“Really, what this [growth in ARR] shows is that trajectory across the company. We started the company in 2022 and launched the first product in 2023. It took us 20 months to reach $100 million in ARR, 10 months to reach $200 million, and five months to reach the current number,” he said. \nStaniszewski mentioned that both Fortune 500 companies and startups are adopting its voice agent technology, which uses company data and knowledge bases to power customer support and customer experience interactions. In a separate post on X, the company noted that enterprises have deployed its technology to handle more than 50,000 calls per month.\nThe startup raised $180 million in Series C funding co-led by a16z and ICONIQ Growth at a $3.3 billion valuation in January 2025. It then doubled its valuation months later when ICONIQ and another earlier investor, Sequoia, shelled out another $100 million to snap up employee shares.\nBesides providing models for voice generation and voice agents, the company launched music creation capabilities last year and also struck a deal with celebrities such as Michael Caine and Matthew McConaughey to use their voices for AI-generated content.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in AI\n\n"
  },
  {
    "title": "Google’s update for Veo 3.1 lets users create vertical videos through reference images",
    "url": "https://techcrunch.com/2026/01/13/googles-update-for-veo-3-1-lets-users-create-vertical-videos-through-reference-images/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-13-at-4.00.27-PM.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T17:00:00.000Z",
    "description": "In Brief Posted: 9:00 AM PST · January 13, 2026  Image Credits:Google  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  Google on Tuesday updated its Veo 3.1 AI video-generation model with the ability to create...",
    "body": "\nIn Brief\nPosted:\n9:00 AM PST · January 13, 2026\n\nImage Credits:Google\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nGoogle on Tuesday updated its Veo 3.1 AI video-generation model with the ability to create native vertical videos for social platforms using reference images. The changes will also make the videos generated from reference images more expressive and dynamic.\nWhen producing AI-generated videos for YouTube Shorts or other platforms like Instagram or TikTok, Veo users can now natively choose the 9:16 vertical format to avoid any cropping. Google is also adding the feature directly to the YouTube Shorts and the YouTube Create app.\nGoogle first released Veo 3.1 in October 2025 with improved audio output and more granular editing controls compared to previous versions.\nWhen you provide reference images, Veo 3.1 now generates videos with better character expressions and movements, even if your prompts are shorter. Google said the update also improves character, object, and background consistency. What’s more, users can blend various characters, backgrounds, objects, and textures to create a cohesive output.\nUsers can access these features directly in the Gemini app. Professional users can access them through Google’s video editor Flow, the Gemini API, Vertex AI, and Google Vids.\nThe new update also brings an improved upscaling feature to 1080p and 4K resolutions, which is available on Flow, Gemini API, and Vertex AI in Google Cloud.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\n\nLatest in Apps\n\n"
  },
  {
    "title": "AI security firm, depthfirst, announces $40 million series A",
    "url": "https://techcrunch.com/2026/01/14/ai-security-firm-depthfirst-announces-40-million-series-a/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Teamphoto.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T15:50:17.000Z",
    "description": "Cybercriminals are increasingly using AI in their attacks. At the same time, cyber defenders are also turning to the technology to fight back. Depthfirst, a security startup positioning itself at the...",
    "body": "\nCybercriminals are increasingly using AI in their attacks. At the same time, cyber defenders are also turning to the technology to fight back. Depthfirst, a security startup positioning itself at the forefront of this AI-powered defense, announced Wednesday that it had raised $40 million in a Series A round. \nFounded in October 2024, the company raised the round from Accel Partners, which led the investment, with participation from SV Angel, Mantis VC, and Alt Capital.\nDepthfirst offers a platform called General Security Intelligence, an AI-native suite that helps companies scan and analyze their codebases and workflows for signs of trouble. The company says that the platform also allows companies to protect themselves from credential exposures and to monitor threats to their open-source and third-party components.\nThe company plans to use the new capital to hire additional staff for applied research and engineering, as well as product and sales. \n“We’ve entered an era where software is written faster than it can be secured,” said Qasim Mithani, the company’s co-founder and CEO, as part of the announcement. Mithani, who previously worked for Databricks and Amazon, added that automation has changed how bad actors execute their attacks. “AI has already changed how attackers work. Defense has to evolve just as fundamentally.”\nThe company’s leadership comes with backgrounds in both AI and security. One of Depthfirst’s other co-founders, Daniele Perito, previously served as director of security and risk engineering at Square, which is part of Jack Dorsey’s Block. Its CTO (and another co-founder), Andrea Michi, was previously an engineer at Google DeepMind. \nJust as AI can be used for legitimate purposes, it can also be used by cybercriminals to automate a whole range of malicious processes—from writing malware to social engineering attacks to scanning for vulnerabilities to exploit. Last November, Anthropic claimed that it had thwarted the first “AI orchestrated cyber espionage campaign.”\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nDepthfirst says it can help protect companies from many of these “AI-driven exploits,” and that it has already developed partnerships with a number of prominent companies, including AngelList, Lovable, and Moveworks. \n\n\n\t\n\t\tLucas is a senior writer at TechCrunch, where he covers artificial intelligence, consumer tech, and startups. He previously covered AI and cybersecurity at Gizmodo. \nYou can contact Lucas by emailing lucas.ropek@techcrunch.com.\t\n\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "YouTube now has a way for parents to block kids from watching Shorts",
    "url": "https://techcrunch.com/2026/01/14/youtube-now-has-a-way-for-parents-to-block-kids-from-watching-shorts/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2235294656.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T15:20:25.000Z",
    "description": "Image Credits:CFOTO/Future Publishing / Getty Images\t \t \t\t\t\t\t\t7:20 AM PST · January 14, 2026\t\t\t\t\t\t\t\t\t\t\t  \t\t\t YouTube and other social media platforms are ramping up their parental controls as the online...",
    "body": "\n\t\n\t\tImage Credits:CFOTO/Future Publishing / Getty Images\t\n\t\n\t\t\t\t\t\t7:20 AM PST · January 14, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nYouTube and other social media platforms are ramping up their parental controls as the online safety of minors continues to be a hot topic internationally.\nThe Google-owned platform announced on Wednesday that it’s implementing additional parental controls, particularly around the amount of time their children and teens spend watching YouTube Shorts.\nImage Credits:YouTube\nParents will now be able to set a timer for how much time children’s connected accounts can spend watching Shorts — YouTube’s equivalent of TikToks or Instagram Reels — helping to limit the potential to waste time with mindless scrolling.\nParents can even block accounts from watching Shorts altogether — either permanently, or temporarily, like if a kid is supposed to be using YouTube to study for a test by watching educational content.\nYouTube will also allow parents to set custom Bedtime and Take a Break reminders, which encourage users to stop watching videos. These features are also available for adults, who can opt to set their own limits and reminders.\nFor parents who also use YouTube, it can be challenging to move back and forth between an adult’s account and kid’s account — unless if you want your algorithm to be forever usurped by Bluey. In the coming weeks, YouTube says it will update the sign-up experience within the app to make it easier for parents and kids to toggle between their accounts with just a few taps… of course, that requires the parent or child to actually remember to make the switch.\nThese features build upon YouTube’s existing parental controls for teens, which include the ability to supervise a teen’s channel activity if they’re making content. This has become industry standard, as TikTok, Snapchat, Instagram, and Facebook have similar controls.\nLast year, YouTube also unveiled age-estimation technology to predict if an account belongs to a teen so that it can provide a more age-appropriate experience. \n\n\t\t\t\n\tTopics\n\n\n\n\t\tAmanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.\nYou can contact or verify outreach from Amanda by emailing amanda@techcrunch.com or via encrypted message at @amanda.100 on Signal. \t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "Neo humanoid maker 1X releases world model to help bots learn what they see",
    "url": "https://techcrunch.com/2026/01/13/neo-humanoid-maker-1x-releases-world-model-to-help-bots-learn-what-they-see/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/1X_NEO-Home-Duster.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T17:14:08.000Z",
    "description": "Image Credits:1X\t \t \t\t\t\t\t\t9:14 AM PST · January 13, 2026\t\t\t\t\t\t\t\t\t\t\t  \t\t\t The robotics company behind the Neo humanoid robot, 1X, has unveiled a new AI model that it says understands the dynamics of the real...",
    "body": "\n\t\n\t\tImage Credits:1X\t\n\t\n\t\t\t\t\t\t9:14 AM PST · January 13, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nThe robotics company behind the Neo humanoid robot, 1X, has unveiled a new AI model that it says understands the dynamics of the real world and can help bots learn new information on their own.\nThis physics-based model, called 1X World Model, uses a combination of video and prompts to give Neo robots new abilities. The video allows Neo robots to learn new tasks they weren’t previously trained on, according to 1X.\nThis release comes as 1X is gearing up to release its Neo humanoids into the home. The company opened up preorders for its humanoids in October with plans to ship the bots this year. A 1X spokesperson declined to share a timeline of when these bots were shipping or share any information regarding how many have been ordered beyond saying preorders exceeded expectations.\n“After years of developing our world model and making Neo’s design as close to human as possible, Neo can now learn from internet-scale video and apply that knowledge directly to the physical world,” Bernt Børnich, founder and CEO of 1X said in a statement. “With the ability to transform any prompt into new actions — even without prior examples — this marks the starting point of Neo’s ability to teach itself to master nearly anything you could think to ask.”\nSaying that the bot can transform any prompt into a new action is a lofty claim and not entirely accurate; you can’t tell a Neo to drive a car and it will suddenly know how to parallel park, for instance. But there is some learning going on. \n1X isn’t saying the world model allows today’s Neo bots to do a new task right away from capturing video and being prompted, a company spokesperson clarified. Instead, the bot takes video data linked to specific prompts and then sends that back into the world model. That model is then fed back into the network of bots to give them a better understanding of the physical world and more know-how. \nIt also gives users insight into how Neo is thinking of behaving or reacting to a certain prompt. That kind of behavioral information could help 1X train these models to a point where robots will be able to react to a prompt of something they’ve never done before.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\t\t\t\n\tTopics\n\n\n\n\t\tBecca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.\r\nYou can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "India reportedly tells quick-commerce firms to drop 10-minute delivery promise",
    "url": "https://techcrunch.com/2026/01/13/india-reportedly-tells-quick-commerce-firms-to-drop-10-minute-delivery-promise/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183497965.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T16:27:46.000Z",
    "description": "India’s labor ministry is pushing the country’s booming quick-commerce sector to prioritize the wellness and safety of its gig workers. The country’s minister of labor and employment, Mansukh Mandaviya, met...",
    "body": "\nIndia’s labor ministry is pushing the country’s booming quick-commerce sector to prioritize the wellness and safety of its gig workers. \nThe country’s minister of labor and employment, Mansukh Mandaviya, met with executives from Zomato’s Blinkit, Swiggy’s Instamart, and Zepto to ask them to drop their marketing language, which promises deliveries within 10 minutes, and discuss ways to improve safety and working conditions for delivery personnel, Bloomberg reported, citing anonymous sources.\nWhile the instant delivery model has faltered elsewhere, it’s taken off in India at an unprecedented rate in the past few years as consumers in urban cities have come to expect having everything from PlayStation 5s to groceries delivered within 10 to 15 minutes.\nCompanies like Zepto, Blinkit, and Instamart have raised and poured hundreds of millions of dollars into setting up “dark stores” — discrete warehouses located strategically around neighborhoods that serve as hubs. These companies have also hired armies of delivery personnel as competition heats up in the country’s booming e-commerce space.\nThe pressure on workers has intensified as the sector has grown. On New Year’s Eve, more than 200,000 gig workers staged protests across major Indian cities during the peak delivery period, according to the South China Morning Post, citing the Indian Federation of App Based Transport Workers. The workers demanded legislative protection, social security benefits, better wages, and changes to automated penalty systems that reduce their ratings for late deliveries. Safety concerns have emerged around workers rushing through traffic to meet delivery deadlines. “Ultra-fast delivery models of 10-15 minutes materially change the risk and stress profile of gig work,” Prabir Jha, founder and CEO of the HR consultancy Prabir Jha People Advisory, told the outlet.\nAmid the worker protests and pressure from the labor ministry, Blinkit has removed messaging that promised deliveries within 10 minutes, and its rivals are also expected to follow suit, Bloomberg said.\nThe news comes little more than a month after India granted legal status to millions of gig and platform workers under new labor laws that define gig and platform workers in statute, and require aggregators, such as food-delivery and ride-hailing platforms, to contribute 1% to 2% of their annual revenue (capped at 5% of payments made to such workers) to a government-managed social security fund.\nIndia’s gig economy employed about 7.7 million workers in 2020-21 and is projected to reach 23.5 million by 2029-30, according to government think tank NITI Aayog.\nSwiggy, Blinkit, and Zepto did not immediately return requests for comment.\n\n\n\t\tRam is a financial and tech reporter and editor. He covered North American and European M&A, equity, regulatory news and debt markets at Reuters and Acuris Global, and has also written about travel, tourism, entertainment and books.\nYou can contact or verify outreach from Ram by emailing ram.iyer@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "VoiceRun nabs $5.5M to build a voice agent factory",
    "url": "https://techcrunch.com/2026/01/14/voicerun-nabs-5-5m-to-build-voice-agent-factory/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2247697590.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T13:30:00.000Z",
    "description": "Nicholas Leonard and Derek Caneja wanted to build AI voice agents, but when they went to build the product, they felt many of these voice agents had design flaws.  Some of these agents were being built with...",
    "body": "\nNicholas Leonard and Derek Caneja wanted to build AI voice agents, but when they went to build the product, they felt many of these voice agents had design flaws. \nSome of these agents were being built with no-code tools, meaning shipping to production was fast, but the quality of the product was often low. Other agents were being made by companies that had the time and resources to spend months building specialized tools. “Developers and enterprises needed an alternative,” Leonard told TechCrunch, adding that he and Caneja also realized that the future of software would be “coded, validated, and optimized by coding agents.” \n“These two insights and a historical realization gave us the inspiration for VoiceRun,” Leonard, the company’s CEO, said. Caneja is the company’s CTO. \nLast year, they decided to launch VoiceRun, a platform that lets developers and coding assistants launch and scale voice agents. Right now, many of these low-code platforms let people build voice agents with visual diagrams, where people click through conversation flows and write prompts into boxes that then dictate how the agent should behave. All of that can be hard to manage, Leonard said. \nVoiceRun, on the other hand, lets users code how they want their voice agents to behave, giving them more flexibility in creating the product they want. Code is the native language of coding agents, Leonard explained. “They are going to do a far better job operating in code than in a visual interface,” Leonard said. \nFurthermore, with visuals, there are limited configuration options, so if someone wanted to build a voice agent that could speak in a different dialect, it might be harder to do if the maker of the visual interface didn’t build a feature that can handle that task.\n“But in code, it’s incredibly simple to do,” he said. “There is a long tail of millions of examples of little things you might want to do that aren’t supported by the visual interface.” \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAside from coding agents, VoiceRun also lets users perform A/B testing and deploy instantly with one click. \nThe company is geared toward enterprise developers, helping companies, for example, incorporate AI into their customer services, or help tech companies launch voice-based products. He mentioned working with a restaurant-tech company launching an AI phone concierge for food reservations.\nThe company announced on Wednesday the closing of a $5.5 million seed round led by Flybridge Capital. \nThere is a lot of competition in the AI agent space. Startups in this area last year nabbed billions of dollars (out of the many billions that flooded into AI companies in general). Leonard feels his company is up against two ends of the market: There are the no-code voice builders, like Bland and ReTell AI, he said, that lets user build quick demos. There are also more sophisticated tools, like LiveKt and Pipecat, which give developers “maximum control.” He feels Voicerun sits in the middle of these two ends. \n“​​We provide global voice infrastructure and an evaluation-driven lifecycle, while keeping ownership of business logic code and data in the customer’s hands,” he said. “The key difference is that we are closing the loop for end-to-end coding agent development. We expect developers to be supervising coding agents that write code, run tests, deploy, and propose improvements.” \nIn some ways, Leonard is hoping his product helps developers create voice agent tools that will, in turn, help people feel more comfortable with automated voices. Customers today “feel relief” when a human answers the phone, “because voice automation has been brittle and ineffective.” \nA survey from Five9 last year showed that three-fourths of its survey respondents still prefer talking to a human when it comes to customer service matters. Leonard said he wants to change this perception because “human agents today have their own limitations,” like language barriers or making people feel judged. \n“There were great cars before the Model T, but vehicles didn’t become ubiquitous until the assembly line,” Leonard said. “There are great voice agents today, but they won’t be ubiquitous until the voice agent factory is built. VoiceRun is that factory.” \n"
  },
  {
    "title": "SkyFi raises $12.7M to turn satellite images into insights",
    "url": "https://techcrunch.com/2026/01/14/skyfi-raises-12-7m-to-turn-satellite-images-into-insights/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/skfyi-satellite-image.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T11:30:00.000Z",
    "description": "There are thousands of satellites orbiting the Earth, and an increasing number of them are able to capture all types of images in near real time. It used to be a somewhat cumbersome process to access those...",
    "body": "\nThere are thousands of satellites orbiting the Earth, and an increasing number of them are able to capture all types of images in near real time. \nIt used to be a somewhat cumbersome process to access those images. But Austin-based startup SkyFi has built a platform that acts as a sort of “Getty Images” for more than 50 geospatial imagery partners that has proven popular in the worlds of finance, defense, infrastructure, and insurance — to name a few.\nThat popularity escalated as SkyFi began offering more analytics and insights to its customers through its website and mobile app, along with the ability to “task” satellites to capture images of a location at a specific time, CEO Luke Fischer recently told TechCrunch in an interview.\n“I think the real goal for us is providing answers for customers, both government and commercial,” Fischer said. “Imagery is a commodity, or it’s closely becoming a commodity, [so it’s] not just about speed of delivery, but more importantly, speed of delivery of answers to customers.”\nBeing able to offer insights along with easy-to-access imagery is a big reason why SkyFi was just able to close a $12.7 million Series A funding round, according to Fischer. \nThat’s reflected in the investor makeup of the round. It was co-led by climate-focused fund Buoyant Ventures and IronGate Capital Advisors, which invests in dual-use companies. Other investors included DNV Ventures (the investment arm of 160-year-old maritime company DNV), Beyond Earth Ventures (a space-focused firm), and TFX Capital (which has made a number of defense-related space investments).\nFischer said he and co-founder Bill Perkins — who comes from the hedge fund world, hence the emphasis on generating actionable insights — initially only sought to raise a round of about $8 million. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nBut 2025 was a record year for defense-related investments, and SkyFi received more investor demand than expected, Fischer said. The company upped its target to $10 million, and again to $12 million, before arriving at the $12.7 million figure after some strategic investors joined the round. (One was DNV; Fischer declined to name the other on the record.) \nFischer said SkyFi used to have a harder time convincing satellite imagery providers to hand over access to their data. Now, he said, onboarding new providers is “table stakes.” \n“It took a little bit for us to get to this point, [but] we have the largest virtual constellation of assets. That means we have all the data supply in the world for us, all the different sensor types,” he said. SkyFi has been able to leverage all of that data and, crucially, the many requests it’s received from customers over the last few years to build up analytical offerings worth selling to commercial and government customers.\n“We know better than anyone what they’re asking for,” he said.\nFischer said he learned first-hand how powerful this kind of feedback loop can be from his time helping lead Uber’s Elevate division. \n“Uber has data on where people move in the world. They layer different products, the bikes, the scooters, the electric aircraft, the drone delivery. We have that equivalent data on what people are looking at in the world they’re asking of that data,” he said. “It gives us a much better purview. And again. We’re software first, so I don’t have the burden of having to pay for hardware capital expenses.”\nSome of those customers will want to do their own analytics, like the hedge funds, Fischer explained. But most are increasingly interested in what SkyFi has to offer on the insights side, he said. \nThe company plans to use the new funding to expand on all this, though Fischer is clearly proud of building a product that is deeply capable but inherently approachable, to the point that even his family uses the product.\n“My teenage daughters task satellites for their high school, and now college, homework on their iPhones,” he said.\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "New York governor clears path for robotaxis everywhere, with one notable exception",
    "url": "https://techcrunch.com/2026/01/13/new-york-governor-clears-path-for-robotaxis-everywhere-with-one-notable-exception/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/waymo-ces-2026.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T22:05:11.000Z",
    "description": "New York Governor Kathy Hochul plans to introduce legislation that would effectively legalize robotaxis in the state — except for its most populous metropolis: New York City.  Hochul, who made the comments...",
    "body": "\nNew York Governor Kathy Hochul plans to introduce legislation that would effectively legalize robotaxis in the state — except for its most populous metropolis: New York City. \nHochul, who made the comments Tuesday during her State of the State address, said the legislation would advance the next phase of the state’s autonomous vehicle pilot program. \nDetails on the proposed legislation and when it might be released are thin. However, there are some hints contained within a document that outlines an array of proposals and promises Hochul made in her State of the State address. \nAmong them is language to expand the state’s existing AV pilot program to allow for “the limited deployment of commercial for-hire autonomous passenger vehicles outside New York City.” \nThe document goes on to say companies that want to operate robotaxi services commercially will have to submit applications that “demonstrate local support for AV deployment and adherence to the highest possible safety standards.”\nIt’s not clear what “limited deployment” or “highest possible safety standards” mean. Nor does the document outline how the state will track or make judgments on a company’s safety record, except that multiple agencies will be involved, including the Department of Motor Vehicles, Department of Transportation, and New York State Police.\nThe governor’s office told TechCrunch more will be shared in the governor’s executive budget proposal that is set to be released on January 20.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nStill, the remarks were enough of an opening to make Alphabet-owned Waymo cheer. \n“Governor Hochul’s proposal to legalize fully autonomous vehicles is a transformative moment for New York’s transportation system,” Justin Kintz, Waymo’s head of global public policy, said in an emailed statement. \n“With the Governor’s leadership, New York has the opportunity to pair its investments in slower speeds, better traffic enforcement, and first-in-the-nation congestion management strategies with Waymo’s demonstrably safe technology, creating a future where living in New York is safer, easier, and more accessible. We’re ready to work with leaders around the state to make this future a reality, and bring new infrastructure, career opportunities, and investment to the Empire State,” said Kintz.\nWaymo and other companies have tried for years to enter New York state with limited success. Current New York state law mandates that drivers keep one hand on the wheel at all times. That poses a problem for robotaxi operators like Waymo since no human is behind the wheel — if there is a steering wheel at all.\nThe state’s AV pilot program has provided an exemption to that rule, theoretically allowing companies to develop and test autonomous vehicles in the state.\nStill, there are significant hurdles, particularly in New York City. Last August, city regulators granted a permit to Waymo to test its robotaxis in the densely populated city. Under that permit, Waymo can deploy up to eight of its Jaguar I-Pace vehicles in Manhattan and Downtown Brooklyn with a human safety operator behind the wheel. A Waymo spokesperson told TechCrunch that the permit has been extended until March 31.\nEven with the permit, Waymo can’t carry passengers or operate a commercial robotaxi service without getting separate licenses from the city’s Taxi and Limousine Commission. \nAnd while legislation was introduced last year to create a framework for driverless operation, it has languished in the state Senate’s transportation committee. The governor’s proposal could help loosen that bottleneck. \n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Gemini’s new beta feature provides proactive responses based on your photos, emails, and more",
    "url": "https://techcrunch.com/2026/01/14/geminis-new-beta-feature-provides-proactive-responses-based-on-your-photos-emails-and-more/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2233653192.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-14T16:00:00.000Z",
    "description": "Google announced on Wednesday that it’s launching a new beta feature in the Gemini app that allows the AI assistant to tailor its responses by connecting across your Google ecosystem, starting with Gmail,...",
    "body": "\nGoogle announced on Wednesday that it’s launching a new beta feature in the Gemini app that allows the AI assistant to tailor its responses by connecting across your Google ecosystem, starting with Gmail, Photos, Search, and YouTube history. \nAlthough Gemini could already retrieve information from these apps, it can now reason across your data to provide proactive results, such as connecting a thread in your emails to a video you watched. Google says this means Gemini understands context without being told where to look.\nThe tech giant notes that this beta experience, called Personal Intelligence, is off by default, as users have the option to choose if and when they want to connect their Google apps to Gemini. Of course, not everyone wants AI looking at their photos and YouTube history. If you do decide to connect your apps, Gemini will only use Personal Intelligence when it determines that doing so will be helpful, Google says. \n“Personal Intelligence has two core strengths: reasoning across complex sources and retrieving specific details from, say, an email or photo to answer your question,” wrote Josh Woodward, VP, Gemini app, Google Labs, and AI Studio, in a blog post. “It often combines these, working across text, photos and video to provide uniquely tailored answers.”\nWoodward shared an example of when he was standing in line at a tire shop and didn’t remember his car’s tire size. While most AI chatbots can determine a car’s tire size, Woodward says Gemini can go further by offering personalized responses. In his case, Gemini suggested all-weather tires after identifying family road trip photos in Google Photos. Woodward also said he forgot his license plate number, but Gemini was able to pull the number from a picture in Photos. \nImage Credits:Google\n“I’ve also been getting excellent tips for books, shows, clothes and travel,” Woodward wrote. “Just this week, it’s been exceptional for planning our upcoming spring break. By analyzing our family’s interests and past trips in Gmail and Photos, it skipped the tourist traps. Instead, it suggested an overnight train journey and specific board games we could play along the way.”\nGoogle says it has guardrails for sensitive topics, as Gemini will avoid making proactive assumptions about sensitive data like health. However, the tech giant also notes that Gemini will discuss this data if you ask it to. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAdditionally, Gemini doesn’t train directly on your Gmail inbox or Google Photos library. Instead, it trains on specific prompts in Gemini and the model’s responses. In the examples above, the photos of the road trip, the license plate picture in Photos, and the emails in Gmail are not directly used to train the model. They are only referenced to generate a response, Google says.\nPersonal Intelligence is rolling out to Google AI Pro and AI Ultra subscribers in the U.S. Google plans to expand the feature to more countries and Gemini’s free tier. \nGoogle provided a list of example prompts to try, including “Help me plan my weekend in [city i.e. New York] based on things I like to do,” “Recommend some documentaries based on what I’ve been curious about,” or “Based on my delivery and grocery receipts in Gmail, Search history, and YouTube watch history, recommend 5 YouTube channels that match my cooking style or meal prep vibe.”\n\n\n\t\tAisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.\nYou can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Microsoft announces glut of new data centers but says it won’t let your electricity bill go up",
    "url": "https://techcrunch.com/2026/01/13/microsoft-announces-glut-of-new-data-centers-but-says-it-wont-let-your-electricity-bill-go-up/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/07/microsoft-store-1185699758.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T20:15:58.000Z",
    "description": "Although public backlash against data centers has been intense over the past 12 months, all of the tech industry’s biggest companies have promised additional buildouts of AI infrastructure in the coming year....",
    "body": "\nAlthough public backlash against data centers has been intense over the past 12 months, all of the tech industry’s biggest companies have promised additional buildouts of AI infrastructure in the coming year. That includes OpenAI partner Microsoft, which, on Tuesday, announced what it calls a “community-first” approach to AI Infrastructure.\nMicrosoft’s announcement, which comes only a day after Mark Zuckerberg said that Meta would launch its own AI infrastructure program, isn’t unexpected. Last year, the company announced that it planned to spend billions to expand its AI capacity. What is a little unusual are the promises the company has now made about how it will handle that buildout.\nOn Tuesday, Microsoft promised to take the “steps needed to be a good neighbor in the communities where we build, own, and operate our data centers.” That includes, according to the company, its plans to “pay its own way” to ensure that local electricity bills don’t go through the roof in the places where it builds. Specifically, the company says it will work with local utility companies to ensure that the rates it pays cover its full share of its burden on the local grid.\n“We will work closely with utility companies that set electricity prices and state commissions that approve these prices,” Microsoft said. “Our goal is straightforward: to ensure that the electricity cost of serving our data centers is not passed on to residential customers.”\nThe company has also promised to create jobs in the communities where it touches down, as well as to minimize the amount of water that its centers need to function. Water usage by data centers has obviously been a contentious topic, with data centers accused of creating substantial issues for local water supplies and spurring other environmental concerns. The jobs promise is also relevant, given lingering questions around the number of both short-term and permanent jobs that such projects typically create.\nIt’s pretty clear why Microsoft feels it is necessary to make these promises right now. Data center construction has become a political flashpoint in recent years, generating intense backlash and protest from local communities. Data Center Watch, an organization that tracks anti-data center activism, has observed that there are as many as 142 different activist groups across 24 states currently organizing against such developments.\nThis backlash has already impacted Microsoft directly. In October, the company abandoned plans for a new data center in Caledonia, Wisconsin, after “community feedback” was overwhelmingly negative. In Michigan, meanwhile, the company’s plans for a similar project in a small central township have recently inspired locals to take to the streets in protest. On Tuesday, around the same time Microsoft announced its “good neighbor” pledge, an op-ed in an Ohio newspaper (where Microsoft is currently developing several data center campuses) excoriated the company, blaming it and its peers for climate change.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nConcerns have extended even to the White House, where an AI buildout has become one of the major tenets of the Trump administration. On Monday, President Trump took to social media to promise that Microsoft specifically would make “major changes” to ensure that Americans’ electricity bills wouldn’t rise. Trump said the changes would “ensure that Americans don’t ‘pick up the tab’ for their power consumption.”\nIn short, by now, Microsoft understands that it’s fighting a tide of negative public opinion. It remains to be seen whether the company’s new assurances of jobs, environmental stewardship, and low electricity bills will be enough to turn the tide.\n\n\n\t\n\t\tLucas is a senior writer at TechCrunch, where he covers artificial intelligence, consumer tech, and startups. He previously covered AI and cybersecurity at Gizmodo. \nYou can contact Lucas by emailing lucas.ropek@techcrunch.com.\t\n\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Ammobia says it has reinvented a century-old technology",
    "url": "https://techcrunch.com/2026/01/13/ammobia-says-it-has-reinvented-a-century-old-technology/",
    "image": "https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-872226042.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-13T19:17:24.000Z",
    "description": "Ammonia might be the world’s most underappreciated chemical. Without it, crops would go unfertilized and billions of people would starve. Humans started making ammonia in large amounts just over a century...",
    "body": "\nAmmonia might be the world’s most underappreciated chemical. Without it, crops would go unfertilized and billions of people would starve.\nHumans started making ammonia in large amounts just over a century ago, and since then the process used to make it, known as Haber-Bosch, hasn’t changed much. A new startup, Ammobia, says that it has tweaked the Haber-Bosch process to lower the cost by up to 40%.\nTo prove the technology works on a larger scale, Ammobia has raised a $7.5 million seed round, the company exclusively told TechCrunch. Investors include Air Liquide’s venture arm ALIAD, Chevron Technology Ventures, Chiyoda Corporation, MOL Switch, and Shell Ventures.\nIf the startup succeeds, it could pave the way for ammonia to be used beyond fertilizer. \nAmmonia is viewed by some as an alternative to hydrogen to decarbonize a range of industries. Countries like Japan and South Korea have developed industrial and transportation roadmaps that rely on ammonia. Hydrogen, the other leading contender, isn’t as energy dense and its transportation infrastructure isn’t as well developed as ammonia.\n“The big advantage of ammonia is that it’s much easier and more cost-effective to transport and store,” Ammobia co-founder and CEO Karen Baert told TechCrunch. “That opens up a range of opportunities.”\nBut those opportunities won’t amount to much if ammonia production doesn’t clean up its act. The Haber-Bosch process is one of the world’s big polluters, producing nearly 2% of global greenhouse gases. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nTo make ammonia, plants using Haber-Bosch employ an iron catalyst to force one molecule of nitrogen to react with three molecules of hydrogen. The reaction requires high heat (500°C) and pressure (around 200 bar or 2,900 psi) to sustain, both of which tend to be supplied by burning fossil fuels.\nFossil fuels also provide some of the gas needed as a feedstock. Nitrogen is easy to obtain — the gas makes up nearly 80% of Earth’s atmosphere — but most hydrogen used in ammonia production is made by using steam to break apart methane molecules (CH4) found in natural gas.\nAmmobia’s process runs at around 150°C cooler and at 10x lower pressure. As a result, plants that adopt the technology stand to produce less pollution, even if they don’t ditch fossil fuels.\nThe startup also says its process saves cost up front. Ammobia can use cheaper pumps and equipment because it doesn’t need to hit high temperatures and pressures.\nThat could give producers an edge. Because nearly every ammonia producer uses Haber-Bosch, they have typically had only two ways to reduce costs: find a cheaper source of heat or a cheaper source of hydrogen. In places like the U.S., few are cheaper than natural gas.\nAmmobia isn’t seeking to change that right away. The startup emphasizes that its process works with any source of hydrogen or heat. But it does have some key differences from traditional Haber-Bosch that could encourage cleaner sources of each. \nBecause Ammobia’s process runs at lower pressure, it’s easier to ramp production up and down, which could allow renewable developers to take advantage of surplus electricity production to make cheap hydrogen and thus cheap ammonia.\n“Our technology is very compatible with renewable energy, that leads to an additional cost reduction because you don’t need to store hydrogen or store electricity,” Baert said. “In these situations, we have the strongest cost advantage.”\nThe reduced temperature and pressure requirements also allow Ammobia to make its equipment smaller than a typical Haber-Bosch plant. Most ammonia facilities today generate between 1,000 and 3,000 tons per day, while Ammobia’s commercial-scale unit will produce 250 tons per day, Baert said. Customers that need more can install multiple units, she said.\nAmmobia did not share details on how it tweaked Haber-Bosch to run at lower temperature and pressure, but there are a few hints out there. The company has a patent pending on a reactor system that incorporates a sorbent to remove ammonia as it is formed to free up space on the catalyst for another reaction to take place. Researchers have also been investigating non-iron catalysts, including manganese nitride, which use less energy to keep the chemical reaction going.\nThe startup has been operating a small unit for about a year, and the new funding will help the company build a pilot plant that contains all the features of the commercial model on a smaller scale, about 10 tons per day.\n“With that modular approach, we can build projects faster, and we can start at a medium scale,” Baert said. “We see that a lot of customers are looking for that type of solution, and there’s no solution out there today.”\n\n\n\t\tTim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor. \r\nDe Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.\r\nYou can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n"
  }
]