[
  {
    "title": "Meta cuts 600 AI jobs amid ongoing reorganization",
    "url": "https://techcrunch.com/2025/10/22/meta-cuts-600-ai-jobs-amid-ongoing-reorganization/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T15:08:18.000Z",
    "description": "In Brief Posted: 8:08 AM PDT · October 22, 2025  Image Credits:Hollie Adams/Bloomberg / Getty Images  \t\t \t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t \t\t\t\t\t \t  Meta’s chief AI officer, Alexandr Wang, wrote in a memo to staff...",
    "body": "\nIn Brief\nPosted:\n8:08 AM PDT · October 22, 2025\n\nImage Credits:Hollie Adams/Bloomberg / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nMeta’s chief AI officer, Alexandr Wang, wrote in a memo to staff on Wednesday that the company will cut about 600 jobs from its superintelligence lab, according to a report from Axios.\nMeta declined to comment, but told TechCrunch that Axios’ reporting is accurate.\nAs Meta, OpenAI, Anthropic, Google, and other companies race to build the most powerful AI systems, Meta had a busy summer on the hiring front. The company poached more than 50 researchers from its competitors by offering multimillion-dollar pay packages, though OpenAI CEO Sam Altman claimed that “none of [OpenAI’s] best people” took the offers.\n“By reducing the size of our team, fewer conversations will be required to make a decision, and each person will be more load-bearing and have more scope and impact,” Wang wrote in the memo to staff.\nThis line of thinking tracks with Meta’s recent “year of efficiency” — a more sanitized way to describe the company’s mass layoffs. At the time, Meta CEO Mark Zuckerberg told staff that “leaner is better.”\nNow, it seems that Meta isn’t lowering its overall headcount by much, but rather, reorganizing its efforts. The company claims that most of these people impacted today should be able to find another job within Meta. \n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\nLatest in AI\n"
  },
  {
    "title": "Should you trust Tools for Humanity’s iris-scanning orb?",
    "url": "https://techcrunch.com/video/should-you-trust-tools-for-humanitys-iris-scanning-orb/",
    "image": "https://techcrunch.com/wp-content/uploads/2023/12/World-ID-with-Orb.png?w=150",
    "tag": "Tech",
    "date": "2025-10-22T18:00:00.000Z",
    "description": "Ever wonder if you’re talking to a real person online or just another bot? As bots increasingly outnumber humans online, leading to an explosion of deepfakes and AI-driven fraud, one company has a solution...",
    "body": "\n\t\t\n\n\n\nEver wonder if you’re talking to a real person online or just another bot? As bots increasingly outnumber humans online, leading to an explosion of deepfakes and AI-driven fraud, one company has a solution straight out of sci-fi: scanning your iris to verify your humanity. \nToday on TechCrunch’s Equity podcast, Rebecca Bellan spoke with Adrian Ludwig, Chief Security Officer and Chief Architect at Tools for Humanity, the company behind World’s eye-scanning Orbs appearing around the globe. Bellan and Ludwig discuss building privacy-first identity verification, the open-source approach to biometric tech, and why proving humanity matters now more than ever. \nSubscribe to Equity on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod. \nCorrection: A previous version stated the World orb scans your iris to verify identity, rather than humanity.  \n\n\t\t\n\tTopics\n\n\n\n\t\tTheresa Loconsolo is an audio producer at TechCrunch focusing on Equity, the network’s flagship podcast. Before joining TechCrunch in 2022, she was one of 2 producers at a four-station conglomerate where she wrote, recorded, voiced and edited content, and engineered live performances and interviews from guests like lovelytheband. Theresa is based in New Jersey and holds a bachelors degree in Communication from Monmouth University. You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n\n\t\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n"
  },
  {
    "title": "What’s Updog? Datadog’s new tool tells you which apps are down",
    "url": "https://techcrunch.com/2025/10/22/whats-updog-datadogs-new-tool-tells-you-which-apps-are-down/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1357481031.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T17:50:07.000Z",
    "description": "Cloud monitoring and security platform Datadog has solved an age-old joke: What’s up, dog? Datadog’s answer is not, “Not much, you?” Rather, the company launched a web dashboard that shows developers the...",
    "body": "\nCloud monitoring and security platform Datadog has solved an age-old joke: What’s up, dog?\nDatadog’s answer is not, “Not much, you?” Rather, the company launched a web dashboard that shows developers the status of dozens of services and tools like AWS, Cloudflare, OpenAI, and Slack — essentially letting them check whether major software providers are functioning properly. The tool is free, so anyone can check Updog to find out if major SaaS providers are up … dog.\nDatadog clearly had fun with this branding, as they should. Rhys Sullivan, a software engineer, said in an X post in June, “you’re telling me that datadog has an uptime monitoring product and they didn’t call it ‘updog’?”\nFour months later, Datadog engineer Tim Brown replied, “Here you go,” and linked to the newly launched Updog.\n\nSullivan’s initial tweet was actually referring to the branding of a tool within the paid Datadog platform, which provides more in-depth monitoring tools, whereas Updog, which is free, is for more general use. Anyone can check the status of popular online services without needing a Datadog subscription.\nJokes aside, Updog seems like it will be a useful free tool for developers — and it probably would’ve come in handy on Monday, when a day-long AWS outage took a great portion of the web offline, including some banks, payment processors, and government services.\nDatadog says that its Updog dashboard is set apart by its use of AI, which can identify subtle patterns in telemetry — the transmission and collection of remote data from servers and services — that can surface potential outages more quickly. If Updog can successfully pull this off, that foreknowledge can make a difference for businesses that depend on SaaS tools for everything from collecting payments to accessing cloud-stored data.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\n“Updog.ai recently surfaced an Amazon DynamoDB degradation 32 minutes before AWS updated its own status page,” Datadog wrote in a blog post.\nWhile a company may not always be able to avoid major collapses like this week’s AWS outage, knowing about service issues early can at least give companies extra time to assess their situation, and that’s what’s Updog. \n\n\n\t\tAmanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.\nYou can contact or verify outreach from Amanda by emailing amanda@techcrunch.com or via encrypted message at @amanda.100 on Signal. \t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Amazon unveils AI smart glasses for its delivery drivers",
    "url": "https://techcrunch.com/2025/10/22/amazon-unveils-ai-smart-glasses-for-its-delivery-drivers/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/amazon-glasses.png?w=150",
    "tag": "Tech",
    "date": "2025-10-22T18:33:34.000Z",
    "description": "Amazon likely hopes that the new glasses will shave valuable time off of each delivery by providing delivery drivers with detailed directions and information about hazards directly in their line of sight.",
    "body": "\n\t\n\t\tImage Credits:Amazon\t\n\t\n\t\t\t\t\t\t11:33 AM PDT · October 22, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nAmazon announced on Wednesday that it’s developing AI-powered smart glasses for its delivery drivers. The idea behind the glasses is to give delivery drivers a hands-free experience that reduces the need to keep looking between their phone, the package they’re delivering, and their surroundings.\nThe e-commerce giant says the glasses will allow delivery drivers to scan packages, follow turn-by-turn walking directions, and capture proof of delivery, all without using their phones. The glasses use AI-powered sensing capabilities and computer vision alongside cameras to create a display that includes things like hazards and delivery tasks. \nAmazon likely hopes that the new glasses will shave time off of each delivery by providing delivery drivers with detailed directions and information about hazards directly in their line of sight.\nImage Credits:Amazon\nWhen a driver parks at a delivery location, Amazon says the glasses automatically activate. The glasses help the driver locate the package inside the vehicle and then navigate to the delivery address. The glasses can provide easy-to-follow directions in places like multi-unit apartment complexes and business locations.  \nThe glasses are paired with a controller worn in the delivery vest that contains operational controls, a swappable battery, and a dedicated emergency button. \nAmazon notes that the glasses also support prescription lenses and transitional lenses that automatically adjust to light. \nImage Credits:Amazon\nThe retailer is currently trialing the glasses with delivery drivers in North America and plans to refine the technology before a wider rollout.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe announcement doesn’t come as a surprise, as Reuters reported last year that Amazon was working on the smart glasses. \nIn the future, Amazon says the glasses will be able to provide drivers with “real-time defect detection” that could notify them if they accidentally drop off a package at the wrong address. The glasses will also be able to detect pets in yards and automatically adjust to hazards like low light conditions.\nAlso on Wednesday, Amazon unveiled a new robotic arm called “Blue Jay” that can work alongside warehouse employees to pick items off shelves and sort them. Additionally, the tech giant announced a new AI tool called Eluna that will help provide operational insights at Amazon warehouses.\n\n\t\t\t\n\tTopics\n\n\n\n\t\tAisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.\nYou can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "OpenAI requested memorial attendee list in ChatGPT suicide lawsuit",
    "url": "https://techcrunch.com/2025/10/22/openai-requested-memorial-attendee-list-in-chatgpt-suicide-lawsuit/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T20:49:19.000Z",
    "description": "The new information comes as the Raines family updated its lawsuit against OpenAI. The family first filed a wrongful death suit against OpenAI in August after alleging their son had taken his own life following conversations with the chatbot about his mental health and suicidal ideation. ",
    "body": "\n\t\n\t\tImage Credits:Silas Stein/picture alliance / Getty Images\t\n\t\n\t\t\t\t\t\t1:49 PM PDT · October 22, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nOpenAI reportedly asked the Raine family — whose 16-year-old son Adam Raine died by suicide after prolonged conversations with ChatGPT — for a full list of attendees from the teenager’s memorial, signaling that the AI firm may try to subpoena friends and family.  \nOpenAI also requested “all documents relating to memorial services or events in the honor of the decedent, including but not limited to any videos or photographs taken, or eulogies given,” per a document obtained by the Financial Times. \nSpeaking to the FT, lawyers from the Raine family described the request as “intentional harassment.” \nThe new information comes as the Raine family updated its lawsuit against OpenAI on Wednesday. The family first filed a wrongful death suit against OpenAI in August after alleging their son had taken his own life following conversations with the chatbot about his mental health and suicidal ideation. The updated lawsuit claims that OpenAI rushed GPT-4o’s May 2024 release by cutting safety testing due to competitive pressure.\nThe suit also claims that in February 2025, OpenAI weakened protections by removing suicide prevention from its “disallowed content” list, instead only advising the AI to “take care in risky situations.” The family argued that after this change, Adam’s ChatGPT usage surged from dozens of daily chats, with 1.6% containing self-harm content in January, to 300 daily chats in April, the month he died, with 17% containing such content. \nIn a response to the amended lawsuit, OpenAI said: “Teen wellbeing is a top priority for us — minors deserve strong protections, especially in sensitive moments. We have safeguards in place today, such as [directing to] crisis hotlines, rerouting sensitive conversations to safer models, nudging for breaks during long sessions, and we’re continuing to strengthen them.” \nOpenAI recently began rolling out a new safety routing system and parental controls on ChatGPT. The routing system pushes more emotionally sensitive conversations to OpenAI’s newer model, GPT-5, which doesn’t have the same sycophantic tendencies as GPT-4o. And the parental controls allow parents to receive safety alerts in limited situations where the teen is potentially in danger of self-harm. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nTechCrunch has reached out to OpenAI and the Raine family attorney.\n\n\t\t\t\n\tTopics\n\n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "Apple confirms it pulled controversial dating apps Tea and TeaOnHer from the App Store",
    "url": "https://techcrunch.com/2025/10/22/apple-confirms-it-pulled-controversial-dating-apps-tea-and-teaonher-from-the-app-store/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/07/tea-app.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T17:32:14.000Z",
    "description": "Apple has pulled the controversial dating safety apps Tea and TeaOnHer from the App Store over violations of its content moderation and privacy rules, following a flood of user complaints and reports of minors’ data being exposed.",
    "body": "\nControversial dating safety apps, Tea and TeaOnHer, have been pulled from the Apple App Store. The apps’ removal was first spotted by the app store intelligence provider Appfigures, which told TechCrunch the two apps were removed from the App Store on Tuesday in all markets but remain live on Google Play.\nReached for comment, Apple confirmed the apps’ removal, saying it removed Tea Dating Advice and TeaOnHer from the App Store because they failed to meet Apple’s requirements around content moderation and user privacy. The company also said it saw an excessive number of user complaints and negative reviews, which included complaints of minors’ personal information being posted in these apps.\nApple communicated the issues to the developers of the apps, a representative said, but the complaints were not addressed. (Request for comment from the app developers has not yet been returned.)\nSpecifically, Apple cited violations of its App Review Guidelines 1.2, 5.1.2, and 5.6. Rule 1.2 says apps with user-generated content should offer reporting and blocking features and should remove objectionable content. Rule 5.1.2 says apps can’t use or share someone’s personal information without permission, and Rule 5.6 says excessive customer reports and negative reviews violate Apple’s Developer Code of Conduct.\nTea and TeaOnHer have generated a lot of headlines and interest since going viral earlier this year. Tea, which had quietly existed since 2023 before picking up steam in 2025, was pitched as a dating safety tool for women, somewhat similar to the “Are We Dating the Same Guy?” Facebook Groups. The app encouraged women to spill details about men, particularly those on dating apps. This included their personal information, Yelp-style reviews, and whether they’d dub them a “green flag” or “red flag.”\nMany men, however, didn’t appreciate the app’s invasion into their privacy and questioned whether sharing information like this could be considered defamation.\nAfter going viral and generating controversy, Tea suffered a data breach over the summer, with hackers gaining access to 72,000 images, including 3,000 selfies and photo IDs submitted for account verification, as well as 59,000 images from posts, comments, and direct messages.\nLater, a rival app called TeaOnHer launched to offer men the ability to dish on women in the same way, but it was beset by security issues that exposed users’ personal information, including government IDs and selfies, TechCrunch discovered in August.\nAppfigures says the Tea app saw 6.1 million total lifetime downloads and had generated $5 million in gross revenue to date. TeaOnHer had 2.2 million downloads and didn’t offer in-app purchases. It notes the apps remain live on Google Play for now. \nWith their App Store removal, however, copycats are gaining traction. For instance, an app called TeaOnHer and Him – Overheard has 354,000 total downloads and has jumped from No. 90 on the Overall Top App Charts to No. 27.\n\n\n\t\tSarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.\nYou can contact or verify outreach from Sarah by emailing sarahp@techcrunch.com or via encrypted message at sarahperez.01 on Signal. \t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "UK designates Apple and Google as having ‘strategic market status,’ opening door for more regulation",
    "url": "https://techcrunch.com/2025/10/22/u-k-designates-apple-and-google-as-having-strategic-market-status-opening-door-for-more-regulation/",
    "image": "https://techcrunch.com/wp-content/uploads/2020/10/apple-fighting-google.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T15:03:37.000Z",
    "description": "The U.K.’s competition regulator has designated Apple and Google with “strategic market status” in their mobile platforms, giving the regulator new powers to enforce competition in areas like app stores, browsers, and operating systems.",
    "body": "\nThe U.K.’s Competition and Markets Authority (CMA) said on Wednesday that it’s designating Apple and Google with strategic market status in their respective mobile platforms. The decision, which affects the companies’ operating systems, app stores, browsers, and browser engines, will enable the regulator to take targeted actions to enhance competition in the space.\nThe CMA had launched investigations into Apple and Google in January, and had proposed interventions in July that indicated the tech giants could be designated with strategic market status (SMS). To reach its conclusions, the CMA consulted over 150 stakeholders and had discussions with both Apple and Google. It then arrived at the decision that Apple and Google had “substantial, entrenched market power and a position of strategic significance in their respective mobile platforms.”\nAmong other findings, the CMA discovered that U.K. mobile device owners are unlikely to switch between Apple and Google’s mobile platforms once they have adopted the ecosystem of their choice. It noted that both platforms require businesses to distribute apps through their app stores to reach consumers.\nNotably, it also said that new technologies, like AI, were “unlikely to eliminate Apple or Google’s market power over the five-year designation period.” \n“Apple and Google’s mobile platforms are used by thousands of businesses right across the economy to market and sell products and services to millions of customers, but the platforms’ rules may be limiting innovation and competition,” Will Hayter, executive director for digital markets at the CMA, said in a statement.\nThe CMA added that designating the platforms with SMS was not a finding of wrongdoing, however. Instead, it allows the regulator to consider “proportionate, targeted interventions to ensure that mobile platforms are open to effective competition, and that consumers and businesses that rely on Google and Apple can have confidence that they are treated fairly,” the announcement states.\nApple and Google have pushed back against the decision, with Apple warning that the decision could mean that users in the U.K. would lose access to getting new features in a timely fashion — something that already happened with Apple Intelligence. Google also said it didn’t see the rationale for the decision.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nA statement released by Apple and shared with TechCrunch reads: \n“Apple faces fierce competition in every market where we operate, and we work tirelessly to create the best products, services and user experience. The UK’s adoption of EU-style rules would undermine that, leaving users with weaker privacy and security, delayed access to new features, and a fragmented, less seamless experience. We’ve seen the impact of regulation on Apple users in the EU, and we urge the UK not to follow the same path.”\nUpdated with Apple’s comment.\n\n\n\t\tSarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.\nYou can contact or verify outreach from Sarah by emailing sarahp@techcrunch.com or via encrypted message at sarahperez.01 on Signal. \t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "GM to introduce eyes-off, hands-off driving system in 2028 ",
    "url": "https://techcrunch.com/2025/10/22/gm-to-introduce-eyes-off-hands-off-driving-system-in-2028/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/GM-Cadillac-Escalade-IQL-eyes-off-driving.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T15:00:00.000Z",
    "description": "GM said Cruise’s technology stack, including its AI models trained on five million driverless miles and simulation framework, feed directly into the automaker’s next-generation driver assistance and autonomy programs.  ",
    "body": "\nGeneral Motors said it plans to launch an automated driving system in 2028 that will allow drivers to keep their eyes off the road and hands off the wheel, starting with the Cadillac Escalade IQ.\nThe announcement, made Wednesday at its GM Forward event in New York City, comes a year after TechCrunch first reported that the automaker was working on the system. \nGM said its hands-off advanced driver assistance system, known as Super Cruise, is the foundation of this future, more capable product. Super Cruise, which launched in 2017 and is now available in 23 vehicle models, can be used on about 600,000 miles of highway. \nThis new eyes-off, hands-off driver assistance system — which will use lidar, radar, and cameras for perception — will also start on highways. GM CEO Mary Barra noted during the event that GM would roll out its eyes-off product faster than it did its hands-off Super Cruise ADAS.\nThe automaker said it has tapped the experience of engineers who worked at its now shuttered autonomous vehicle technology subsidiary Cruise to improve the capabilities of that system. When GM shut down Cruise, its commercial robotaxi business, in December 2024, it absorbed the subsidiary and combined it with its own efforts to develop driver assistance features. Over the last year, GM has also rehired several Cruise engineers as it pursues its goal of developing fully autonomous personal vehicles.  \nGM said it is also feeding Cruise’s technology stack, which includes AI models trained on five million driverless miles and a simulation framework running virtual test scenarios, into its next-generation driver assistance and autonomy programs.\n“Robotaxi as a proof of concept when you start makes a lot of sense,” Sterling Anderson, GM’s executive vice president of global product and former co-founder of AV startup Aurora Innovation, said during the event, adding that the high cost of sensors and compute on autonomous vehicles required high utilization of those vehicles. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\n“We’re now in a position in 2025 where the industry broadly has brought down the cost tremendously of some of the hardware,” Anderson said. “And GM, uniquely, has the install base, the manufacturing capacity to put these out at much larger volumes and much lower costs. Had the industry had low-cost systems and a huge install base and manufacturing capacity to begin with, we probably all would have gone for personal autonomous vehicles to begin with.”\nIn the U.S., Mercedes is currently the only automaker with a commercially available hands-off, eyes-off system. Such systems would fall under the SAE’s Level 3 of automation, which refers to an automated system that can drive itself under certain conditions but might still require a human to take over. Mercedes’ Drive Pilot is only available on certain mapped highways in California and Nevada, and only functions in heavy, low-speed traffic.\nGM’s eyes-off product will work on highways that GM hasn’t mapped, according to Baris Cetinok, GM’s senior vice president of software and services. He added that the system will only require human takeover for things like off-ramps, and can handle emergencies and sudden incidents. \n“Human intervention should not be the escape hatch for sudden incidents,” Cetinok said. \nGetting to market with an eyes-off, hands-off driving system would put GM ahead of most other automakers, unless they get there first. Earlier this year, Stellantis unveiled its own Level 3 system, but it has put the launch on hold. Tesla has been gunning to “solve full self-driving” by relying only on its cars’ cameras and neural networks for years, even though its Autopilot and FSD systems still require the driver to keep their eyes on the road.  \n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Tinder will require new users in the US to verify their identity with a selfie ",
    "url": "https://techcrunch.com/2025/10/22/tinder-will-require-new-users-in-the-us-to-verify-their-identity-with-a-selfie/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/TinderFaceCheck2.png?w=150",
    "tag": "Tech",
    "date": "2025-10-22T16:33:25.000Z",
    "description": "Image Credits:Tinder\t \t \t\t\t\t\t\t9:33 AM PDT · October 22, 2025\t\t\t\t\t\t\t\t\t\t\t  \t\t\t Dating app giant Tinder announced on Wednesday that it’s expanding its facial-verification feature to more users in the U.S.  The...",
    "body": "\n\t\n\t\tImage Credits:Tinder\t\n\t\n\t\t\t\t\t\t9:33 AM PDT · October 22, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nDating app giant Tinder announced on Wednesday that it’s expanding its facial-verification feature to more users in the U.S. \nThe facial-verification feature, known as Face Check, requires new users to verify their identity by submitting a short video selfie. This initiative aims to reduce impersonation on the platform and ensure that people are not connected to bots or fake accounts.\nFace Check creates a 3D video scan of the user’s face to verify its similarity with their profile pictures. Members who successfully complete the verification process earn a badge on their profiles, indicating to others that they have been verified. Additionally, the feature identifies whether the same face is utilized across different accounts, providing an additional safeguard against impersonation and fraudulent profiles.\nTinder says that the video selfies are deleted shortly after review but that it keeps a “non-reversible, encrypted face map and face vector,” which help verify new photos, spot fraud, and stop people from making duplicate accounts. \nImage Credits:Tinder\nThe Face Check feature has already been in place in California since June, as well as in Colombia and Canada. It’s also now available in Australia, India, and other countries across Southeast Asia. \nFace Check will roll out to additional U.S. states in the coming months. It will also roll out to other dating apps owned by parent company Match Group in 2026.\nUsers have been leaving the Tinder app in recent years because of issues related to safety and privacy, along with unfavorable encounters with other users. The company is facing challenges in earning revenue from its user base, reporting a 7% drop in paying users during the second quarter of 2025.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nSince launching the feature, Tinder claims to have already seen promising results, including a 60% reduction in the exposure to potential “bad actors” and a 40% decline in the number of “bad actor reports.” \nOther companies have also recently introduced anti-scam facial-recognition tests. For example, Meta uses similar technology to help users regain access to compromised Facebook or Instagram accounts. Additionally, Bumble offers photo verification, requiring members to take a selfie that mimics a pose they select to get verified.\n\n\t\t\t\n\tTopics\n\n\n\n\t\tLauren covers media, streaming, apps and platforms at TechCrunch.\nYou can contact or verify outreach from Lauren by emailing laurenf.techcrunch@gmail.com or via encrypted message at laurenforris22.25 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "GM’s under-the-hood overhaul puts AI and automated driving at the center",
    "url": "https://techcrunch.com/2025/10/22/gms-under-the-hood-overhaul-puts-ai-and-automated-driving-at-the-center/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/GM-Cadillac-Escalade-IQL-exterior.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T15:00:00.000Z",
    "description": "General Motors is overhauling the electrical and computational guts of its future vehicles in a bid to deliver faster software, more capable automated driving features, and a custom, conversational AI...",
    "body": "\nGeneral Motors is overhauling the electrical and computational guts of its future vehicles in a bid to deliver faster software, more capable automated driving features, and a custom, conversational AI assistant.\nThe result of this overhaul will debut in 2027 in the Cadillac Escalade IQ.\nThe U.S. automaker, which unveiled its plans at an event Wednesday in New York City, said a new electric architecture and centralized computing platform will be the foundation for all of its future gas-powered and electric vehicles, starting in 2028. The next-generation supercomputer, Nvidia Drive AGX Thor, will power the compute unit — the result of an expanded partnership between GM and Nvidia that was announced in March.\nThis under-the-hood renovation is a required step if the company wants to introduce more services and features, like a conversational AI assistant or a system that allows a car to safely navigate highways while the driver watches a movie — two products that GM said it is working on and will bring to future vehicles. It would also allow GM to improve the performance of its vehicles, fix problems, or add new features to its infotainment systems via software updates — all of which would make it more competitive with Tesla and the rising threat of Chinese automakers.\nGM Chief Product Officer Sterling Anderson said he’s been focused on accelerating the rollout of this new architecture since joining the company in May because it “brings a lot of goodness,” like bandwidth and a “dramatic increase in the compute.” It’s part of Anderson’s broader goal of getting technologically advanced products into consumers’ hands faster.\n“Going forward, on the core business, my focus has really been around speed, user experience of the product, and profitability,” Anderson told TechCrunch. “We’re looking across the business to find opportunities to dramatically reduce the development time for our vehicle platforms. Today, it’s on the order of four to five years. I’d like to get it closer to two.”\nInside most modern vehicles, including GM brands Buick, Chevrolet, Cadillac, and GMC, are dozens of small computers that handle everything from the infotainment and safety systems to propulsion, steering, and braking. The number of these computers, called electronic control units or ECUs, has risen over the past decade as automakers have added more services and features. Tesla, which took a ground-up, software-first approach, was able to outpace established brands with more computing power and the ability to roll out new features and improve performance through wireless software updates, similar to iPhones or Android-based smartphones.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nLegacy automakers have spent years, and billions of dollars, trying to catch up.\nThe industry widely agrees that part of the solution is to change the underlying hardware architecture to handle the growing computational appetites of infotainment features, safety systems, and automated driving.\nGM is taking a similar, although not identical, approach to the zonal architectures used by Tesla and Rivian. GM said it will consolidate dozens of ECUs into a unified computer core that will coordinate every subsystem in the vehicle in real time. That core will be connected to three aggregators — hubs that will convert signals from hundreds of sensors in the vehicle into a unified digital language and then route commands back to the correct hardware.\nThe upshot: The central computing platform will connect every system in the car, including propulsion, steering, braking, infotainment, and safety, through a high-speed Ethernet backbone.\nImage Credits:GM\nGM calls the plan a “full reimagining” of how its vehicles are designed, updated, and improved over time. The end result, GM claims, will be vehicles with 10 times more over-the-air software update capacity, 1,000 times more bandwidth, and up to 35 times more AI performance for autonomy and advanced features. \nGM has been on this software-centric, reimagining-the-vehicle road for several years. In 2020, GM rolled out an updated hardware architecture called Vehicle Intelligence Platform (VIP) to allow for greater data processing power and over-the-air software updates. The following year, GM unveiled a cloud-based, end-to-end software platform called Ultifi that executives promised would make vehicles more capable and give drivers access to in-car subscriptions and new apps and services through over-the-air updates. The Ultifi branding has since been dropped, but it exists in GM’s newest models and is the software that operates on top of the VIP architecture. GM continued its bid for a more software-centric vehicle in 2022 when it consolidated dozens of computers used to operate the infotainment system into a single computing platform.\nGM says this latest move builds on all of this. \n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Amazon will buy thousands of pedal-assist cargo vehicles from Rivian spinoff Also",
    "url": "https://techcrunch.com/2025/10/22/amazon-will-buy-thousands-of-pedal-assist-cargo-vehicles-from-rivian-spinoff-also/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/amazon-prime-also-.jpeg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T18:09:41.000Z",
    "description": "Also, the micromobility startup spun out of Rivian, has landed a commercial deal with Amazon to supply the e-commerce company with thousands of its new pedal-assist cargo quad vehicles that are big enough to...",
    "body": "\nAlso, the micromobility startup spun out of Rivian, has landed a commercial deal with Amazon to supply the e-commerce company with thousands of its new pedal-assist cargo quad vehicles that are big enough to carry more than 400 pounds of packages and small enough to use a bike lane. \nUnder the multi-year collaboration, the two companies will work on customizing the pedal-assist vehicles to meet Amazon’s delivery needs in Europe and the United States. The TM-Q pedal-assist electric quads will launch in spring 2026, according to Also, which was revealed on Wednesday at an event in Oakland alongside the company’s new e-bike called the TM-B.\nWhile Also is a new company, its executives already have a long-held relationship with Amazon. Rivian, the EV maker where Also was born, is backed by Amazon and has supplied the company with more than 25,000 of its electric delivery vans.\n“We really understand how to work with each other,” Rivian founder and CEO RJ Scaringe told TechCrunch ahead of the event, adding that everything they learned from the EDV van program was poured into this project. “This is where having Rivian as a large shareholder is very handy because we can do all this tight coordination through one fleet management portal that manages your large vehicles, like the EDV vans, and the Also products.”\nThe advantage is knowing exactly what Amazon needs, Scaringe added. “There’s no guesswork and Also has benefited from a lot of input from the Rivian team, which has been involved, because they’re so close to Amazon.”\nAlso started as a skunkworks within Rivian and spun out of the EV maker earlier this year with a new name and $105 million in funding from Eclipse. Also is a stand-alone company, but it has close ties with Rivian, which holds a minority stake. Scaringe will serve on its board, and Also will use — and already has — the automaker’s tech, retail presence, and economies of scale.\nImage Credits:Kirsten Korosec\nThe TM-Q and Also’s TM-B e-bike share much of the same DNA, including the drivetrain, a pedal-by-wire system developed by Also. Even some of the physical elements, notably the handlebars and a built-in five-inch circular touchscreen that can be turned to lock and unlock the vehicle, are the same. That touchscreen unit, which displays navigation, media controls, fitness stats, and assist levels, syncs with the Also app to let users check their battery charge, download software updates, and manage security.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe vehicles also share the same battery technology, although the quad cargo vehicles have more power capacity. Instead of incorporating a large battery in the electric quad vehicles, Also has kept them portable and removable. Also president Chris Yu said the company is working on building battery dock stations so you can actually swap them.\nUnlike its two-wheeled consumer sibling, the TM-Q will be tailored to commercial uses and includes software that handles logistics, delivery, and charging. The TM-Q’s diminutive stature and pedal-assist system make it ideal for delivering packages to customers who live in dense, urban areas, according to Emily Barber, Director of Amazon’s Global Fleet.\nThere is already an operational micromobility operation for Also quad cargo vehicles. Amazon has more than 70 micromobility hubs in cities across the U.S. and Europe, Barber said. \nImage Credits:Also\nAmazon won’t be the only TM-Q customers, though. Yu said Also, noting how popular the quad design was within the company, won’t completely limit its quad cargo vehicles to commercial customers. The company also unveiled a consumer TM-Q that has the same underlying quad platform but lacks the delivery van topper. Instead, the vehicle has a bench system spacious enough to haul a few friends, kids, pets, or groceries.\nAnd there may be other iterations in the future, Yu and Scaringe hinted. \n“It’s less about what’s on top here and it’s more about the underlying quad platform,” Yu said. \nThat comes with a distinct advantage, Scaringe noted. “What I love about these, to do a new top hat on a car it’s like a billion dollars; to do new top hat here, it’s a lot less,” he said, laughing. \n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Snapchat makes its first open prompt AI Lens available for free in the US",
    "url": "https://techcrunch.com/2025/10/22/snapchat-makes-its-first-open-prompt-ai-lens-available-for-free-in-the-us/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/10/Imagine_Lens_16x9.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T21:25:30.000Z",
    "description": "Snapchat is making its new “Imagine Lens,” the company’s first open prompt image-generation AI Lens, available to all users for free. The Lens was initially launched in September but only for paid...",
    "body": "\nSnapchat is making its new “Imagine Lens,” the company’s first open prompt image-generation AI Lens, available to all users for free. The Lens was initially launched in September but only for paid subscribers. With the Lens, users can edit their own Snaps using custom prompts or generate their own.\nFor instance, you could prompt the app, “Turn me into an alien” after snapping a selfie, or request an image of a “grumpy cat.” The company suggests you could use the Lens to try on Halloween costume ideas, or reimagine your friend in a new look, among other things.\nThe results can be shared with friends, posted to your Story on Snapchat, or shared beyond the app. \nThe broadened availability of the AI Lens follows the launch of AI video-generating apps from Meta (Meta AI) and OpenAI (Sora), which compete for young people’s attention with even more advanced AI tools and features than photo modifications. \nFor instance, Sora lets users generate videos of themselves after providing the app with a one-time video and audio recording to capture their appearance. Friends can share these AI personas, dubbed “cameos,” with one another, so they can star in videos together.\nThat puts pressure on other social apps like Snapchat to keep up, so making the AI image Lens free to use seems a worthwhile investment for the app maker. \nUntil now, Snapchat’s AI Lens was only available to Lens+ and Snapchat Platinum Subscribers, the company says. With the expanded rollout, Snap is making a limited number of image generations available to all free users, as well. At launch, free users in the U.S. will be able to access the new Lens, with plans for other markets underway, starting with Canada, Great Britain, and Australia.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe Lens is found near the front of the in-app Lens Carousel, or you can search for it by name. To create, tap the caption to edit your prompt, or use one of the preloaded suggestions if you need inspiration.\nThe company notes that Snapchat users access Lenses more than 8 billion times per day. \n\n\n\t\tSarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.\nYou can contact or verify outreach from Sarah by emailing sarahp@techcrunch.com or via encrypted message at sarahperez.01 on Signal. \t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Redwood Materials raises another $350M to power up its energy storage business",
    "url": "https://techcrunch.com/2025/10/23/redwood-materials-raises-another-350-million-to-power-up-its-energy-storage-business/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/06/Modular_Data_Center_2.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-23T12:00:00.000Z",
    "description": "Image Credits:Redwood Materials\t \t \t\t\t\t\t\t5:00 AM PDT · October 23, 2025\t\t\t\t\t\t\t\t\t\t\t  \t\t\t Battery recycling and cathode production company Redwood Materials has raised $350 million as it grows its new energy...",
    "body": "\n\t\n\t\tImage Credits:Redwood Materials\t\n\t\n\t\t\t\t\t\t5:00 AM PDT · October 23, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nBattery recycling and cathode production company Redwood Materials has raised $350 million as it grows its new energy storage business in a bid to power the AI data center boom.\nThe Series E round, led by venture firm Eclipse, also included a new strategic investment by Nvidia’s venture capital arm, NVentures. The company’s valuation was not disclosed, but a source familiar with the round told TechCrunch it was about $6 billion, a billion higher than its previous valuation.\nThe funds will be used to expand the company’s burgeoning energy storage business as well as its refining and materials production capacity. Redwood, founded by former Tesla CTO JB Straubel, also plans to hire more engineers and staff for its operations team.\nWhen Redwood Materials was founded in 2017, it set out to create a circular supply chain for batteries by focusing on recycling scrap from battery cell production and consumer electronics like cell phone batteries and laptop computers. That business — which continues to grow — involves processing those discarded goods and extracting materials like cobalt, nickel and lithium that are typically mined. Redwood supplies those materials back to its customers, which include Panasonic, GM and Toyota.\nRedwood has since added new, related pursuits like cathode production. Most recently, it launched an energy storage business that uses the thousands of EV batteries it collects to provide power to companies. That business, called Redwood Energy, is largely directed towards serving AI data centers as well as other large-scale industrial sites.\nRedwood is sitting on massive quantities of EV batteries that have too much life left to put through the recycling process. The company ties these retired EV batteries to renewable energy sources like wind and solar to create an off-grid system that sends power to AI data centers or industrial sites. The system can be tied to the grid, and Redwood says the EV batteries can also be connected to natural gas turbines or future nuclear generators for large-scale energy storage.\nIt has plenty of supply. The company recovers more than 70% of all used or discarded battery packs in North America, and not all are recycled right away. As of June, Redwood had stockpiled more than 1 gigawatt-hour worth of batteries that could be used for energy storage. By 2028, the company plans to deploy 20 gigawatt-hours of grid-scale storage, placing it on track to become the largest repurposer of used EV battery packs.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\t\t\t\n\tTopics\n\n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t"
  },
  {
    "title": "GM is bringing Google Gemini-powered AI assistant to cars in 2026 ",
    "url": "https://techcrunch.com/2025/10/22/gm-is-bringing-google-gemini-powered-ai-assistant-to-cars-in-2026/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2233653192.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T15:51:03.000Z",
    "description": "GM is the latest automaker to lean into generative AI-based assistants that promise to respond to driver requests in a more natural-sounding way. Stellantis is collaborating with French AI firm Mistral, Mercedes is integrating ChatGPT, and Tesla has brought xAI’s Grok to its vehicles.  ",
    "body": "\nGeneral Motors will add a conversational AI assistant powered by Google Gemini to its cars, trucks, and SUVs starting next year, the U.S. automaker said Wednesday during an event in New York City. \nThe Google Gemini rollout is one of several tech-centric announcements made at the automaker’s GM Forward event, and it will be one of the first to get into consumers’ hands. Others, including an overhaul of its electrical architecture and computing platform and an automated driving feature that allows drivers to keep their hands off the wheel and eyes off the road, aren’t coming to GM brands until 2028.\nGM is the latest automaker to lean in to generative AI-based assistants that promise to respond to driver requests in a more natural-sounding way. Stellantis is collaborating with French AI firm Mistral, Mercedes is integrating ChatGPT, and Tesla has brought xAI’s Grok to its vehicles.  \nGM’s integration with Gemini is the next logical step for the automaker. Vehicles produced by GM brands Buick, Chevrolet, Cadillac, and GMC already have “Google built-in,” an operating system that gives drivers access to Google Assistant, Google Maps, and other apps directly from the car’s infotainment screen. In 2023, Google began using Google Cloud’s Dialogflow chatbot to handle non-emergency OnStar features, including common driver queries like routing and navigation assistance. \nGM’s Gemini-powered AI assistant will have similar levels of capability — it’ll just perform better, according to Dave Richardson, senior vice president of software and services. \n“One of the challenges with current voice assistants is that, if you’ve used them, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that. They have context about previous conversations that they can bring up. They’re flexible in how you speak to them … so overall you’re getting a better, more natural experience.”\nThat might make drafting and sending messages, planning routes with additional stops (like a charging station or a favorite coffee shop), or even prepping for a meeting on the go a more pain-free experience. The assistant will also have access to the web to be able to answer certain questions like, “What’s the history of this bridge I’m driving over?”\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe Gemini assistant will be made available via the Play Store as an over-the-air upgrade to OnStar-equipped vehicles, model year 2015 and above.\nGM’s new voice assistant is a step toward the automaker’s goal of developing its own custom-built AI that connects to your vehicle’s systems through OnStar, GM’s in-car concierge. The way GM executives described the technology at the NYC event, it seems like a mix of a health wearable and an AI pendant, but for your car.\nThe assistant promises to access vehicle data to provide maintenance alerts and route suggestions, explain car features like one-pedal driving, and turn your heat or air conditioning on before you enter the vehicle. \n“The idea here is you take [an existing] large language model, and you train it and refine it on a specific domain,” Richardson said. “We’ll take a base model and train it on the vehicle’s specifications, distill that down, and have that running on the vehicle.”\nWhile GM has a close relationship with Google and will already be implementing Gemini into certain vehicles, Richardson said GM plans to test several foundational models from other AI firms, which could include OpenAI, Anthropic, and others. \nRichardson said drivers will be able to control what information the assistant can access and use, and it can learn from your habits to offer personalized recommendations. GM’s emphasis on user controls is notable given the company’s recent controversy over selling customer driving and geolocation data to insurance brokers. \nRichardson said any data GM gets from drivers goes directly toward improving the product and won’t be sold to bring in additional revenue for the automaker. Over the last nearly two years, GM has brought on a new data team — including Christina Montgomery, who spent 30 years as IBM’s chief privacy and trust officer — to put standard processes and data governance technology in place.\n“Everything that we’re going to do is going to be driven by customer consent, so you can always opt in or opt out,” he said. “Our viewpoint is that data and privacy has to be built into everything that we do.”\nThis article has been updated with comments from Dave Richardson.\n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n"
  },
  {
    "title": "Why Cohere’s ex-AI research lead is betting against the scaling race",
    "url": "https://techcrunch.com/2025/10/22/why-coheres-ex-ai-research-lead-is-betting-against-the-scaling-race/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/03/Sara-Hooker_headshot-e1759963248106.jpg?w=150",
    "tag": "Tech",
    "date": "2025-10-22T20:52:17.000Z",
    "description": "AI labs are racing to build data centers as large as Manhattan, each costing billions of dollars and consuming as much energy as a small city. The effort is driven by a deep belief in “scaling” — the idea...",
    "body": "\nAI labs are racing to build data centers as large as Manhattan, each costing billions of dollars and consuming as much energy as a small city. The effort is driven by a deep belief in “scaling” — the idea that adding more computing power to existing AI training methods will eventually yield superintelligent systems capable of performing all kinds of tasks.\nBut a growing chorus of AI researchers say the scaling of large language models may be reaching its limits, and that other breakthroughs may be needed to improve AI performance.\nThat’s the bet Sara Hooker, Cohere’s former VP of AI Research and a Google Brain alumna, is taking with her new startup, Adaption Labs. She co-founded the company with fellow Cohere and Google veteran Sudip Roy, and it’s built on the idea that scaling LLMs has become an inefficient way to squeeze more performance out of AI models. Hooker, who left Cohere in August, quietly announced the startup this month to start recruiting more broadly.\n\nI'm starting a new project.Working on what I consider to be the most important problem: building thinking machines that adapt and continuously learn. We have incredibly talent dense founding team + are hiring for engineering, ops, design. Join us: https://t.co/eKlfWAfuRy— Sara Hooker (@sarahookr) October 7, 2025\n\nIn an interview with TechCrunch, Hooker says Adaption Labs is building AI systems that can continuously adapt and learn from their real-world experiences, and do so extremely efficiently. She declined to share details about the methods behind this approach or whether the company relies on LLMs or another architecture.\n“There is a turning point now where it’s very clear that the formula of just scaling these models — scaling-pilled approaches, which are attractive but extremely boring — hasn’t produced intelligence that is able to navigate or interact with the world,” said Hooker.\nAdapting is the “heart of learning,” according to Hooker. For example, stub your toe when you walk past your dining room table, and you’ll learn to step more carefully around it next time. AI labs have tried to capture this idea through reinforcement learning (RL), which allows AI models to learn from their mistakes in controlled settings. However, today’s RL methods don’t help AI models in production — meaning systems already being used by customers — to learn from their mistakes in real time. They just keep stubbing their toe.\nSome AI labs offer consulting services to help enterprises fine-tune their AI models to their custom needs, but it comes at a price. OpenAI reportedly requires customers to spend upward of $10 million with the company to offer its consulting services on fine-tuning.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 27-29, 2025\n\t\t\t\t\t\t\t\n\t\t\n\t\n“We have a handful of frontier labs that determine this set of AI models that are served the same way to everyone, and they’re very expensive to adapt,” said Hooker. “And actually, I think that doesn’t need to be true anymore, and AI systems can very efficiently learn from an environment. Proving that will completely change the dynamics of who gets to control and shape AI, and really, who these models serve at the end of the day.”\nAdaption Labs is the latest sign that the industry’s faith in scaling LLMs is wavering. A recent paper from MIT researchers found that the world’s largest AI models may soon show diminishing returns. The vibes in San Francisco seem to be shifting, too. The AI world’s favorite podcaster, Dwarkesh Patel, recently hosted some unusually skeptical conversations with famous AI researchers.\nRichard Sutton, a Turing award winner regarded as “the father of RL,” told Patel in September that LLMs can’t truly scale because they don’t learn from real-world experience. This month, early OpenAI employee Andrej Karpathy told Patel he had reservations about the long-term potential of RL to improve AI models.\nThese types of fears aren’t unprecedented. In late 2024, some AI researchers raised concerns that scaling AI models through pretraining — in which AI models learn patterns from heaps of datasets — was hitting diminishing returns. Until then, pretraining had been the secret sauce for OpenAI and Google to improve their models.\nThose pretraining scaling concerns are now showing up in the data, but the AI industry has found other ways to improve models. In 2025, breakthroughs around AI reasoning models, which take additional time and computational resources to work through problems before answering, have pushed the capabilities of AI models even further.\nAI labs seem convinced that scaling up RL and AI reasoning models are the new frontier. OpenAI researchers previously told TechCrunch that they developed their first AI reasoning model, o1, because they thought it would scale up well. Meta and Periodic Labs researchers recently released a paper exploring how RL could scale performance further — a study that reportedly cost more than $4 million, underscoring how expensive current approaches remain.\nAdaption Labs, by contrast, aims to find the next breakthrough and prove that learning from experience can be far cheaper. The startup was in talks to raise a $20 million to $40 million seed round earlier this fall, according to three investors who reviewed its pitch decks. They say the round has since closed, though the final amount is unclear. Hooker declined to comment.\n“We’re set up to be very ambitious,” said Hooker, when asked about her investors.\nHooker previously led Cohere Labs, where she trained small AI models for enterprise use cases. Compact AI systems now routinely outperform their larger counterparts on coding, math, and reasoning benchmarks — a trend Hooker wants to continue pushing on.\nShe also built a reputation for broadening access to AI research globally, hiring research talent from underrepresented regions such as Africa. While Adaption Labs will open a San Francisco office soon, Hooker says she plans to hire worldwide.\nIf Hooker and Adaption Labs are right about the limitations of scaling, the implications could be huge. Billions have already been invested in scaling LLMs, with the assumption that bigger models will lead to general intelligence. But it’s possible that true adaptive learning could prove not only more powerful — but far more efficient.\nMarina Temkin contributed reporting.\n"
  }
]