[
  {
    "title": "Meta pauses international expansion of its Ray-Ban Display glasses",
    "url": "https://techcrunch.com/2026/01/06/meta-pauses-international-expansion-of-its-ray-ban-display-glasses/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/09/Meta-Ray-Ban-Display-Outdoor-Lifestyle-1.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-06T15:04:49.000Z",
    "description": "\nIn Brief\nPosted:\n7:04 AM PST · January 6, 2026\n\nImage Credits:Meta\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nMeta is pausing its plans to sell its R",
    "body": "\nIn Brief\nPosted:\n7:04 AM PST · January 6, 2026\n\nImage Credits:Meta\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nMeta is pausing its plans to sell its Ray-Ban Display glasses outside the U.S. due to “unprecedented demand and limited supply,” the company said on Tuesday. Meta had originally planned to launch the glasses in France, Italy, Canada, and the U.K. in early 2026.\n“Since launching last fall, we’ve seen an overwhelming amount of interest, and as a result, product waitlists now extend well into 2026,” the company said. “Because of this unprecedented demand and limited inventory, we’ve decided to pause our planned international expansion.”\nMeta says it will continue focusing on fulfilling U.S. orders while it re-evaluates its approach to international availability.\nUnveiled in September, the Meta Ray-Ban Display smart glasses are controlled by a wristband called the Meta Neural Band, which detects subtle hand gestures.\nAt CES this week in Las Vegas, Meta showed off new features coming to the glasses and the Neural Band. The glasses are getting a new teleprompter feature that gives users a portable way to deliver prepared remarks. Plus, users can now jot down messages using their finger on any surface while wearing Meta Neural Band and have those movements transcribed into digital messages.\nMeta is also expanding pedestrian navigation to Denver, Las Vegas, Portland, and Salt Lake City. \n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\nLatest in Hardware\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Meta pauses international expansion of its Ray-Ban Display glasses",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/09/Meta-Ray-Ban-Display-Outdoor-Lifestyle-1.jpg?w=150"
      ],
      "datePublished": "2026-01-06T15:04:49.000Z",
      "dateModified": "2026-01-06T15:04:49.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "AMD unveils new AI PC processors for general use and gaming at CES",
    "url": "https://techcrunch.com/2026/01/05/amd-unveils-new-ai-pc-processors-for-general-use-and-gaming-at-ces/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Ryzen-AI-Blog-1200x675-1.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-06T03:30:00.000Z",
    "description": "\nAMD Chair and CEO Lisa Su kicked off her keynote at CES 2026 with a message about what compute could deliver: AI for everyone. \nAs part of that promi",
    "body": "\nAMD Chair and CEO Lisa Su kicked off her keynote at CES 2026 with a message about what compute could deliver: AI for everyone. \nAs part of that promise, AMD announced a new line of AI processors as the company thinks AI-powered personal computers are the way of the future.\nThe semiconductor giant revealed AMD Ryzen AI 400 Series processor, its latest version of its AI-powered PC chips, at the yearly CES conference on Monday. The company says the latest version of its Ryzen processor series allows for 1.3x faster multitasking than its competitors and are 1.7x times faster at content creation.\nThese new chips feature 12 CPU Cores, individual processing units inside a core processor, and 24 threads, independent streams of instruction\nThis is an upgrade to the Ryzen AI 300 Series processor that was announced in 2024. AMD started producing the Ryzen processor series in 2017.\nRahul Tikoo, senior vice president and general manager of AMD’s client business, said AMD has expanded to over 250 AI PC platforms on the company’s recent press briefing. That represents a growth 2x over the last year, he added.\n“In the years ahead, AI is going to be a multi-layered fabric that gets woven into every level of computing at the personal layer,” Tikoo said. “Our AI PCs and devices will transform how we work, how we play, how we create and how we connect with each other.”\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAMD also announced the release of the AMD Ryzen 7 9850X3D, the latest version of its gaming-focused processor.\n“No matter who you are and how you use technology on a daily basis, AI is reshaping everyday computing,” Tikoo said. “You have thousands of interactions with your PC every day. AI is able to understand, learn context, bring automation, provide deep reasoning and personal customization to every individual.”\nPCs that include either the Ryzen AI 300 Series processor or the AMD Ryzen 7 9850X3D processor become available in the first quarter of 2026.\nThe company also announced the latest version of its Redstone ray tracing technology, which simulates physical behavior of light, which allows for better video game graphics without a performance or speed lag.\nFollow along with all of TechCrunch’s coverage of the annual CES conference here. \n\n\n\t\tBecca is a senior writer at TechCrunch that covers venture capital trends and startups. She previously covered the same beat for Forbes and the Venture Capital Journal.\r\nYou can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AMD unveils new AI PC processors for general use and gaming at CES",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/Ryzen-AI-Blog-1200x675-1.jpg?w=150"
      ],
      "datePublished": "2026-01-06T03:30:00.000Z",
      "dateModified": "2026-01-06T03:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Amazon’s Ring doorbells get fire alerts, an app store and new sensors",
    "url": "https://techcrunch.com/2026/01/06/amazons-ring-doorbells-get-fire-alerts-an-app-store-and-new-sensors/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/20250714_lifestyle_wireddoorbellprogen3_sn_frontdoor_RGB.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-01-06T14:00:00.000Z",
    "description": "\nAmazon’s augmenting its Ring smart doorbells with new features, including new fire alerts, an app store, and a new set of Ring Sensors.\nThe company s",
    "body": "\nAmazon’s augmenting its Ring smart doorbells with new features, including new fire alerts, an app store, and a new set of Ring Sensors.\nThe company said the new Ring Sensors can detect motion, openings, glass breakage, and smoke, and can also monitor carbon monoxide levels, leaks, temperature changes, and air quality. They also let you control lighting and appliances that are connected to your smart home network. \nAmazon is also adding a new app store to the Ring app to allow users to use its cameras with third-party apps. The store is currently available in the U.S. only, and users will be able to browse a selection of apps in the coming weeks. While the company didn’t specify what kind of apps the store would feature, it said these apps would focus on small business operations and everyday needs around the house.\nAnd as fires grow more common in drought affected areas, the company has teamed up with the fire monitoring app, Watch Duty, to show real-time updates and early warnings in the Ring app’s Neighbors section. Users can also share live updates using their Ring cameras to this section. \nNotably, the new devices being launched support Amazon’s Sidewalk shared network feature, which creates a mesh network between the company’s Echo and Ring devices by sharing a small portion of your bandwidth, enabling devices to work even when they aren’t in wireless range of your Wi-Fi router.\nAmazon is also adding a new AI-based feature to Ring cameras that learns the everyday patterns of a property and alerts users if anything unusual occurs. Dubbed “AI Unusual Event Alerts,” the company said the feature enables the Ring camera to surface specific warnings when it detects a person, based on location, actions and clothing. \nFor people who subscribe to Amazon’s Virtual Security Guard services, these warnings could trigger intervention automatically. In the last month, the company has rolled out features that use video recognition to trigger Alexa responses and send you personalized notifications based on a database of 50 faces.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe company has also launched a new Ring Car Alarm with in-built GPS for vehicle monitoring.\n\n\n\t\tIvan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.\r\nYou can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Amazon’s Ring doorbells get fire alerts, an app store and new sensors",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/20250714_lifestyle_wireddoorbellprogen3_sn_frontdoor_RGB.jpeg?w=150"
      ],
      "datePublished": "2026-01-06T14:00:00.000Z",
      "dateModified": "2026-01-06T14:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Narwal adds AI to its vacuum cleaners to monitor pets and find jewelry",
    "url": "https://techcrunch.com/2026/01/05/narwal-adds-ai-to-its-vacuum-cleaners-to-monitor-pets-and-find-jewelry/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/002.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-01-06T07:18:00.000Z",
    "description": "\n\t\n\t\tImage Credits:Narwal / Narwal\t\n\t\n\t\t\t\t\t\t11:18 PM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nRobot vacuum maker Narwal unveiled its new set of smart vac",
    "body": "\n\t\n\t\tImage Credits:Narwal / Narwal\t\n\t\n\t\t\t\t\t\t11:18 PM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nRobot vacuum maker Narwal unveiled its new set of smart vacuum cleaners at the Consumer Electronics Show (CES) with AI-powered features such as monitoring pets, finding valuable objects, and notifying users about misplaced toys.\nThe company said that its new flagship Flow 2 robot vacuum has a rounded design and easy-lift tanks for better cleaning. The device uses two 1080p RGB cameras with a 136-degree field of view to map out the area and recognize different kinds of objects using AI models.\nNarwal said that through this tech stack, the vacuum cleaner has the ability to identify an unlimited number of objects. The device first tries to identify an object locally, but in case there are no matches, it sends the data to the cloud for further processing. \nImage Credits: NarwalImage Credits:Narwal\nThe Flow 2 has three key modes called pet care mode, baby care mode, and AI floor tag mode. With pet care mode, you can define zones where pets usually rest or hang out to clean them. Plus, it can monitor pets and also check in on your pets via two-way audio (there is no guarantee that they would listen to you, though). In the baby care mode, the vacuum switches to quiet mode near the crib and notifies you of misplaced toys. In the AI floor tag mode, the vacuum recognizes valuable items like jewelry, avoids them, and alerts you.\nNarwal said that its newest vacuum cleaner has four cleaning modes that can identify different types of dirt. The device can also return to its base to wash the mop and then re-mop a certain area if it is dirty. The company noted that the Flow 2’s design allows for a higher hot water washing temperature for better cleaning.\nImage Credits: Narwal\nAlong with the Flow 2, the company also showed off a handheld vacuum called the U50 that weighs 1.41kg (3.1 lbs) and has UV-C sterilization along with heat treatment for allergen removal. The company also demoed an unnamed cordless vacuum with a slim design, 360-degree swivel, and up to 50 minutes of run time. The cordless vacuum also has an auto-empty station that can support up to 60 days of dust disposal.\n\n\t\t\t\n\tTopics\n\n\n\n\t\tIvan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.\r\nYou can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Narwal adds AI to its vacuum cleaners to monitor pets and find jewelry",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/002.jpeg?w=150"
      ],
      "datePublished": "2026-01-06T07:18:00.000Z",
      "dateModified": "2026-01-06T07:18:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Lucid Motors doubled EV output in 2025 after early Gravity SUV struggles",
    "url": "https://techcrunch.com/2026/01/05/lucid-motors-doubled-ev-output-in-2025-after-early-gravity-suv-struggles/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/04/lucid-gravity-main.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T16:51:18.000Z",
    "description": "\n\t\n\t\tImage Credits:Lucid Group\t\n\t\n\t\t\t\t\t\t8:51 AM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nLucid Motors built twice as many electric vehicles in 2025 as it",
    "body": "\n\t\n\t\tImage Credits:Lucid Group\t\n\t\n\t\t\t\t\t\t8:51 AM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nLucid Motors built twice as many electric vehicles in 2025 as it did in the prior year, a sign that the company has bounced back from early production struggles with its new Gravity SUV. \nThe company announced Monday that it finished the year having built 18,378 EVs, with 8,412 of those coming in the fourth quarter alone. That’s more than Lucid built at its Casa Grande, Arizona factory in the first half of the year. Lucid also said it delivered — meaning sold — 15,841 vehicles across the whole year, a 55% increase over 2024’s figures.\nThe stronger finish to 2025 sets Lucid up for an all-important year that will see the company start building the first vehicle on its new mid-sized EV platform. The company has said this first vehicle will cost around $50,000, putting it near the same part of the market as the Tesla Model Y and Rivian’s upcoming R2 SUV.\nThe numbers still pale in comparison to the projections Lucid Motors threw around when it went public in a $4 billion reverse merger in 2021. At that time, the company claimed it would deliver 135,000 vehicles in 2025, with 86,000 of those being Gravity SUVs, 42,000 being Air sedans, and the remaining 7,000 coming from its yet-to-debut mid-sized EV. \nThose targets quickly became unrealistic as Lucid ran into production, supply, and demand challenges for both of its vehicles, all while navigating an automotive market that was severely disrupted by the pandemic. The company particularly struggled in early 2025 as it started to ramp up production of the Gravity SUV. It has since been dealing with a number of quality issues on the vehicle, to the level that interim CEO Marc Winterhoff sent an email to customers in December saying that he shared in their “frustration.”\n“Lingering software problems have unfortunately affected our customers’ experience and satisfaction. I would like to assure you that we are laser focused on addressing these issues,” he wrote.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\t\t\t\n\tTopics\n\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Lucid Motors doubled EV output in 2025 after early Gravity SUV struggles",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/04/lucid-gravity-main.jpg?w=150"
      ],
      "datePublished": "2026-01-05T16:51:18.000Z",
      "dateModified": "2026-01-05T16:51:18.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Lego Smart Bricks introduce a new way to build — and they don’t require screens",
    "url": "https://techcrunch.com/2026/01/05/lego-smart-bricks-introduce-a-new-way-to-build-and-they-dont-require-screens/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/SMARTBrick_16x9.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T20:31:51.000Z",
    "description": "\n\t\n\t\tImage Credits:Lego\t\n\t\n\t\t\t\t\t\t12:31 PM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nLego announced its new Smart Play system at CES 2026 on Monday, adding",
    "body": "\n\t\n\t\tImage Credits:Lego\t\n\t\n\t\t\t\t\t\t12:31 PM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nLego announced its new Smart Play system at CES 2026 on Monday, adding interactive, responsive Legos to the famously analog franchise.\nThe Smart Play system includes a 2×4 brick, Smart Tag tiles, and Smart Minifigures. The Smart Bricks and Minifigures can sense nearby Smart Tags, which are 2×2 studless tiles with unique digital IDs that tell the Bricks and Minifigures how to act.\nIf the Smart Tag comes in a set for building a helicopter, for example, then the Smart Brick will light up and make propeller sounds that would help bring a helicopter to life. Its built-in accelerometer would make these lights and sounds more consistent with how you’re actually playing with the helicopter, since the Brick will be able to sense when the helicopter is zooming through the sky or turned upside down.\nImage Credits:LEGO\nThe Smart Bricks are powered by a patented ASIC chip, which is smaller than the size of a single Lego stud. The chip uses near-field magnetic positioning to recognize the Tags around it, as well as a miniature speaker, accelerometer, and LED array. Lego also developed a Bluetooth-based protocol called BrickNet, which allows multiple Smart Bricks to recognize each other and operate in tandem. The company claims that BrickNet is protected by enhanced encryption and privacy controls (all of which is necessary, but imagine a world where hacking into toys wasn’t a concern!).\nThere’s no setup required to pair the elements of the Smart Play system, making it easy for kids to get started — and parents will be pleased to note that there are no screens involved in the Smart system at all. However, Lego’s website says that there will be a Smart Tag for animating Lego toilets, so… there’s that.\nLego’s first two Smart Play sets — which are both Star Wars-themed — will launch on March 1, though preorders open on Friday. The “Luke’s Red Five X-wing” building set will retail for $69.99, while the larger “Throne Room Duel and A-wing” set will cost $159.99. These sets use the Smart Play system to animate characters like Luke Skywalker and Princess Leia, allowing them to interact with Smart Tags, which enable Lightsaber duels among other Star Wars-related capabilities.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\t\t\t\n\tTopics\n\n\n\n\t\tAmanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.\nYou can contact or verify outreach from Amanda by emailing amanda@techcrunch.com or via encrypted message at @amanda.100 on Signal. \t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Lego Smart Bricks introduce a new way to build — and they don’t require screens",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/SMARTBrick_16x9.jpg?w=150"
      ],
      "datePublished": "2026-01-05T20:31:51.000Z",
      "dateModified": "2026-01-05T20:31:51.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "China’s Hesai will double production as lidar sensor industry shakes out",
    "url": "https://techcrunch.com/2026/01/05/chinas-hesai-will-double-production-as-lidar-sensor-industry-shakes-out/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/image.png?w=150",
    "tag": "Tech",
    "date": "2026-01-05T18:00:00.000Z",
    "description": "\nChinese lidar-maker Hesai announced plans on Monday to double its production capacity from 2 million units to 4 million units this year, as it looks ",
    "body": "\nChinese lidar-maker Hesai announced plans on Monday to double its production capacity from 2 million units to 4 million units this year, as it looks to corner the global market for the laser-based sensors. That would be well up from the 1 million-plus unit mark that Hesai hit in 2025.\nHesai’s push to grab more market share comes just one month after leading U.S. lidar-maker Luminar filed for Chapter 11 bankruptcy. That company is not expected to continue operating once its bankruptcy plan is approved, though it is looking to sell the lidar business.\nHesai has raised hundreds of millions of dollars over the last few years and is now listed on both the Nasdaq and the Hong Kong stock exchanges. That’s despite fighting an uphill battle against the U.S. government, which has accused the company of working closely with China’s military industry — a charge that Hesai has challenged.\nAt the 2026 Consumer Electronics Show in Las Vegas, Hesai told reporters it was able to double the production target because of “accelerating demand” in the automotive and robotics industries.\nThe company’s automotive efforts have been buoyed by the Chinese car market’s adoption of lidar sensors, which Hesai said is now in 25% of new electric cars sold in the country. It also claimed that many new vehicles in China are expected to integrate between three to six lidar sensors per car, “significantly expanding Hesai’s addressable market.” Hesai boasts 24 automotive customers, including a “top European” automaker, and said it has 4 million orders for its newest ATX lidar sensor.\nAutomotive has proved to be a fickle market for lidar sensors outside of China. That was one of the contributing factors to Luminar’s downfall, according to the company’s own bankruptcy filings. While Luminar secured deals to integrate its lidar sensors on Volvo, Polestar, and Mercedes-Benz vehicles, those plans fell apart. Volvo had at one point agreed to buy 1.1 million lidar sensors from Luminar, but delays to its new vehicle programs and cost overruns caused the Swedish automaker to back out of the deal. (Volvo ultimately only purchased around 10,000 sensors from Luminar.)\nRobotics is not guaranteed to be a successful market for lidar sensors, but some players besides Hesai see great promise. San Francisco-based Ouster, which acquired rival player Velodyne in 2023 as the lidar industry began to consolidate, has said it believes robotics represents a $14 billion market opportunity. This includes not just humanoid robotics, but last-mile delivery robots and military applications.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAt CES, Hesai is showcasing a robotic lawnmower and a robotic dog that use the company’s JT series lidar sensor. The company also hinted at its inclusion in humanoid robots as well. It has struck deals to provide lidar sensors to autonomous vehicle companies like Pony AI, Motional, WeRide, and Baidu.\nHesai also boasted it has helped drive down the cost of lidar sensors by 99.5% in just eight years. That, too, was a contributing factor to Luminar’s downfall; “pressure to reduce costs due to lower price points of China-based competitors” has been regularly listed in the company’s bankruptcy filings as the second-most important factor that explains why the U.S. company found it so hard to build up a self-sustaining business.\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "China’s Hesai will double production as lidar sensor industry shakes out",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/image.png?w=150"
      ],
      "datePublished": "2026-01-05T18:00:00.000Z",
      "dateModified": "2026-01-05T18:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Insight Partners sued by former vice president Kate Lowry",
    "url": "https://techcrunch.com/2026/01/05/insight-partners-sued-by-former-vice-president-kate-lowry/",
    "image": "https://techcrunch.com/wp-content/uploads/2023/11/gavel-messy-legal.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T23:30:00.000Z",
    "description": "\nKate Lowry, a former vice president at Insight Partners, is suing the firm, alleging disability discrimination, gender discrimination, and wrongful t",
    "body": "\nKate Lowry, a former vice president at Insight Partners, is suing the firm, alleging disability discrimination, gender discrimination, and wrongful termination, according to a suit filed on December 30 in San Mateo County, California, and seen by TechCrunch. Insight Partners did not immediately respond to TechCrunch’s request for comment.\nLowry told TechCrunch she filed the suit because she believes “too many powerful, wealthy people in venture act like it’s OK to break the law and systemically underpay and abuse their employees.”\n“It’s an oppressive system that reflect[s] broader trends in society that use fear, intimidation, and power to silence and isolate truth. I’m trying to change that.”\nLowry began working at Insight Partners in 2022, after previously working for Meta, McKinsey & Company, and an early-stage startup. The suit alleges that, upon being hired, she was assigned to a different supervisor than the person mentioned during her interview.  \nShe alleges in the suit that she was told by her new supervisor, who was a woman, to be “online all the time, including PTO, holidays, and weekends,” and to respond between “6 a.m. and 11 p.m. daily.”  \nLowry says in the suit that this first supervisor “berated, hazed, and antagonized” her, spoke openly about a hazing that would be “longer and more intense” than what she put other male reports through.  \nSome comments the supervisor allegedly made, according to the suit, include “you are incompetent, shut up and take notes” and “you need to obey me like a dog; do whatever I say whenever I say it, without speaking.”  Lowry also alleges that her supervisor assigned her “redundant tasks” and restricted her ability to participate in calls, while allowing less experienced male colleagues to do so. Lowry, instead, she alleges, was relegated to “administrative tasks such as note-taking and cataloging.”  \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nLowry said she became “increasingly ill” because of the work environment and that her physician advised a medical leave of absence, which she was granted and took from February to July 2023.  \nWhen she returned to work, she was placed on a new team and, the suit alleges, was told by the head of human resources that “if the new team did not like her, she would be fired.”  \nIn September 2023, Lowry said she got a concussion and took another medical leave and returned to work near the end of 2024. Due to some departures, she was placed under the supervision of a new person, where Lowry said her poor treatment continued. She also alleges that in 2024, her compensation was about 30% below the market. \nBy April 2025, she alleges she was told her compensation would be cut. In May of 2025, through her attorneys, Lowry sent a letter to Insight regarding her alleged treatment by the company. A week later, the firm terminated her employment, the suit states.  \nThe lawsuit is reminiscent of Ellen Pao’s suit against Kleiner Perkins back in 2012, in which she alleged discrimination and retaliation. That suit offered what was, at the time, a rare glimpse into how women partners felt they were treated in venture capital. Though Pao lost that suit, it sent waves through the industry, and other women went on to sue major tech companies.  \n\n\n\t\tDominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. She is based in New York City.\r\nYou can contact or verify outreach from Dominic by emailing dominic.davis@techcrunch.com or via encrypted message at +1 646 831-7565 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Insight Partners sued by former vice president Kate Lowry",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2023/11/gavel-messy-legal.jpg?w=150"
      ],
      "datePublished": "2026-01-05T23:30:00.000Z",
      "dateModified": "2026-01-05T23:30:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "This is Uber’s new robotaxi from Lucid and Nuro",
    "url": "https://techcrunch.com/2026/01/05/this-is-ubers-new-robotaxi-from-lucid-and-nuro/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/uber-lucid-gravity.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T23:00:04.000Z",
    "description": "\nUber, Lucid Motors, and Nuro have revealed the production-intent version of their collaborative robotaxi at the 2026 Consumer Electronics Show, and T",
    "body": "\nUber, Lucid Motors, and Nuro have revealed the production-intent version of their collaborative robotaxi at the 2026 Consumer Electronics Show, and TechCrunch got a sneak peek ahead of the reveal.\nIt’s a vehicle that’s been in the works for more than half a year now, part of a deal that saw Uber invest $300 million into Lucid and commit to buying 20,000 of the company’s EVs. On Monday, the companies said the robotaxi is already being tested on public roads ahead of a planned commercial service launching in the San Francisco Bay Area later this year.\nBased on the Lucid Gravity SUV, the robotaxi has high-resolution cameras, solid state lidar sensors, and radars integrated into the body and the roof-mounted “halo.” The autonomy package is powered by Nvidia’s Drive AGX Thor computer. That halo also has integrated LED lights that will help riders identify their vehicle (similar to how Waymo’s Jaguar I-Pace SUVs work).\nCrucially, all of this extra tech is added to the Gravity as it’s being built at Lucid Motors’ Casa Grande, Arizona factory, saving the companies some time and money. By comparison, Waymo currently has to take apart the I-Pace SUVs it receives from Jaguar and integrate the autonomous tech as it puts them back together. (Future Waymo vehicles are planned to be more purpose-built.)\nImage Credits:Sean O'Kane\nThe vehicle unveiled on Monday is a more polished-up version of the test version that the three companies have spent the last seven months showing off in press photos. The newest element revealed at CES has to do with how users will interface with the Uber-Lucid-Nuro robotaxi. That includes a small screen on the halo meant to greet riders and a ride interface inside the cabin.\nAnyone who has ridden in a Waymo will find this UI experience familiar. The rear passenger screen shows an isometric graphical view of the robotaxi moving through city streets, with representations of nearby cars and pedestrians. \nThe companies did not have an interactive version of the software — which is being created by Uber — ready to test out just yet. But it has been built to show the standard information like estimated drop-off time, how much ride time is remaining, and climate and music controls. There are also buttons to reach rider support and to tell the robotaxi to pull over.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe front passenger screen shows a lot of the same information, just on a larger central touchscreen display. In the demonstration car on display at the Fontainebleau hotel, a lot of the same elements appeared on the Gravity’s sweeping 34-inch curved OLED display, which sits behind the steering wheel. \nUber chose to build this forthcoming “premium” robotaxi service around the Gravity, and at a high level it seems like a wise decision. The Gravity is immensely spacious inside, especially in the two-row configuration on display at the hotel. (Uber says a three-row version will be available, too.) \nThat said, the Gravity’s first full year came with struggles. Lucid fought with software issues as it ramped up production of the SUV, and the problems got bad enough that interim CEO Marc Winterhoff sent an email to owners in December apologizing for the “frustrations” they experienced. \nLucid has seemingly been able to bounce back from that, and on Monday announced that it doubled its 2024 production figures and reached new sales records. Time will tell if the robotaxi version has any of the same kinds of software struggles.\nUber, Lucid, and Nuro said Monday that once final validation is complete on the robotaxi later this year, true production versions will start rolling off Lucid’s factory lines in Arizona. The companies did not give a concrete timeline for that, though.\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "This is Uber’s new robotaxi from Lucid and Nuro",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/uber-lucid-gravity.jpg?w=150"
      ],
      "datePublished": "2026-01-05T23:00:04.000Z",
      "dateModified": "2026-01-05T23:00:04.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "The 2026 BMW iX3 voice assistant will be powered by Alexa+",
    "url": "https://techcrunch.com/2026/01/05/the-2026-bmw-ix3-voice-assistant-will-be-powered-by-alexa/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/bmw-amazon.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T17:00:00.000Z",
    "description": "\n\t\n\t\tImage Credits:Amazon\t\n\t\n\t\t\t\t\t\t9:00 AM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nBMW is finally getting the next-generation Alexa voice assistant and ",
    "body": "\n\t\n\t\tImage Credits:Amazon\t\n\t\n\t\t\t\t\t\t9:00 AM PST · January 5, 2026\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nBMW is finally getting the next-generation Alexa voice assistant and it’s coming with a generative AI upgrade. \nAmazon said Monday that the 2026 BMW iX3 will be equipped with Alexa+, the same generative AI tech that launched in millions of the e-commerce giant’s smart devices last year. This will be the first vehicle to come with Amazon’s next-generation voice assistant, the companies announced during the 2026 Consumer Electronics Show in Las Vegas.\nThe launch is one part of Amazon’s effort to bring its LLM-powered voice and digital assistant to every device — whether handheld or in the driver’s seat — touched by consumers. Alexa+ is already in more than 600 million devices. And automotive is next on the list.\nBringing a custom version of Alexa+ into the BMW iX3 will be an important test for Amazon. Automakers have struggled for years to bring a voice assistant inside vehicles that can handle complex functions and requests that don’t end with the driver yelling in frustration. Efforts to develop natural language processing — a form of AI that lets computers understand and respond to human speech — have been in the works for more than a decade. And while progress has been made, these systems can still be easily stumped by humans.\nBMW and Amazon’s Alexa+ partnership has been three years in the making.\nBMW announced in 2022 that Amazon Alexa would be the foundation of its next-generation voice assistant. This meant BMW wouldn’t just embed Alexa into its vehicles but would also use Amazon’s technology platform known as Alexa Custom Assistant to build its own custom version. That timeline was extended as Amazon worked on an automotive version of Alexa+, an overhauled voice assistant developed and powered by large language models that promises to deliver seamless and natural conversations, like talking to a human.\nAlexa+ was built using Amazon Bedrock, a service that lets AWS customers build apps using generative AI models from Amazon and other third-party partners. Customers, like BMW, can then customize the app with their proprietary data.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe end result, according to Amazon, is a voice assistant that can break down complex requests, reason through steps, and take actions across different services. For instance, Amazon says users can start a conversation with their Alexa+-enabled Echo speaker in the home and continue it in their BMW. Once in the car, the user can make requests through the Alexa+ assistant that might normally require opening up different apps, like music, navigation, and a home security system.\n\n\t\t\t\n\tTopics\n\n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "The 2026 BMW iX3 voice assistant will be powered by Alexa+",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/bmw-amazon.jpeg?w=150"
      ],
      "datePublished": "2026-01-05T17:00:00.000Z",
      "dateModified": "2026-01-05T17:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Nvidia launches Alpamayo, open AI models that allow autonomous vehicles to ‘think like a human’",
    "url": "https://techcrunch.com/2026/01/05/nvidia-launches-alpamayo-open-ai-models-that-allow-autonomous-vehicles-to-think-like-a-human/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Alpamayo-Image.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T21:52:22.000Z",
    "description": "\nAt CES 2026, Nvidia launched Alpamayo, a new family of open source AI models, simulation tools, and datasets for training physical robots and vehicle",
    "body": "\nAt CES 2026, Nvidia launched Alpamayo, a new family of open source AI models, simulation tools, and datasets for training physical robots and vehicles that are designed to help autonomous vehicles reason through complex driving situations.\n“The ChatGPT moment for physical AI is here – when machines begin to understand, reason, and act in the real world,” Nvidia CEO Jensen Huang said in a statement. “Alpamayo brings reasoning to autonomous vehicles, allowing them to think through rare scenarios, drive safely in complex environments, and explain their driving decisions.” \nAt the core of Nvidia’s new family is Alpamayo 1, a 10 billion-parameter chain-of-thought, reason-based vision language action (VLA) model that allows an AV to think more like a human so it can solve complex edge cases — like how to navigate a traffic light outage at a busy intersection — without previous experience. \n“It does this by breaking down problems into steps, reasoning through every possibility, and then selecting the safest path,” Ali Kani, Nvidia’s vice president of automotive, said Monday during a press briefing. \nOr as Huang put it during his keynote on Monday: “Not only does [Alpamayo] take sensor input and activate steering wheel, brakes, and acceleration, it also reasons about what action it’s about to take. It tells you what action it’s going to take, the reasons by which it came about that action. And then, of course, the trajectory.”\nAlpamayo 1’s underlying code is available on Hugging Face. Developers can fine-tune Alpamayo into smaller, faster versions for vehicle development, use it to train simpler driving systems, or build tools on top of it like auto-labeling systems that automatically tag video data or evaluators that check if a car made a smart decision. \n“They can also use Cosmos to generate synthetic data and then train and test their Alpamayo-based AV application on the combination of the real and synthetic dataset,” Kani said. Cosmos is Nvidia’s brand of generative world models, AI systems that create a representation of a physical environment so they can make predictions and take actions. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAs part of the Alpamayo rollout, Nvidia is also releasing an open dataset with more than 1,700 hours of driving data collected across a range of geographies and conditions, covering rare and complex real-world scenarios. The company is additionally launching AlpaSim, an open source simulation framework for validating autonomous driving systems. Available on GitHub, AlpaSim is designed to recreate real-world driving conditions, from sensors to traffic, so developers can safely test systems at scale.\n\n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Nvidia launches Alpamayo, open AI models that allow autonomous vehicles to ‘think like a human’",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/Alpamayo-Image.jpg?w=150"
      ],
      "datePublished": "2026-01-05T21:52:22.000Z",
      "dateModified": "2026-01-05T21:52:22.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Boston Dynamics’ next-gen humanoid robot will have Google DeepMind DNA",
    "url": "https://techcrunch.com/2026/01/05/boston-dynamicss-next-gen-humanoid-robot-will-have-google-deepmind-dna/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/atlas-announcement.jpg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T21:55:55.000Z",
    "description": "\nRobotics company Boston Dynamics has struck a partnership with Google’s AI research lab to speed up the development of its next-generation humanoid r",
    "body": "\nRobotics company Boston Dynamics has struck a partnership with Google’s AI research lab to speed up the development of its next-generation humanoid robot Atlas — and make it act more human around people.\nThe partnership, which was announced Monday during the Hyundai press conference at CES 2026, is centered on robotics research that will use Google DeepMind’s AI foundation models. Boston Dynamics’ humanoid robot Atlas will be the first test case, according to Carolina Parada, senior director of robotics at Google DeepMind.\n“We’re looking to integrate our cutting-edge AI foundation models with Boston Dynamics’ new Atlas robots, and we’ll aim to develop the world’s most advanced robot foundation model to fulfill the promise of true general-purpose human needs,” Parada said onstage.\nThe tie-up comes less than a year after the Google AI research lab announced new AI models called Gemini Robotics that are designed to allow robots to perceive, reason, use tools, and interact with humans. Gemini Robotics is based on a large-scale multimodal generative AI model, Gemini. At the time, Google DeepMind said the robotics AI model was trained to generalize behavior across a range of different robotics hardware.\nEnter Boston Dynamics, and its majority owner, Hyundai Motor Group. While accelerating research will be a central piece of this partnership, this has real-world scaling intent.\nBoston Dynamics already has products, like the quadruped Spot, that are in customers’ hands in more than 40 countries. Its warehouse robot Stretch has unloaded more than 20 million boxes globally since its launch in 2023, according to Hyundai. Now Boston Dynamics and Hyundai are preparing for the next generation, starting with the humanoid robot Atlas, which the company announced Monday is already in production and headed to the Hyundai factory in Savannah, Georgia\nA prototype of Atlas walked onstage during the press conference, showing off its ability to move. But as Alberto Rodriguez, director of Atlas behavior at Boston Dynamics, noted, making “Atlas into a product requires more than athletic performance for humanoids to really deliver on their promise. They have to be able to interact with people naturally.”\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nRodriguez and his counterparts at Boston Dynamics believe that recent advancements in AI have created a clear path to get to those capabilities. That kind of natural interaction with humans has real safety implications. \nThe Atlas product, which was also revealed onstage Monday and will eventually head to Hyundai’s factory, has 56 degrees of freedom with rotation joints and human-scale hands that have tactile sensing. And it’s strong. The Atlas robot can lift up to 110 pounds and is designed to perform repetitive movements. \nWith that kind of dexterity and strength, it will be critical for Atlas, or any humanoid robot, to safely interact and work with humans. Some of that has been handled on the hardware side; Atlas, for instance, has 360-degree cameras to allow it to see when people are approaching. But DeepMind’s work could help the robots learn how to act.\n“Rather than having a set of predefined, loaded tasks onto the robot, we think robots should understand the physical world the same way we do,”Parada said. “They should be able to learn from their experience. Should be able to generalize new situations and get better over time. So whether it is to assemble a new car part or to tie your shoelaces, robots should learn the same way we do from a handful of examples, and then get better very quickly with a little bit of practice.”\nHyundai, which plans to bring Atlas to its factory this year and eventually deploy them for tasks like parts sequencing by 2028, has also developed protocols to increase safety and efficiency.\nHyundai said Monday it is opening a U.S. facility this year called a Robot Metaplant Application Center, or RMAC, that will teach robots how to map movements like lifts and turns. Training data from RMAC will be combined with real-world data collected via a software platform used in its Georgia factory to continually improve the robots.\nFollow along with all of TechCrunch’s coverage of the annual CES conference here. \nThis article was updated to include more information about Atlas’ specs. \n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Boston Dynamics’ next-gen humanoid robot will have Google DeepMind DNA",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/atlas-announcement.jpg?w=150"
      ],
      "datePublished": "2026-01-05T21:55:55.000Z",
      "dateModified": "2026-01-05T21:55:55.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Offshore wind developers sue Trump administration for halting $25B in projects",
    "url": "https://techcrunch.com/2026/01/05/offshore-wind-developers-sue-trump-administration-for-halting-25b-in-projects/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-831764682.jpeg?w=150",
    "tag": "Tech",
    "date": "2026-01-05T18:20:23.000Z",
    "description": "\nThree offshore wind developers are suing the Trump administration after the Department of the Interior halted five projects worth a total of $25 bill",
    "body": "\nThree offshore wind developers are suing the Trump administration after the Department of the Interior halted five projects worth a total of $25 billion on December 22. If completed, the projects would generate a total of 6 gigawatts of electricity.\nTwo lawsuits were filed Thursday and Friday last week by Ørsted and Equinor, which are developing the 704 megawatt Revolution Wind and the 2 gigawatt Empire Wind, respectively. Another was filed on December 23 by Dominion Energy, which is building a 2.6 gigawatt farm off the coast of Virginia.\nRevolution Wind is nearly 90% complete, while Empire Wind and Coastal Virginia Offshore Wind are each about 60% complete. Dominion said it was losing $5 million per day as a result of the halt.\nAvangrid, which is developing Vineyard Wind 1, has not filed a lawsuit yet. Nearly half that project is currently operational.\nThe Department of the Interior cited national security concerns in its decision to stop construction on the projects. Though it didn’t mention specifics, the Trump administration may have been referencing the challenges wind turbines present to radar operations. The Department of Energy had issued a report that discussed this security concern, as well as solutions to it, in February 2024.\nWind turbines’ whirling blades have been known to stymie radar systems, but researchers in the government and private companies have been working to mitigate the problem for well over a decade. \nChoosing the precise site for wind energy projects is one of the biggest ways to ameliorate interference. The Bureau of Ocean Energy Management coordinates with the Military Aviation and Installation Assurance Siting Clearinghouse to “review each proposed offshore wind project on a project-by-project basis, and would attempt to de-conflict concerns related to individual projects or multiple projects,” according to Vineyard Wind 1’s environmental impact statement.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nNewer radar systems can filter the noise that wind farms produce through adaptive processing algorithms, Rand Corporation senior engineer Nicholas O’Donoughue previously told TechCrunch. Vineyard Wind 1 agreed to help fund radar adaptations and to curtail operations when asked by the Pentagon, for example. \nEarlier last year, the Trump administration halted approvals for new offshore wind projects in addition to pausing work on Empire Wind and Revolution Wind. The latter restarted after New York State negotiated with the Trump administration, while a federal judge struck down the stop work order for Revolution Wind. \n\n\n\t\tTim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor. \r\nDe Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.\r\nYou can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Offshore wind developers sue Trump administration for halting $25B in projects",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-831764682.jpeg?w=150"
      ],
      "datePublished": "2026-01-05T18:20:23.000Z",
      "dateModified": "2026-01-05T18:20:23.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Hacktivist deletes white supremacist websites live onstage during hacker conference",
    "url": "https://techcrunch.com/2026/01/05/hacktivist-deletes-white-supremacist-websites-live-on-stage-during-hacker-conference/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/martha-root-whitedate-hack-screenshot1-e1767638022105.png?w=150",
    "tag": "Tech",
    "date": "2026-01-05T18:57:31.000Z",
    "description": "\nA hacktivist remotely wiped three white supremacist websites live onstage during their talk at a hacker conference last week, with the sites yet to r",
    "body": "\nA hacktivist remotely wiped three white supremacist websites live onstage during their talk at a hacker conference last week, with the sites yet to return online.\nThe pseudonymous hacker, who goes by Martha Root — dressed as Pink Ranger from the Power Rangers — deleted the servers of WhiteDate, WhiteChild, and WhiteDeal in real time at the end of a talk at the annual Chaos Communication Congress in Hamburg, Germany. \nRoot gave the talk alongside journalists Eva Hoffmann and Christian Fuchs, who wrote an article about the hacked sites for the German weekly paper Die Zeit in October. \nAs of this writing, WhiteDate, which Hoffmann described as a “Tinder for Nazis”; WhiteChild, a site that claimed to match white supremacists’ sperm and egg donors; and WhiteDeal, a sort-of Taskrabbit-esque labor marketplace for racists, are all offline.\nThe administrator of the three websites confirmed the hack on their social media accounts. \n“They publicly delete all my websites while the audience rejoices. This is cyberterrorism,” the administrator wrote on X on Sunday, vowing repercussions.\nThe administrator also claimed that Root deleted their X account before it was restored.\n\n‼️A German hacker known as \"Martha Root\" dressed as a pink Power Ranger and deleted a white supremacist dating website live onstageThis happened during the recent CCC conference.Martha had infiltrated the site, ran her own AI chatbot to extract as much information from users… pic.twitter.com/vpTEoFR8JR— International Cyber Digest (@IntCyberDigest) January 2, 2026\n\nRoot also published the data allegedly scraped from WhiteDate online. \nThe hacker said that they scraped WhiteDate’s public data and found “poor cybersecurity hygiene that would make even your grandma’s AOL account blush.” Root said that users’ images included precise geolocation metadata that “practically hands out home addresses with a side of awkward selfies.” \n“Imagine calling yourselves the ‘master race’ but forgetting to secure your own website — maybe try mastering to host WordPress before world domination,” Root wrote. \nThe leaked data includes users’ profiles with name, pictures, description, age, location (both containing precise coordinates and user-set country and state), gender, language, race, and other personal information that users uploaded. Root wrote on the site that “for now” there are no emails, passwords, or private conversations. \nAccording to the leaked data, WhiteDate had more than 6,500 users, of which 86% were men and 14% women. “A gender ratio that makes the Smurf village look like a feminist utopia,” Root wrote.\nRoot infiltrated the sites using AI chatbots that bypassed verification processes and were verified as “white,” according to the talks’ abstract. \nDDoSecrets, a nonprofit collective that stores leaked datasets in the public interest, announced that it has received “files and user information” from the three white supremacist websites. The collective, which calls this release “WhiteLeaks,” has not publicly released the data but is instead asking verified journalists and researchers to request access to the full 100 gigabyte dataset.\nThe administrator of the three websites did not immediately respond to TechCrunch’s request for comment, which was sent to an email address shown during the conference talk. TechCrunch also sent an email to an address that appears on the public domain records of two of the three websites. The person behind that address also did not immediately respond to our email.\nRoot, Hoffmann, and Fuchs claim to have identified the real identity of the websites’ administrator as a woman from Germany. TechCrunch could not independently confirm the identity of the administrator.\n\n\n\t\tLorenzo Franceschi-Bicchierai is a Senior Writer at TechCrunch, where he covers hacking, cybersecurity, surveillance, and privacy. \nYou can contact or verify outreach from Lorenzo by emailing lorenzo@techcrunch.com, via encrypted message at +1 917 257 1382 on Signal, and @lorenzofb on Keybase/Telegram.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Hacktivist deletes white supremacist websites live onstage during hacker conference",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/martha-root-whitedate-hack-screenshot1-e1767638022105.png?w=150"
      ],
      "datePublished": "2026-01-05T18:57:31.000Z",
      "dateModified": "2026-01-05T18:57:31.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Nvidia wants to be the Android of generalist robotics ",
    "url": "https://techcrunch.com/2026/01/05/nvidia-wants-to-be-the-android-of-generalist-robotics/",
    "image": "https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-05-at-5.03.42-PM.png?w=150",
    "tag": "Tech",
    "date": "2026-01-05T23:00:00.000Z",
    "description": "\nNvidia released a new stack of robot foundation models, simulation tools, and edge hardware at CES 2026, moves that signal the company’s ambition to ",
    "body": "\nNvidia released a new stack of robot foundation models, simulation tools, and edge hardware at CES 2026, moves that signal the company’s ambition to become the default platform for generalist robotics, much as Android became the operating system for smartphones. \nNvidia’s move into robotics reflects a broader industry shift as AI moves off the cloud and into machines that can learn how to think in the physical world, enabled by cheaper sensors, advanced simulation, and AI models that increasingly can generalize across tasks. \nNvidia revealed details on Monday about its full-stack ecosystem for physical AI, including new open foundation models that allow robots to reason, plan, and adapt across many tasks and diverse environments, moving beyond narrow task-specific bots, all of which are available on Hugging Face. \nThose models include: Cosmos Transfer 2.5 and Cosmos Predict 2.5, two world models for synthetic data generation and robot policy evaluation in simulation; Cosmos Reason 2, a reasoning vision language model (VLM) that allows AI systems to see, understand, and act in the physical world; and Isaac GR00T N1.6, its next-gen vision language action (VLA) model purpose-built for humanoid robots. GR00T relies on Cosmos Reason as its brain, and it unlocks whole-body control for humanoids so they can move and handle objects simultaneously. \nNvidia also introduced Isaac Lab-Arena at CES, an open source simulation framework hosted on GitHub that serves as another component of the company’s physical AI platform, enabling safe virtual testing of robotic capabilities.\nThe platform promises to address a critical industry challenge: As robots learn increasingly complex tasks, from precise object handling to cable installation, validating these abilities in physical environments can be costly, slow, and risky. Isaac Lab-Arena tackles this by consolidating resources, task scenarios, training tools, and established benchmarks like Libero, RoboCasa, and RoboTwin, creating a unified standard where the industry previously lacked one.\nSupporting the ecosystem is Nvidia OSMO, an open source command center that serves as connective infrastructure that integrates the entire workflow from data generation through training across both desktop and cloud environments. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAnd to help power it all, there’s the new Blackwell-powered Jetson T4000 graphics card, the newest member of the Thor family. Nvidia is pitching it as a cost-effective on-device compute upgrade that delivers 1200 teraflops of AI compute and 64 gigabytes of memory while running efficiently at 40 to 70 watts. \nNvidia is also deepening its partnership with Hugging Face to let more people experiment with robot training without needing expensive hardware or specialized knowledge. The collaboration integrates Nvidia’s Isaac and GR00T technologies into Hugging Face’s LeRobot framework, connecting Nvidia’s 2 million robotics developers with Hugging Face’s 13 million AI builders. The developer platform’s open source Reachy 2 humanoid now works directly with Nvidia’s Jetson Thor chip, letting developers experiment with different AI models without being locked into proprietary systems.  \nThe bigger picture here is that Nvidia is trying to make robotics development more accessible, and it wants to be the underlying hardware and software vendor powering it, much like Android is the default for smartphone makers.\nThere are early signs that Nvidia’s strategy is working. Robotics is the fastest growing category on Hugging Face, with Nvidia’s models leading downloads. Meanwhile robotics companies, from Boston Dynamics and Caterpillar to Franka Robots and NEURA Robotics, are already using Nvidia’s tech.\nFollow along with all of TechCrunch’s coverage of the annual CES conference here.\n\n\n\n\t\tRebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Her work has also appeared in Forbes, Bloomberg, The Atlantic, The Daily Beast, and other publications. \r\nYou can contact or verify outreach from Rebecca by emailing rebecca.bellan@techcrunch.com or via encrypted message at rebeccabellan.491 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Nvidia wants to be the Android of generalist robotics ",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-05-at-5.03.42-PM.png?w=150"
      ],
      "datePublished": "2026-01-05T23:00:00.000Z",
      "dateModified": "2026-01-05T23:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  }
]