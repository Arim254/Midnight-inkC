[
  {
    "title": "Another bid to block state AI regulation has failed…for now",
    "url": "https://techcrunch.com/2025/12/03/another-bid-to-block-state-ai-regulation-has-failedfor-now/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1246479507.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T16:06:35.000Z",
    "description": "\nIn Brief\nPosted:\n8:06 AM PST · December 3, 2025\n\nImage Credits:Benjamin Fanjoy/Bloomberg / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nTh",
    "body": "\nIn Brief\nPosted:\n8:06 AM PST · December 3, 2025\n\nImage Credits:Benjamin Fanjoy/Bloomberg / Getty Images\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nThe latest bid to squeeze a ban on states regulating AI into an annual defense bill has reportedly been rejected after facing bipartisan pushback. \nHouse Majority Leader Steve Scalise (R-LA) said Tuesday that Republican leaders would look for “other places” to include the measure – an effort that President Trump has supported – according to The Hill. \nThe proposal to preempt states from enacting their own AI regulation came months after GOP lawmakers sought to include a 10-year moratorium on state AI laws in Trump’s tax and spending bill earlier this year. The provision failed then due to strong resistance from both parties.\nSilicon Valley has supported such measures, arguing that state regulations create an unworkable patchwork of rules that could stymy innovation. \nCritics argue that most state AI legislation is focused on safety, transparency, and consumer protections, and in the absence of federal AI laws that perform those tasks, blocking states from regulating would be effectively handing over control to Big Tech with no oversight.\nScalise reportedly acknowledged that the defense bill was not the place to include such a provision, and echoed Trump’s previous calls to introduce the ban as a separate bill. A leaked draft executive order signals Trump is considering taking matters into his own hands, though those efforts have reportedly paused for now.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\nLatest in Government & Policy\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Another bid to block state AI regulation has failed…for now",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1246479507.jpg?w=150"
      ],
      "datePublished": "2025-12-03T16:06:35.000Z",
      "dateModified": "2025-12-03T16:06:35.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Kalshi raises $1B at $11B valuation, doubling value in under two months",
    "url": "https://techcrunch.com/2025/12/02/kalshi-raises-1b-at-11b-valuation-doubling-value-in-under-two-months/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/04/54430828088_f8b05f4647_4k.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-02T22:30:42.000Z",
    "description": "\nIn Brief\nPosted:\n2:30 PM PST · December 2, 2025\n\nImage Credits:TechCrunch\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nPrediction market Kalshi, which ",
    "body": "\nIn Brief\nPosted:\n2:30 PM PST · December 2, 2025\n\nImage Credits:TechCrunch\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nPrediction market Kalshi, which allows people to bet on future events, announced on Tuesday that it raised a $1 billion funding round at an $11 billion valuation, confirming TechCrunch’s scoop from last month.\nThe round was led by returning investor Paradigm, with participation from Sequoia Capital, Andreessen Horowitz, Capital G, and other existing backers. The latest funding comes less than two months after Kalshi announced that it raised $300 million at a $5 billion valuation.\nAlthough the trading platform surged in popularity last year when people used it to predict the outcome of the 2024 U.S. presidential elections, a large portion of Kalshi’s trades are actually tied to sports, according to The New York Times.\nKalshi is reportedly planning to announce a partnership with CNN. Additionally, future growth is expected to come from various companies using Kalshi to hedge against business-specific risks, such as government shutdowns or adverse weather changes.\nPolymarket, Kalshi’s main rival, was reportedly in talks to raise another round at a $12 billion to $15 billion valuation, Bloomberg reported in October.\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\nLatest in Startups\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Kalshi raises $1B at $11B valuation, doubling value in under two months",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/04/54430828088_f8b05f4647_4k.jpg?w=150"
      ],
      "datePublished": "2025-12-02T22:30:42.000Z",
      "dateModified": "2025-12-02T22:30:42.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Bending Spoons agrees to buy Eventbrite for $500M to revive stalled brand",
    "url": "https://techcrunch.com/2025/12/02/bending-spoons-agrees-to-buy-eventbrite-for-500m-to-revive-stalled-brand/",
    "image": "https://techcrunch.com/wp-content/uploads/2020/03/eventbrite-crowd.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-02T23:03:55.000Z",
    "description": "\nIn Brief\nPosted:\n3:03 PM PST · December 2, 2025\n\nImage Credits:Eventbrite\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nBending Spoons, a company that b",
    "body": "\nIn Brief\nPosted:\n3:03 PM PST · December 2, 2025\n\nImage Credits:Eventbrite\n\n\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\n\nBending Spoons, a company that buys and revitalizes stagnating tech companies, has agreed to purchase Eventbrite for about $500 million, a far cry from the $1.76 billion the company was worth when it went public in 2018.\nJust like many of Bending Spoons’ previous acquisitions, including Evernote, Meetup, Vimeo, and AOL, Eventbrite has a strong brand, but the company’s business has stopped growing, according to audited financials.  \nThe events marketplace and ticketing company was co-founded in 2006 by the husband-and-wife team Julia and Kevin Hartz, and Renaud Visage. During its 12 years as a private business, the one-time tech darling raised approximately $330 million in venture capital from top investors such as Sequoia Capital and Tiger Global Management.\nUnlike traditional private equity firms, Bending Spoons buys companies that it intends to hold forever, aiming to turn them profitable by cutting costs, raising prices, and introducing new product features. In October, Bending Spoons announced a massive $270 million funding round that valued the company at $11 billion.\nBesides Bending Spoons, other investors follow the strategy of acquiring, fixing, and holding stalled software firms, often referred to as “venture zombie” companies. These firms include Constellation Software, Curious, Tiny, SaaS.group, Arising Ventures, and Calm Capital.\nAndrew Dumont, the founder and CEO of Curious, told TechCrunch that the firm buys “great companies” at low prices and quickly revives them to achieve 20% to 30% profit margins. \nAudited annual revenue was flat at about $325 million for both fiscal year 2024 and fiscal year 2023. Bending Spoons has agreed to pay approximately 1.7 times Eventbrite’s trailing 12 months’ revenue of $295 million. Despite this seemingly low revenue multiple, Eventbrite stockholders will receive $4.50 in cash per share, an 81% premium over the previous day’s $2.48 closing price.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\n\tTopics\n\n\n\t\n\t\tSubscribe for the industry’s biggest tech news\n\t\n\nLatest in Media & Entertainment\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Bending Spoons agrees to buy Eventbrite for $500M to revive stalled brand",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2020/03/eventbrite-crowd.jpg?w=150"
      ],
      "datePublished": "2025-12-02T23:03:55.000Z",
      "dateModified": "2025-12-02T23:03:55.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Amazon Fire TV’s new AI feature lets you jump to scenes by describing them to Alexa+",
    "url": "https://techcrunch.com/2025/12/03/amazon-fire-tvs-new-ai-feature-lets-you-jump-to-scenes-by-describing-them-to-alexa/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/fire-tv-1.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T15:54:58.000Z",
    "description": "\n\t\n\t\tImage Credits:Amazon\t\n\t\n\t\t\t\t\t\t7:54 AM PST · December 3, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nAmazon announced Wednesday that it’s introducing a new AI-powered Fi",
    "body": "\n\t\n\t\tImage Credits:Amazon\t\n\t\n\t\t\t\t\t\t7:54 AM PST · December 3, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nAmazon announced Wednesday that it’s introducing a new AI-powered Fire TV feature that lets viewers jump to specific movie scenes on Prime Video simply by describing them to Alexa+. \n“Our number one mission at Fire TV is getting you to what you want to watch—fast,” Amazon wrote in a blog post. “Today’s launch builds on that mission with this new AI-powered feature. Just describe a movie scene like you would to a friend, and Alexa+ will jump directly to that specific moment—no more searching required.”\nAmazon says you can describe the scene to Alexa by mentioning details like the actor or character’s name, or a memorable quote.\nFor example, you could say “Jump to the scene in Mamma Mia where Sophie sings ‘Honey Honey’ in Love Actually” or “Jump to the scene where Deloris Jordan says ‘a shoe is just a shoe until my son steps into it’.”\nOther examples include: “Jump to the scene when John McClane says ‘come out to the coast, we’ll get together, have a few laughs’” and “Jump to the card scene in Love Actually.”\nAmazon says Alexa+ can identify the movie you’re talking about even if you don’t mention the title. It then uses visual understanding and movie captions to understand the characters, plot, and action in scenes to determine the specific moment you’re looking for. \nLike Alexa+, the new feature is built on Amazon Bedrock, which is Amazon’s service that offers a choice of generative AI models from the company itself and third-party partners through an API. The feature leverages a variety of large language models, including Amazon Nova and Anthropic Claude. \nThe feature works with thousands of movie titles available on Prime Video, including tens of thousands of indexed scenes, Amazon says. The company plans to add more movies and scenes, and expand the capability to TV shows soon.\nIt’s worth noting that the feature will only work if the movie is included with a Prime membership, or if you have purchased or rented it on Prime Video. \n\n\t\t\t\n\tTopics\n\n\n\n\t\tAisha is a consumer news reporter at TechCrunch. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Aisha holds an honours bachelor’s degree from University of Toronto and a master’s degree in journalism from Western University.\nYou can contact or verify outreach from Aisha by emailing aisha@techcrunch.com or via encrypted message at aisha_malik.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Amazon Fire TV’s new AI feature lets you jump to scenes by describing them to Alexa+",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/fire-tv-1.jpg?w=150"
      ],
      "datePublished": "2025-12-03T15:54:58.000Z",
      "dateModified": "2025-12-03T15:54:58.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Waymo starts autonomous testing in Philadelphia",
    "url": "https://techcrunch.com/2025/12/03/waymo-starts-autonomous-testing-in-philadelphia/",
    "image": "https://techcrunch.com/wp-content/uploads/2024/12/waymo2.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T14:00:00.000Z",
    "description": "\n\t\n\t\tImage Credits:Waymo\t\n\t\n\t\t\t\t\t\t6:00 AM PST · December 3, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nWaymo is adding another four cities to its growing list of robotaxi r",
    "body": "\n\t\n\t\tImage Credits:Waymo\t\n\t\n\t\t\t\t\t\t6:00 AM PST · December 3, 2025\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\nWaymo is adding another four cities to its growing list of robotaxi rollouts. The company announced Wednesday it has begun testing its autonomous vehicles (with a safety monitor) in Philadelphia, and that it will start manual driving to collect data in Baltimore, St. Louis, and Pittsburgh.\nWaymo did not offer a timeline for when it plans to launch commercial services in those locations, nor do we know whether the Alphabet-owned company will partner with other companies to operate robotaxis in each one. That has been the move in cities like Atlanta and Austin, for example, where Waymo has partnered with Uber to advance its robotaxi rollout.\nBut the new locations join a list of over 20 cities where the company is either offering rides, prepping a commercial launch, or testing. Waymo is also now offering rides on freeways in Los Angeles, Phoenix, and the San Francisco Bay Area. The company plans to be doing one million rides per week by the end of 2026.\nWaymo has done all this while claiming to be operating at a level five times safer than humans, according to data the company recently released. \nBut the expansion has not come without its issues. The National Highway Traffic Safety Administration is investigating how the company’s vehicles operate near school buses, after a Waymo was filmed driving around a stopped bus in Atlanta in September. \nThis week, Austin news outlet KXAN published a report showing Waymo’s vehicles have driven past school buses that were in the process of unloading or loading children multiple times — including after Waymo claims to have shipped software updates to address the problem.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n\n\t\t\t\n\tTopics\n\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n\n\t\t",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Waymo starts autonomous testing in Philadelphia",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2024/12/waymo2.jpg?w=150"
      ],
      "datePublished": "2025-12-03T14:00:00.000Z",
      "dateModified": "2025-12-03T14:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Autolane is building ‘air traffic control’ for autonomous vehicles",
    "url": "https://techcrunch.com/2025/12/03/autolane-is-building-air-traffic-control-for-autonomous-vehicles/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/autolane.jpg?w=112",
    "tag": "Tech",
    "date": "2025-12-03T14:00:00.000Z",
    "description": "\nThe rapid succession of robotaxi deployments from companies like Waymo and Zoox have people in the industry, once again, dreaming about how autonomou",
    "body": "\nThe rapid succession of robotaxi deployments from companies like Waymo and Zoox have people in the industry, once again, dreaming about how autonomous vehicles might change our daily lives. That includes driverless taxi rides, sure, but also headier ideas like sending an autonomous vehicle to fetch groceries or pick up dry cleaning.\nIf those things are ultimately going to happen, navigating the handoff moments — like where exactly a vehicle should stop to receive the groceries — will be a crucial piece of the puzzle. Palo Alto-based Autolane is trying to build that layer of infrastructure, and it now has $7.4 million in fresh funding to take on that goal.\nBacked by VC firms like Draper Associates and Hyperplane, Autolane said it will start by coordinating pickup and drop-off points for companies that want to let robotaxis come onto their private property. The startup has signed a deal with Simon Property Group to coordinate driverless vehicle arrivals and departures at shopping centers owned by the real estate company in Austin, Texas and San Francisco, California.\nThis deal will include creating simple, physical infrastructure like signage (think: the many kinds of Uber and Lyft pick-up and drop-off stanchions that decorate modern hotels and airports) and also software.\n“I believe we are one of the first, let’s say, ‘application layer’ companies in autonomy,” Autolane co-founder and CEO Ben Seidl told TechCrunch in an exclusive interview. “We aren’t the fundamental models. We’re not building the cars. We’re not doing anything like that. We are simply saying, as this industry balloons rapidly and has exponential growth — as is already occurring this year and will occur for the next 10 years straight — someone is going to have to sit in the middle and orchestrate, coordinate, and kind of evaluate what’s going on.”\nAutolane is starting with robotaxis in mind, but Seidl is clearly focused on the bigger-picture idea of applying his company’s tech to all kinds of tasks autonomous vehicles might be able to perform in the future. And he wants to move quickly with Autolane because, as he sees it, the startup doesn’t have “any direct competition” right now. He expects that to change soon.\nSeidl said he was convinced there was a business here after buying a Tesla last year and using the company’s Full Self-Driving (Supervised) driver assistance software for the first time.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n“As soon as my own personal car was driving me around town, pretty much flawlessly, I just — my head kind of exploded,” he said. “I was mostly enthralled by the idea that this was going to change logistics, retail, real estate, where we work, where we live, where we play, how we get around, what the price of movement of goods and services and people will be.” \nSeidl cited the viral incident from earlier this year where a Waymo robotaxi got stuck navigating a Chick-fil-A drive-through in Santa Monica, California, as an example of the problem Autolane is trying to head off. In that case, the robotaxi had dropped off its passengers and then struggled to negotiate the fast food company’s notorious drive-through lanes. Seidl said by using Autolane software and designating an exact pick-up and drop-off location, problems like this can be avoided in the future.\n“Someone has got to bring some order to this chaos, and the chaos is already starting,” he said.\nCompanies could surely do some of this work themselves, at least on the physical infrastructure side. It’s simply not that hard to make a sign.\n“Anyone can do that,” Seidl said. “That’s not the case, though, for autonomy. Robotics need precise instructions and precise geolocation and technological communication. You can’t just put up a white sign with some black letters and hope for the best with 10 different types of of robotics coming in.” \nInstead, Seidl said the value of Autolane is in how it will integrate with the companies that own real estate as well as with the autonomous vehicle providers. That’s why the plan is to essentially build APIs for the physical locations so autonomous vehicle companies can receive these precise instructions. Businesses will have to “directly integrate into each one of these robotics companies, car companies, so that they follow your rules,” he said.\nSeidl also said he explicitly does not want to work with cities or municipalities. \n“We don’t work on public streets. We don’t work with public parking spots. We’re just providing these tools as kind of a B2B, hardware-enabled SAS solution so that Costco, or McDonald’s, or Home Depot, or, in our case, Simon Property Group, the world’s largest retail REIT [real estate investment trust] can begin to have what I like to refer to as ‘air traffic control for autonomous vehicles,’ meaning they know which ones are incoming and outgoing,” he said.\n\n\n\t\tSean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.\r\nYou can contact or verify outreach from Sean by emailing sean.okane@techcrunch.com or via encrypted message at okane.01 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Autolane is building ‘air traffic control’ for autonomous vehicles",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/autolane.jpg?w=112"
      ],
      "datePublished": "2025-12-03T14:00:00.000Z",
      "dateModified": "2025-12-03T14:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Google Photos’ 2025 Recap turns to Gemini to find your highlights",
    "url": "https://techcrunch.com/2025/12/03/google-photos-2025-recap-turns-to-gemini-to-find-your-highlights/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/Google-Photos-Recap-2025-12-03-at-10.34.31-AM.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T16:00:00.000Z",
    "description": "\nGoogle Photos users can now access their year-end Recap, the photo-hosting site’s own version of something akin to Spotify Wrapped. Like other annual",
    "body": "\nGoogle Photos users can now access their year-end Recap, the photo-hosting site’s own version of something akin to Spotify Wrapped. Like other annual reviews, the Google Photos Recap lets you look back on your past year in photos, offering a combination of memorable highlights enhanced with graphics and other effects, plus photo stats and more. \nU.S. users will also gain access to a new feature powered by Google’s AI, Gemini, which will showcase your hobbies and other top highlights, the company says.\nFirst introduced in 2024, Google Photos Recap aims to capitalize on the data-powered review trend, popularized by services like Spotify Wrapped, and in past decades, by time-traveling apps like Timehop. \nHowever, this year, the Google Photos Recap also serves as a testing ground for Gemini, as the company unleashes the AI on your photo archive to help surface more of the moments you might like to review.\nImage Credits:Google\nIn addition, the recap will offer photo stats from the year, like total photo count, top people, and, new for this year, a total selfie count. The feature also now lets you hide specific people or photos. After doing so, you can then regenerate your Recap for an updated version. \nThe photos and memories from the Recap can be easily shared on social media and elsewhere. A new integration with CapCut will add a button at the end of the Recap to export it to the photo and video editing app, where you can use other Google Photos templates to customize the Recap further. \nImage Credits:Google\nThere’s also a new carousel at the end of the Recap containing short videos, photos, and collages designed for sharing to group chats or social media. One option even allows you to share your Recap directly to your WhatsApp Status. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nIf you don’t immediately see your Recap, you can request Google Photos to generate it for you using an option at the top of the app. After viewing the Recap, it will remain in your app throughout the month of December. To access it again during this time, you can find it either in the back of your Memories carousel or pinned in your Collections tab. \nImage Credits:Google\nIn addition to the annual review, Google Photos will release a series of 2025 highlights throughout the month of December, the company noted. \n\n\n\t\tSarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.\nYou can contact or verify outreach from Sarah by emailing sarahp@techcrunch.com or via encrypted message at sarahperez.01 on Signal. \t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Google Photos’ 2025 Recap turns to Gemini to find your highlights",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/Google-Photos-Recap-2025-12-03-at-10.34.31-AM.jpg?w=150"
      ],
      "datePublished": "2025-12-03T16:00:00.000Z",
      "dateModified": "2025-12-03T16:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Healthify upgrades its AI assistant Ria with real-time conversation capabilities",
    "url": "https://techcrunch.com/2025/12/02/healthify-upgrades-its-ai-assistant-ria-with-real-time-conversation-capabilities/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/1.-16x9-Primary-Banner.jpeg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T07:00:00.000Z",
    "description": "\nWith new AI models, health tracking companies have realized that they can now provide insights using both structured and unstructured data. The new g",
    "body": "\nWith new AI models, health tracking companies have realized that they can now provide insights using both structured and unstructured data. The new goal is to create interfaces and modalities that make it easier for users to create a habit of logging their meals or workouts, along with having an ever-present AI assistant that can guide people in areas like nutrition and exercise.\nKhosla-backed health startup Healthify on Tuesday launched a new version of its health assistant Ria, which you can converse with live, via voice, and by using the camera for getting input about your food.\nThe startup is using OpenAI’s tech to power this conversational mode. With this release, Ria supports more than 50 languages, including 14 Indian languages. The company said that it can also support mixed language input like Hinglish or Spanglish. While the company is largely utilizing OpenAI’s models for this release, it said that in the future it could use other models if needed.\nImage Credits: Healthify\nThrough the new version of Ria, users can ask for their health overview for specified time frames like day, week, or month, or an overall summary. The app can pull data from different sources like fitness trackers, sleep trackers, or glucose monitors to give users insights about exercise, sleep, readiness, and glucose spikes, and give suggestions.\nJust like Google Gemini’s Live Conversation mode, you can point the camera to ask about different food items and their nutritional value, then log them. \n\n\n\nHealthify also showed off a demo of using Ray-Ban Meta smart glasses to converse with Ria in real time and use the device’s camera to log food. \nThe startup believes its users will feel more comfortable chatting in real time with an assistant. Plus, they can do multiple things in one session, such as getting insights, generating an exercise plan, or logging their goals. If you forget to log your food for the day, you can describe your meals in one go instead of typing them out, and the assistant will log them for you.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nWhat’s more, the company is looking to utilize its updated AI in more places. In the coming months, it plans to make the conversational assistant a central piece of user onboarding so it can gather more insights from unstructured conversations. (Notably, new-age dating apps have opted for this kind of interface to create better matches for users.)\nThe startup is also creating a more persistent memory layer over OpenAI’s models and its assistant to have the app remember long-term context around preferences and health changes to give more personalized suggestions. \nHealthify is also making the assistant available in conversations with your coach or nutritionist to help either of you pull data or answer your questions when they are not available. Plus, it’s adding Ria to your calls with coaches and nutritionists so it can transcribe the calls for insights. Users or coaches can also ask Ria for data while they are on a call.\nThe company’s CEO, Tushar Vashisht, said that the team trained Ria on years of conversational data between coaches and users to give grounded and accurate advice.\nApart from Healthify, other apps like Alma, Cal AI, MyfitnessPal, and Ladder have created ways for users to input food intakes using voice, text, or images. Healthify believes that with its live conversation mode, data aggregation from various platforms, and AI trained on years of data, it has an edge over its competitors. What’s more, the company has added a way to access your gallery and automatically detect food photos to give you options for adding meals that you might have missed logging in. \n“We are focusing on creating a health ecosystem of nutrition-driven data with other integrations. From an AI perspective, we are putting in levers to solve for accountability in users when it comes to health,” the company’s CPO Paritosh Kumar told TechCrunch.\nHealthify, which has more than 45 million registered users and a few million active monthly users, is also launching a new AI plan in the U.S with updated Ria assistant and meal planning at $20 per month. Prior to this, the company had been testing various plans with text-based AI and certified nutrition coaches.\nThe company said it’s hoping to soon announce partnerships around its GLP-1-aided weight loss programs. In the coming months, Healthify also plans to partner with health tracking device companies to bring their data into Ria.\nVashisht said the company may raise a new funding round in the near future, given its strong U.S. adoption and growth. \n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Healthify upgrades its AI assistant Ria with real-time conversation capabilities",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/1.-16x9-Primary-Banner.jpeg?w=150"
      ],
      "datePublished": "2025-12-03T07:00:00.000Z",
      "dateModified": "2025-12-03T07:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Uber and Avride launch robotaxi service in Dallas",
    "url": "https://techcrunch.com/2025/12/03/uber-and-avride-launch-robotaxi-service-in-dallas/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/uber-avride-dallas.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T12:00:00.000Z",
    "description": "\nUber customers in Dallas may get an Avride-branded robotaxi the next time they hail a ride. \nA year after announcing their partnership, Uber and Avri",
    "body": "\nUber customers in Dallas may get an Avride-branded robotaxi the next time they hail a ride. \nA year after announcing their partnership, Uber and Avride have launched a commercial robotaxi service in Dallas. The service comes with a few caveats, however, including the addition of a human safety operator behind the wheel, and a limited operating area. The companies said fully driverless operations, without a safety operator, will begin in the future and the service area will expand.\nFor Uber, the launch closes out a year of rapid dealmaking — and deployments — with a variety of autonomous vehicle technology companies, including Waymo, China’s WeRide and San Francisco-based startup Nuro. To date, Uber has locked in 20 partnerships with AV companies across freight, delivery and robotaxis, some of which are now in commercial operation. Uber offers autonomous vehicles through its ride-hailing app in Abu Dhabi and Riyadh with WeRide, and in Atlanta, Austin, and Phoenix with Waymo.\nUber said it plans to have autonomous vehicles on its network in at least 10 cities by the end of 2026. Over the next two years, the plan is to launch AVs on its app in Arlington, Texas, Dubai, London, Los Angeles, Munich and the San Francisco Bay Area.\nMany of these partnerships have included an investment by Uber, and Avride, an Austin-based startup that sits under parent company Nebius Group, is one of those.\nIn October 2024, the ride-hailing company struck a multi-year deal with Avride to bring its sidewalk delivery robots and autonomous vehicles to both Uber Eats and Uber. Within months, Avride’s sidewalk robots began delivering food via the Uber Eats app in Austin, Dallas and Jersey City.\nThis fall, Avride secured strategic investments and commercial commitments worth $375 million from Uber and Nebius, which was previously known as Yandex NV, the Netherlands-based company that sold off its Russian business in 2024.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nUber’s use of Avride sidewalk robots for its food delivery business was notable, but this robotaxi launch has arguably higher stakes for both companies.\nThe robotaxi fleet of all-electric Hyundai Ioniq 5 vehicles is equipped with Avride’s self-driving system, and will service a 9-square-mile area of Dallas that includes downtown. Uber said it plans to expand the operating territory in the coming months.\n\nThe fleet, currently limited, will eventually expand to hundreds of Avride robotaxis across Dallas in the next few years, according to an Uber spokesperson.\nThe robotaxi service in Dallas will eventually operate similarly to Uber’s partnership with Waymo in Austin and Atlanta. Avride will initially manage its own fleet, and Uber will take over day-to-day fleet operations, including cleaning, maintenance, inspections, charging and depot management. From the start, Uber will provide end-to-end rider support, while Avride will oversee vehicle testing.\nUber riders who request UberX, Uber Comfort or Uber Comfort Electric rides may be matched with an Avride robotaxi. The match is not guaranteed, and riders can increase their chances of getting a robotaxi by changing a setting in the Uber app. Robotaxi rides will cost the same as those operated by a human driver, according to Uber.\nWhen an Uber user is notified they’ve been matched with an Avride robotaxi, they can choose to accept or switch to a human-driven ride. Once the robotaxi arrives, riders can use the Uber app to unlock the vehicle, open the trunk and start the trip.\n\n\n\t\tKirsten Korosec is a reporter and editor who has covered the future of transportation from EVs and autonomous vehicles to urban air mobility and in-car tech for more than a decade. She is currently the transportation editor at TechCrunch and co-host of TechCrunch’s Equity podcast. She is also co-founder and co-host of the podcast, “The Autonocast.” She previously wrote for Fortune, The Verge, Bloomberg, MIT Technology Review and CBS Interactive.\nYou can contact or verify outreach from Kirsten by emailing kirsten.korosec@techcrunch.com or via encrypted message at kkorosec.07 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Uber and Avride launch robotaxi service in Dallas",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/uber-avride-dallas.jpg?w=150"
      ],
      "datePublished": "2025-12-03T12:00:00.000Z",
      "dateModified": "2025-12-03T12:00:00.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Amazon challenges competitors with on-premises Nvidia ‘AI Factories’",
    "url": "https://techcrunch.com/2025/12/02/amazon-challenges-competitors-with-on-premises-nvidia-ai-factories/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/Amazon-AWS-AI-Factory.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T00:43:37.000Z",
    "description": "\nAmazon announced a new product Tuesday called “AI Factories” that allows big corporations and governments to run its AI systems in their own data cen",
    "body": "\nAmazon announced a new product Tuesday called “AI Factories” that allows big corporations and governments to run its AI systems in their own data centers. Or as AWS puts it: Customers supply the power and the data center, and AWS plunks in the AI system, manages it, and can tie it into other AWS cloud services.\nThe idea is to cater to companies and governments concerned with data sovereignty, or absolute control over their data so it can’t wind up in a competitor’s or foreign adversary’s hands. An on-prem AI Factory means not sending their data to a model maker and not even sharing the hardware.\nIf that product name sounds familiar, it should. That’s what Nvidia calls its hardware systems that are chock-full of tools needed to run AI, from its GPU chips to its networking tech. This AWS AI Factory is, in fact, a collaboration with Nvidia, both companies say. \nIn this case, the AWS Factory will use a combination of AWS and Nvidia technology. Companies that deploy these systems can opt for Nvidia’s latest Blackwell GPUs or Amazon’s new Trainium3 chip. It uses AWS’ homegrown networking, storage, databases, and security and can tap into Amazon Bedrock — the AI model selection and management service, and AWS SageMaker AI, the model building and training tool.\nInterestingly, AWS is far from the only giant cloud provider installing Nvidia AI Factories. In October, Microsoft showed off its first of many-to-come AI Factories rolling out into its global data centers to run OpenAI workloads. Microsoft didn’t announce at the time that these extreme machines would be available for private clouds. Instead, Microsoft highlighted how it was leaning on a host of Nvidia AI Factory data center tech to build and connect its new “AI Superfactories,” aka new state-of-the-art data centers being built in Wisconsin and Georgia.\nLast month, Microsoft also outlined the data centers and cloud services that would be built in local countries to address the data sovereignty issue. To be fair, its options also include “Azure Local,” Microsoft’s own managed hardware that could be installed on customer sites.\nStill, it is a bit ironic that AI is causing the biggest cloud providers to invest so heavily in corporate private data centers and hybrid clouds like it’s 2009 all over again.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Amazon challenges competitors with on-premises Nvidia ‘AI Factories’",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/Amazon-AWS-AI-Factory.jpg?w=150"
      ],
      "datePublished": "2025-12-03T00:43:37.000Z",
      "dateModified": "2025-12-03T00:43:37.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "After intense backlash, India pulls mandate to pre-install government app on smartphones",
    "url": "https://techcrunch.com/2025/12/03/after-intense-backlash-india-pulls-mandate-to-pre-install-government-app-on-smartphones/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/12/sanchar-sathi-app.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T12:11:44.000Z",
    "description": "\nIndia has backed away from its plan to force smartphone makers to pre-install a government app on all devices, following backlash and mounting concer",
    "body": "\nIndia has backed away from its plan to force smartphone makers to pre-install a government app on all devices, following backlash and mounting concerns that the mandate would expand state access to users’ devices and weaken privacy protections.\nOn Wednesday, the Indian telecom ministry said Sanchar Saathi, an anti-theft and cybersecurity protection app, would remain voluntary, and that smartphone makers would no longer be required to preload it on devices they sell. \nThe new notice effectively reverses a directive issued to manufacturers last week (and circulated online on Monday) that had instructed manufacturers to bake the app into all devices and prevent its features from being disabled. News of the mandate soon ignited concerns over privacy and state overreach.\n“Given Sanchar Saathi’s increasing acceptance, the government has decided not to make pre-installation mandatory for mobile manufacturers,” the ministry said.\nHowever, the government has not yet issued an official notification to smartphone makers reflecting the withdrawal, and manufacturers are still waiting for formal instructions, two manufacturer sources involved with the proceedings told TechCrunch.\nSince its release in January 2025, Sanchar Saathi has so far been downloaded 14 million times, and contributes information on roughly 2,000 cyber-fraud incidents per day, per the Indian government. The recent controversy boosted interest in the platform, and the ministry noted that about 600,000 citizens registered to download the app on December 2 alone.\nThe telecom ministry’s notice follows much confusion over whether the app was truly voluntary, as the government claimed. Telecom minister Jyotiraditya Scindia had insisted earlier this week that users could delete Sanchar Saathi at any time, even though the directive circulating among manufacturers stated that the app’s functionalities “must not be disabled or restricted.” \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nThe conflicting signals fueled criticism that the government was attempting to downplay the extent of its mandate. Critics warned that forcing a government app onto every smartphone, and preventing its features from being disabled would give authorities excessive visibility into users’ devices.\nThe directive had also raised concerns within the industry, with manufacturers privately questioning the feasibility of enforcing a permanent, system-level app without clear legal backing.\nDeputy telecom minister Pemmasani Chandra Sekhar said in media interviews that Apple did not participate in the working group for the initiative, though other smartphone makers did.\nSanchar Saathi had more than 3 million monthly active users in November, according to marketing intelligence firm Sensor Tower. Web traffic to Sanchar Saathi has also surged, with monthly unique visitors rising by more than 49% year-over-year, per Sensor Tower.\nThe Internet Freedom Foundation, a New Delhi-based digital rights group, called the reversal a “welcome development,” but urged caution, noting that it is still awaiting the legal order that should accompany the announcement. The group added that “cautious optimism, not closure,” was warranted until revised directions under the Cyber Security Rules, 2024, are published and independently verified.\nOther parts of the Sanchar Saathi ecosystem continue to expand. Recommerce and trade-in platforms are still required to validate devices through a central IMEI database, and the telecom ministry is also piloting an API that could allow these firms to submit customer and device information directly to the state. \n\n\n\t\tJagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. \r\nYou can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "After intense backlash, India pulls mandate to pre-install government app on smartphones",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/12/sanchar-sathi-app.jpg?w=150"
      ],
      "datePublished": "2025-12-03T12:11:44.000Z",
      "dateModified": "2025-12-03T12:11:44.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Google tests merging AI Overviews with AI Mode",
    "url": "https://techcrunch.com/2025/12/02/google-tests-merging-ai-overviews-with-ai-mode/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/09/google-ai-mode-techcrunch.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-02T22:26:34.000Z",
    "description": "\nAs OpenAI goes into “Code Red” over competitive pressures, Google announced it has begun testing a new feature that merges its AI Overviews with AI M",
    "body": "\nAs OpenAI goes into “Code Red” over competitive pressures, Google announced it has begun testing a new feature that merges its AI Overviews with AI Mode in Search. That means that users who are provided with the now common AI-generated snapshot of key information on a topic or question above their search results can choose to go deeper by asking follow-up questions in a conversational interface.\nGoogle calls this conversational feature AI Mode. It launched to U.S. users this May, and to global users this August, allowing for back-and-forth chats with Google’s Gemini AI, in an experience similar to ChatGPT.\nHowever, accessing the experience so far has required you to think ahead about what type of question you were preparing to search for. If it were a more traditional search query, or one where you could expect to get a quick answer, you’d likely stick with typing into the search box as usual.\nBut if you expected to ask more questions or explore a topic in more detail, you’d have to click over to the AI Mode tab to start chatting with the AI instead.\nGoogle now wants to test whether or not it makes sense to differentiate the two experiences. After all, the process of information seeking can often lead to a desire to learn more. You may have thought you were starting a simple query, only to find yourself delving deeper into the topic.\n\n(1/2) Today we’re starting to test a new way to seamlessly go deeper in AI Mode directly from the Search results page on mobile, globally.This brings us closer to our vision for Search: just ask whatever’s on your mind – no matter how long or complex – and find exactly what you… pic.twitter.com/mcCS7oT2FI— Robby Stein (@rmstein) December 1, 2025\n\nWith the new test, announced on Monday, Google says users will be able to “seamlessly go deeper” in AI Mode directly from the Search results page. While the test is rolling out to users globally, it’s only available on mobile devices for the time being. \nThe rollout comes alongside a push inside Google’s AI rival, OpenAI, which is now delaying other products to focus on improving the chatbox experience. Thanks in part to the release of Gemini’s Nano Banana image model and other Gemini improvements, Gemini has grown to over 650 million monthly users as of November. Merging the conversational mode with AI Overviews, which has 2 billion monthly users, could give Gemini an edge in consumer adoption.\nNotes VP of Product for Google Search Robby Stein, in a post on X, “You shouldn’t have to think about where or how to ask your question.” Instead, he explained, users will continue to get an AI Overview as a helpful starting point, but will then be able to ask conversational follow-up questions in AI Mode from the same screen.\n“This brings us closer to our vision for Search: just ask whatever’s on your mind – no matter how long or complex – and find exactly what you need,” Stein wrote. \n\nCheck out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.\n\n\n\t\tSarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.\nYou can contact or verify outreach from Sarah by emailing sarahp@techcrunch.com or via encrypted message at sarahperez.01 on Signal. \t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Google tests merging AI Overviews with AI Mode",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/09/google-ai-mode-techcrunch.jpg?w=150"
      ],
      "datePublished": "2025-12-02T22:26:34.000Z",
      "dateModified": "2025-12-02T22:26:34.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Nothing looks to its community to raise $5M, wants to be ‘IPO-ready’ in 3 years",
    "url": "https://techcrunch.com/2025/12/03/nothing-looks-to-its-community-to-raise-5m-wants-to-be-ipo-ready-in-3-years/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/07/Nothing-Phone-3-feat.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-03T12:54:15.000Z",
    "description": "\nHardware maker Nothing is letting its user base buy its stock as part of a new community investment round of $5 million. The new round, which opens o",
    "body": "\nHardware maker Nothing is letting its user base buy its stock as part of a new community investment round of $5 million. The new round, which opens on December 10, will enable consumers to buy the company’s shares at its Series C valuation of $1.3 billion.\nThe company said it has so far raised $8 million in total from over 8,000 people across two previous community investment rounds. It held its first community funding event in 2021, aiming to raise $1.5 million. \n“This isn’t about raising capital, it’s about giving our community/fans a chance to invest while we’re private and join us on the journey,” a spokesperson for Nothing told TechCrunch.\nCommunity investors have a rotating seat on the company’s board, but it is unclear what else they get for investing in the company through such rounds.\nNothing raised $200 million in its Series C back in September from investors including Tiger Global, GV, Highland Europe, EQT, Latitude, I2BF and Tapestry. The company has raised $450 million to date.\nThe community round comes as Nothing makes changes to its corporate structure as it tries to increase its share of a smartphone market dominated by giants like Samsung and Apple. The company is spinning off its budget CMF brand, and plans to explore AI-centric devices while it keeps building smartphones and audio products. And Nothing claims it crossed $1 billion in cumulative revenue this year, up 150% from 2024. \nThe startup is working to be “IPO-ready” in three years, CEO Carl Pei told TechCrunch in an email. “The timing will depend on market conditions and what makes sense for the business at that point in time,” he said. \n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\n“What’s important is that we’re already operating with that discipline now. We’re building the systems, the governance, the financial discipline that a public company needs. It forces us to think longer-term and make smarter decisions that prioritise sustainable growth,” Pei added.\nIt’s not clear if Nothing aims to raise another round before an IPO. When asked about its fundraising plans, a Nothing spokesperson said the company is not thinking about raising capital immediately, but it wouldn’t be averse to those conversations.\nThose interested in investing in the community round can use platforms like Wefunder and Crowdcube to participate.\n\n\n\t\tIvan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web.\r\nYou can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Nothing looks to its community to raise $5M, wants to be ‘IPO-ready’ in 3 years",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/07/Nothing-Phone-3-feat.jpg?w=150"
      ],
      "datePublished": "2025-12-03T12:54:15.000Z",
      "dateModified": "2025-12-03T12:54:15.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Amazon previews 3 AI agents, including ‘Kiro’ that can code on its own for days",
    "url": "https://techcrunch.com/2025/12/02/amazon-previews-3-ai-agents-including-kiro-that-can-code-on-its-own-for-days/",
    "image": "https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1065679054.jpg?w=150",
    "tag": "Tech",
    "date": "2025-12-02T22:18:01.000Z",
    "description": "\nAmazon Web Services on Tuesday announced three new AI agents it calls “frontier agents,” including one designed to learn how you like to work and the",
    "body": "\nAmazon Web Services on Tuesday announced three new AI agents it calls “frontier agents,” including one designed to learn how you like to work and then operate on its own for days.\nEach of these agents handle different tasks such as writing code, security processes like code reviews, and automating DevOps tasks such as preventing incidents when pushing new code live. Preview versions of the agents are available now.\nPerhaps the biggest and most interesting claim by AWS is its promise that the frontier agent called “Kiro autonomous agent” can work on its own for days at a time.\nKiro is a software coding agent based on AWS’s existing AI coding tool Kiro, which was announced in July. While that existing tool could be used for vibe coding (which is really just prototyping), it was intended to produce operational code, or software that would be pushed live. To make reliable code, the AI must follow a company’s software-coding specifications. Kiro does that through a concept called “spec-driven development.”\nAs Kiro codes, it has the human instruct, confirm, or correct its assumptions, thereby creating specifications. The Kiro autonomous agent watches how the team works in various tools by scanning existing code, among other training means. And then, AWS says, it can work independently.\n“You simply assign a complex task from the backlog and it independently figures out how to get that work done,” AWS CEO Matt Garman promised when introducing the new product during his keynote at AWS re:Invent on Tuesday.\n“It actually learns how you like to work, and it continues to deepen its understanding of your code and your products and the standards that your team follows over time,” he said.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nAmazon says Kiro maintains “persistent context across sessions.” In other words, it doesn’t run out of memory and forget what it was supposed to do.  It can therefore be handed tasks and work on its own for hours or days, Amazon promises, with minimal human intervention. \nGarman described a task like updating a bit of critical code used by 15 bits of corporate software. Instead of assigning and verifying each update, Kiro can be assigned to fix all 15 in one prompt. \nTo complete the automation of coding tasks, the cloud provider developed AWS Security Agent, an agent that works independently to identify security problems as code is written, tests it after the fact, and then offers suggested fixes. The DevOps Agent rounds out the trio, automatically testing the new code for performance issues, or compatibility with other software, hardware, or cloud settings.\nTo be sure, Amazon’s agents aren’t the first to claim long work windows. For instance OpenAI said last month that GPT‑5.1-Codex-Max, its agentic coding model, is designed for long runs, too, up to 24 hours.\nIt’s also not totally clear that the biggest hurdle to agentic adoption is the context window (aka the ability to work continuously without stalling out). LLMs still have hallucination and accuracy issues that turn developers into “babysitters,” they say.  So developers often want to assign short tasks and verify quickly before moving on.\nStill, before agents can become like co-workers, context windows must grow bigger. Amazon’s tech is another big step in that direction. \n\nCheck out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Amazon previews 3 AI agents, including ‘Kiro’ that can code on its own for days",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1065679054.jpg?w=150"
      ],
      "datePublished": "2025-12-02T22:18:01.000Z",
      "dateModified": "2025-12-02T22:18:01.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  },
  {
    "title": "Microreactor startup Antares raises $96M for land, sea, and space-based nuclear power",
    "url": "https://techcrunch.com/2025/12/02/microreactor-startup-antares-raises-96m-for-land-sea-and-space-based-nuclear-power/",
    "image": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-157741219.jpeg?w=150",
    "tag": "Tech",
    "date": "2025-12-02T20:26:13.000Z",
    "description": "\nNuclear startup Antares said Tuesday it has raised $96 million in Series B funding as it pursues its small modular reactor design.\nThe round, which w",
    "body": "\nNuclear startup Antares said Tuesday it has raised $96 million in Series B funding as it pursues its small modular reactor design.\nThe round, which was led by Shine Capital with participation from Alt Capital, Caffeinated, FiftyThree Stations, Industrious, and others, consists of $71 million in equity and $25 million in debt.\nAntares says it is targeting commercial, defense, and space-based applications with its R1 microreactor, which will produce between 100 kilowatts and 1 megawatt of electricity. The design uses TRISO fuel, which in Antares case is spheres of carbon- and ceramic-coated uranium embedded in graphite.\nThe startup is one of several companies that have benefited recently from renewed interest in nuclear power over the last six months.\nLast week, Amazon-backed X-energy said it had raised a $700 million Series D round, which came on the heels of an upsized $700 million Series C that closed in February. The company is also designing a reactor around TRISO fuel. Deep Fission, which had struggled to raise money as recently as April, went public in a $30 million reverse merger in September. \nAalo Atomics raised $100 million in August to build a demonstration data center powered by a microreactor, and in June, Nvidia contributed to a $650 million round for TerraPower, a small modular reactor startup also backed by Bill Gates.\nBig nuclear plants have been given a second chance, too.\n\n\t\tTechcrunch event\n\t\t\n\t\t\tSan Francisco\n\t\t\t\t\t\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\t\t\t\t\tOctober 13-15, 2026\n\t\t\t\t\t\t\t\n\t\t\n\t\nEarlier this month, Microsoft partner Constellation Energy received a $1 billion loan from the Department of Energy to restart a reactor at Three Mile Island by 2028. That project is expected to cost $1.6 billion to refurbish the reactor that was idled in 2019. In October, Google said it would work with NextEra Energy to reopen a nuclear power plant in Iowa that was damaged during a torrential downpour in 2020.\nEarlier this summer, Amazon bought 1.92 gigawatts of generating capacity from a Talen Energy nuclear plant in Pennsylvania. Meta also said in June it would buy the clean energy attributes from a Constellation Energy nuclear power plant in Illinois.\nAnd while big nuclear has been a major beneficiary, the Trump administration is bullish on small nuclear’s potential to revive the industry’s fortunes in the coming decade. \nIn August, Antares was named one of 11 participants in the Department of Energy’s reactor pilot program, which aims to have at least three of those begin operation by July 4, 2026, a timeline that’s significantly faster than the nuclear industry is accustomed to.\nAntares has said it aims to demonstrate its reactor for the DOE next year and is planning to turn on its full-power reactor sometime in 2027.\n\n\n\t\tTim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor. \r\nDe Chant is also a lecturer in MIT’s Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. He received his PhD in environmental science, policy, and management from the University of California, Berkeley, and his BA degree in environmental studies, English, and biology from St. Olaf College.\r\nYou can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com.\t\n\t\n\t\tView Bio \n\t\n",
    "schema": {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "Microreactor startup Antares raises $96M for land, sea, and space-based nuclear power",
      "image": [
        "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-157741219.jpeg?w=150"
      ],
      "datePublished": "2025-12-02T20:26:13.000Z",
      "dateModified": "2025-12-02T20:26:13.000Z",
      "author": [
        {
          "@type": "Person",
          "name": "Midnight Ink Staff"
        }
      ]
    }
  }
]